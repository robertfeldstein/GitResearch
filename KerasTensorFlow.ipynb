{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.layers import Flatten\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>CMI_C01</th>\n",
       "      <th>CMI_C02</th>\n",
       "      <th>CMI_C03</th>\n",
       "      <th>CMI_C04</th>\n",
       "      <th>CMI_C05</th>\n",
       "      <th>CMI_C06</th>\n",
       "      <th>CMI_C07</th>\n",
       "      <th>...</th>\n",
       "      <th>CMI_C11</th>\n",
       "      <th>CMI_C12</th>\n",
       "      <th>CMI_C13</th>\n",
       "      <th>CMI_C14</th>\n",
       "      <th>CMI_C15</th>\n",
       "      <th>CMI_C16</th>\n",
       "      <th>ACM</th>\n",
       "      <th>BCM</th>\n",
       "      <th>Cloud_Probabilities</th>\n",
       "      <th>Lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(44.28533797848896, -96.33244120270002)</td>\n",
       "      <td>0.169623</td>\n",
       "      <td>0.099563</td>\n",
       "      <td>0.375139</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.195774</td>\n",
       "      <td>0.102440</td>\n",
       "      <td>298.40840</td>\n",
       "      <td>...</td>\n",
       "      <td>288.29090</td>\n",
       "      <td>257.63177</td>\n",
       "      <td>292.63490</td>\n",
       "      <td>292.07776</td>\n",
       "      <td>288.22775</td>\n",
       "      <td>269.13647</td>\n",
       "      <td>0.078123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(44.16192918412268, -96.2790076055067)</td>\n",
       "      <td>0.180972</td>\n",
       "      <td>0.110357</td>\n",
       "      <td>0.416170</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.207321</td>\n",
       "      <td>0.111607</td>\n",
       "      <td>298.71533</td>\n",
       "      <td>...</td>\n",
       "      <td>287.71057</td>\n",
       "      <td>257.37183</td>\n",
       "      <td>291.90130</td>\n",
       "      <td>291.38574</td>\n",
       "      <td>287.57257</td>\n",
       "      <td>268.87482</td>\n",
       "      <td>0.109530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>(44.03893135837276, -96.22611143587908)</td>\n",
       "      <td>0.240833</td>\n",
       "      <td>0.172460</td>\n",
       "      <td>0.445059</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.238750</td>\n",
       "      <td>0.145952</td>\n",
       "      <td>298.25534</td>\n",
       "      <td>...</td>\n",
       "      <td>285.00128</td>\n",
       "      <td>255.86801</td>\n",
       "      <td>288.94000</td>\n",
       "      <td>288.50170</td>\n",
       "      <td>285.11570</td>\n",
       "      <td>267.86960</td>\n",
       "      <td>0.813740</td>\n",
       "      <td>0.094060</td>\n",
       "      <td>0.265362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>(43.916339862914086, -96.17374408076766)</td>\n",
       "      <td>0.245674</td>\n",
       "      <td>0.177897</td>\n",
       "      <td>0.430456</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.237897</td>\n",
       "      <td>0.147659</td>\n",
       "      <td>298.69244</td>\n",
       "      <td>...</td>\n",
       "      <td>285.33386</td>\n",
       "      <td>256.09546</td>\n",
       "      <td>289.18967</td>\n",
       "      <td>288.67377</td>\n",
       "      <td>285.32043</td>\n",
       "      <td>267.93500</td>\n",
       "      <td>0.687891</td>\n",
       "      <td>0.093906</td>\n",
       "      <td>0.228131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>(43.794150142168, -96.1218971247137)</td>\n",
       "      <td>0.252857</td>\n",
       "      <td>0.182976</td>\n",
       "      <td>0.475952</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.233353</td>\n",
       "      <td>0.140972</td>\n",
       "      <td>297.63165</td>\n",
       "      <td>...</td>\n",
       "      <td>284.73395</td>\n",
       "      <td>255.71437</td>\n",
       "      <td>288.62890</td>\n",
       "      <td>288.18744</td>\n",
       "      <td>284.90723</td>\n",
       "      <td>267.90747</td>\n",
       "      <td>0.797112</td>\n",
       "      <td>0.125466</td>\n",
       "      <td>0.303975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                               Coordinates   CMI_C01  \\\n",
       "0           0      0   (44.28533797848896, -96.33244120270002)  0.169623   \n",
       "1           1      1    (44.16192918412268, -96.2790076055067)  0.180972   \n",
       "2           2      2   (44.03893135837276, -96.22611143587908)  0.240833   \n",
       "3           3      3  (43.916339862914086, -96.17374408076766)  0.245674   \n",
       "4           4      4      (43.794150142168, -96.1218971247137)  0.252857   \n",
       "\n",
       "    CMI_C02   CMI_C03   CMI_C04   CMI_C05   CMI_C06    CMI_C07  ...  \\\n",
       "0  0.099563  0.375139  0.001111  0.195774  0.102440  298.40840  ...   \n",
       "1  0.110357  0.416170  0.001071  0.207321  0.111607  298.71533  ...   \n",
       "2  0.172460  0.445059  0.001111  0.238750  0.145952  298.25534  ...   \n",
       "3  0.177897  0.430456  0.001587  0.237897  0.147659  298.69244  ...   \n",
       "4  0.182976  0.475952  0.001270  0.233353  0.140972  297.63165  ...   \n",
       "\n",
       "     CMI_C11    CMI_C12    CMI_C13    CMI_C14    CMI_C15    CMI_C16       ACM  \\\n",
       "0  288.29090  257.63177  292.63490  292.07776  288.22775  269.13647  0.078123   \n",
       "1  287.71057  257.37183  291.90130  291.38574  287.57257  268.87482  0.109530   \n",
       "2  285.00128  255.86801  288.94000  288.50170  285.11570  267.86960  0.813740   \n",
       "3  285.33386  256.09546  289.18967  288.67377  285.32043  267.93500  0.687891   \n",
       "4  284.73395  255.71437  288.62890  288.18744  284.90723  267.90747  0.797112   \n",
       "\n",
       "        BCM  Cloud_Probabilities  Lightning  \n",
       "0  0.000000             0.029264          0  \n",
       "1  0.000000             0.046814          0  \n",
       "2  0.094060             0.265362          0  \n",
       "3  0.093906             0.228131          0  \n",
       "4  0.125466             0.303975          0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets/2023-10-11.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 937500\n",
      "    Positive: 540 (0.06% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Look at class imbalance\n",
    "\n",
    "neg, pos = np.bincount(df['Lightning'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"CMI_C01\", \"CMI_C02\", \"CMI_C03\",\"CMI_C04\", \"CMI_C05\",\"CMI_C06\", \"CMI_C07\",\"CMI_C15\",\"Cloud_Probabilities\",\"Lightning\"]\n",
    "#let's just do less features\n",
    "#Predictors\n",
    "\n",
    "copy_df = df.copy()\n",
    "copy_df = copy_df[features]\n",
    "\n",
    "X = copy_df[features]\n",
    "\n",
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(copy_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Lightning'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Lightning'))\n",
    "test_labels = np.array(test_df.pop('Lightning'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class probability in training set:   0.0005\n",
      "Average class probability in validation set: 0.0006\n",
      "Average class probability in test set:       0.0007\n"
     ]
    }
   ],
   "source": [
    "#Averages are roughly similar\n",
    "\n",
    "print(f'Average class probability in training set:   {train_labels.mean():.4f}')\n",
    "print(f'Average class probability in validation set: {val_labels.mean():.4f}')\n",
    "print(f'Average class probability in test set:       {test_labels.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (600000,)\n",
      "Validation labels shape: (150000,)\n",
      "Test labels shape: (187500,)\n",
      "Training features shape: (600000, 9)\n",
      "Validation features shape: (150000, 9)\n",
      "Test features shape: (187500, 9)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommended parameters for imbalanced model\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "      keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Dense(len(features), activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    #Output layer\n",
    "    keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.FalsePositives(), tf.keras.metrics.Precision()])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 128\n",
    "BATCH_SIZE = 16384\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.4594029]\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 10)                100       \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 10)                40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 16)                176       \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501 (1.96 KB)\n",
      "Trainable params: 481 (1.88 KB)\n",
      "Non-trainable params: 20 (80.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initial_bias = np.log([pos/len(df)])\n",
    "print(initial_bias)\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:50:43.387027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:50:45.884890: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 340ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00041134],\n",
       "       [0.00034539],\n",
       "       [0.00069391],\n",
       "       [0.00034064],\n",
       "       [0.00145828],\n",
       "       [0.00058739],\n",
       "       [0.00116875],\n",
       "       [0.00042583],\n",
       "       [0.00153909],\n",
       "       [0.00042853]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n",
    "\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model()\n",
    "# model.load_weights(initial_weights)\n",
    "# model.layers[-1].bias.assign([0.0])\n",
    "# zero_bias_history = model.fit(\n",
    "#     train_features,\n",
    "#     train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=16,\n",
    "#     validation_data=(val_features, val_labels), \n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model()\n",
    "# model.load_weights(initial_weights)\n",
    "# careful_bias_history = model.fit(\n",
    "#     train_features,\n",
    "#     train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=16,\n",
    "#     validation_data=(val_features, val_labels), \n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
    "# plot_loss(careful_bias_history, \"Careful Bias\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'precision',]\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > threshold)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(threshold))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.50\n",
      "Weight for class 1: 868.06\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:50:47.121076: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 3.7349 - false_positives_2: 29027.0000 - precision_13: 0.0019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:50:56.094060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 11s 176ms/step - loss: 3.7349 - false_positives_2: 29027.0000 - precision_13: 0.0019 - val_loss: 0.0046 - val_false_positives_2: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 2/250\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.4722 - false_positives_2: 25190.0000 - precision_13: 0.0027 - val_loss: 0.0049 - val_false_positives_2: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 3/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.5876 - false_positives_2: 25216.0000 - precision_13: 0.0022 - val_loss: 0.0058 - val_false_positives_2: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 4/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3600 - false_positives_2: 25016.0000 - precision_13: 0.0025 - val_loss: 0.0063 - val_false_positives_2: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 5/250\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.2183 - false_positives_2: 25627.0000 - precision_13: 0.0026 - val_loss: 0.0096 - val_false_positives_2: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 6/250\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 3.3390 - false_positives_2: 26556.0000 - precision_13: 0.0029 - val_loss: 0.0124 - val_false_positives_2: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 7/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.2754 - false_positives_2: 27912.0000 - precision_13: 0.0029 - val_loss: 0.0147 - val_false_positives_2: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 8/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.3870 - false_positives_2: 27275.0000 - precision_13: 0.0025 - val_loss: 0.0154 - val_false_positives_2: 0.0000e+00 - val_precision_13: 0.0000e+00\n",
      "Epoch 9/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0149 - false_positives_2: 28644.0000 - precision_13: 0.0029 - val_loss: 0.0210 - val_false_positives_2: 3.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 10/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9900 - false_positives_2: 29847.0000 - precision_13: 0.0029 - val_loss: 0.0222 - val_false_positives_2: 2.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 11/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.1549 - false_positives_2: 31347.0000 - precision_13: 0.0022 - val_loss: 0.0344 - val_false_positives_2: 613.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 12/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 3.0847 - false_positives_2: 31706.0000 - precision_13: 0.0025 - val_loss: 0.0315 - val_false_positives_2: 270.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 13/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.7466 - false_positives_2: 30362.0000 - precision_13: 0.0028 - val_loss: 0.0272 - val_false_positives_2: 38.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 14/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.8115 - false_positives_2: 30047.0000 - precision_13: 0.0031 - val_loss: 0.0266 - val_false_positives_2: 31.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 15/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.4229 - false_positives_2: 29990.0000 - precision_13: 0.0035 - val_loss: 0.0420 - val_false_positives_2: 1694.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 16/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.9419 - false_positives_2: 30850.0000 - precision_13: 0.0024 - val_loss: 0.0448 - val_false_positives_2: 2117.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 17/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.6735 - false_positives_2: 30023.0000 - precision_13: 0.0033 - val_loss: 0.0312 - val_false_positives_2: 187.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 18/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.5720 - false_positives_2: 29296.0000 - precision_13: 0.0026 - val_loss: 0.0371 - val_false_positives_2: 706.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 19/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.6098 - false_positives_2: 30312.0000 - precision_13: 0.0031 - val_loss: 0.0372 - val_false_positives_2: 675.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 20/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4991 - false_positives_2: 30443.0000 - precision_13: 0.0027 - val_loss: 0.0371 - val_false_positives_2: 622.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 21/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.4581 - false_positives_2: 29752.0000 - precision_13: 0.0030 - val_loss: 0.0359 - val_false_positives_2: 380.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 22/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.3062 - false_positives_2: 30023.0000 - precision_13: 0.0030 - val_loss: 0.0434 - val_false_positives_2: 1515.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 23/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.3407 - false_positives_2: 29971.0000 - precision_13: 0.0033 - val_loss: 0.0359 - val_false_positives_2: 367.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 24/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.1722 - false_positives_2: 29550.0000 - precision_13: 0.0030 - val_loss: 0.0348 - val_false_positives_2: 226.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 25/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.9804 - false_positives_2: 29779.0000 - precision_13: 0.0034 - val_loss: 0.0366 - val_false_positives_2: 298.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 26/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.2298 - false_positives_2: 30024.0000 - precision_13: 0.0030 - val_loss: 0.0390 - val_false_positives_2: 526.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 27/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.3029 - false_positives_2: 30626.0000 - precision_13: 0.0027 - val_loss: 0.0442 - val_false_positives_2: 1200.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 28/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0136 - false_positives_2: 31701.0000 - precision_13: 0.0030 - val_loss: 0.0494 - val_false_positives_2: 2036.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 29/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 2.0798 - false_positives_2: 31969.0000 - precision_13: 0.0031 - val_loss: 0.0470 - val_false_positives_2: 1445.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 30/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9521 - false_positives_2: 32298.0000 - precision_13: 0.0031 - val_loss: 0.0523 - val_false_positives_2: 2459.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 31/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.1428 - false_positives_2: 33271.0000 - precision_13: 0.0031 - val_loss: 0.0555 - val_false_positives_2: 3059.0000 - val_precision_13: 3.2680e-04\n",
      "Epoch 32/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 2.0004 - false_positives_2: 32985.0000 - precision_13: 0.0030 - val_loss: 0.0515 - val_false_positives_2: 2156.0000 - val_precision_13: 0.0000e+00\n",
      "Epoch 33/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9351 - false_positives_2: 33068.0000 - precision_13: 0.0032 - val_loss: 0.0641 - val_false_positives_2: 4712.0000 - val_precision_13: 0.0011\n",
      "Epoch 34/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.8190 - false_positives_2: 35567.0000 - precision_13: 0.0032 - val_loss: 0.0706 - val_false_positives_2: 5729.0000 - val_precision_13: 0.0012\n",
      "Epoch 35/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9430 - false_positives_2: 35885.0000 - precision_13: 0.0030 - val_loss: 0.0713 - val_false_positives_2: 5769.0000 - val_precision_13: 0.0012\n",
      "Epoch 36/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.8826 - false_positives_2: 35826.0000 - precision_13: 0.0030 - val_loss: 0.0716 - val_false_positives_2: 5740.0000 - val_precision_13: 0.0012\n",
      "Epoch 37/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9072 - false_positives_2: 37068.0000 - precision_13: 0.0029 - val_loss: 0.0814 - val_false_positives_2: 7055.0000 - val_precision_13: 0.0021\n",
      "Epoch 38/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.8746 - false_positives_2: 38850.0000 - precision_13: 0.0028 - val_loss: 0.0910 - val_false_positives_2: 8152.0000 - val_precision_13: 0.0024\n",
      "Epoch 39/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.8479 - false_positives_2: 38016.0000 - precision_13: 0.0028 - val_loss: 0.0751 - val_false_positives_2: 6039.0000 - val_precision_13: 0.0015\n",
      "Epoch 40/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.9419 - false_positives_2: 37940.0000 - precision_13: 0.0026 - val_loss: 0.0760 - val_false_positives_2: 6139.0000 - val_precision_13: 0.0016\n",
      "Epoch 41/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.9277 - false_positives_2: 37922.0000 - precision_13: 0.0027 - val_loss: 0.0817 - val_false_positives_2: 6925.0000 - val_precision_13: 0.0020\n",
      "Epoch 42/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.7900 - false_positives_2: 38988.0000 - precision_13: 0.0026 - val_loss: 0.0995 - val_false_positives_2: 8999.0000 - val_precision_13: 0.0032\n",
      "Epoch 43/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.7727 - false_positives_2: 40856.0000 - precision_13: 0.0027 - val_loss: 0.0979 - val_false_positives_2: 8804.0000 - val_precision_13: 0.0032\n",
      "Epoch 44/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.7015 - false_positives_2: 41258.0000 - precision_13: 0.0029 - val_loss: 0.1126 - val_false_positives_2: 10191.0000 - val_precision_13: 0.0038\n",
      "Epoch 45/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.7500 - false_positives_2: 40755.0000 - precision_13: 0.0029 - val_loss: 0.1063 - val_false_positives_2: 9651.0000 - val_precision_13: 0.0036\n",
      "Epoch 46/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.6253 - false_positives_2: 40410.0000 - precision_13: 0.0029 - val_loss: 0.0974 - val_false_positives_2: 8696.0000 - val_precision_13: 0.0032\n",
      "Epoch 47/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.6542 - false_positives_2: 39462.0000 - precision_13: 0.0030 - val_loss: 0.0887 - val_false_positives_2: 7631.0000 - val_precision_13: 0.0025\n",
      "Epoch 48/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.5664 - false_positives_2: 38436.0000 - precision_13: 0.0033 - val_loss: 0.0849 - val_false_positives_2: 7092.0000 - val_precision_13: 0.0024\n",
      "Epoch 49/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.6924 - false_positives_2: 37755.0000 - precision_13: 0.0029 - val_loss: 0.0752 - val_false_positives_2: 5355.0000 - val_precision_13: 0.0011\n",
      "Epoch 50/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.5589 - false_positives_2: 38641.0000 - precision_13: 0.0029 - val_loss: 0.0840 - val_false_positives_2: 6750.0000 - val_precision_13: 0.0022\n",
      "Epoch 51/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.5255 - false_positives_2: 40249.0000 - precision_13: 0.0030 - val_loss: 0.1104 - val_false_positives_2: 10030.0000 - val_precision_13: 0.0039\n",
      "Epoch 52/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.6080 - false_positives_2: 41891.0000 - precision_13: 0.0028 - val_loss: 0.1194 - val_false_positives_2: 10809.0000 - val_precision_13: 0.0042\n",
      "Epoch 53/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.5594 - false_positives_2: 42496.0000 - precision_13: 0.0030 - val_loss: 0.1181 - val_false_positives_2: 10710.0000 - val_precision_13: 0.0042\n",
      "Epoch 54/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.5420 - false_positives_2: 41211.0000 - precision_13: 0.0030 - val_loss: 0.0959 - val_false_positives_2: 8334.0000 - val_precision_13: 0.0031\n",
      "Epoch 55/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.5367 - false_positives_2: 40300.0000 - precision_13: 0.0027 - val_loss: 0.1136 - val_false_positives_2: 10301.0000 - val_precision_13: 0.0043\n",
      "Epoch 56/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.5316 - false_positives_2: 42804.0000 - precision_13: 0.0030 - val_loss: 0.1133 - val_false_positives_2: 10252.0000 - val_precision_13: 0.0043\n",
      "Epoch 57/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.4708 - false_positives_2: 41385.0000 - precision_13: 0.0031 - val_loss: 0.0992 - val_false_positives_2: 8574.0000 - val_precision_13: 0.0031\n",
      "Epoch 58/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.5122 - false_positives_2: 41585.0000 - precision_13: 0.0026 - val_loss: 0.1148 - val_false_positives_2: 10382.0000 - val_precision_13: 0.0043\n",
      "Epoch 59/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.5237 - false_positives_2: 43785.0000 - precision_13: 0.0027 - val_loss: 0.1381 - val_false_positives_2: 12256.0000 - val_precision_13: 0.0045\n",
      "Epoch 60/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.4788 - false_positives_2: 44802.0000 - precision_13: 0.0027 - val_loss: 0.1569 - val_false_positives_2: 13265.0000 - val_precision_13: 0.0043\n",
      "Epoch 61/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.5000 - false_positives_2: 45259.0000 - precision_13: 0.0028 - val_loss: 0.1453 - val_false_positives_2: 12646.0000 - val_precision_13: 0.0045\n",
      "Epoch 62/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.3327 - false_positives_2: 44395.0000 - precision_13: 0.0030 - val_loss: 0.1387 - val_false_positives_2: 12264.0000 - val_precision_13: 0.0045\n",
      "Epoch 63/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.4353 - false_positives_2: 43514.0000 - precision_13: 0.0029 - val_loss: 0.1247 - val_false_positives_2: 11249.0000 - val_precision_13: 0.0045\n",
      "Epoch 64/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.3734 - false_positives_2: 43356.0000 - precision_13: 0.0032 - val_loss: 0.1305 - val_false_positives_2: 11758.0000 - val_precision_13: 0.0045\n",
      "Epoch 65/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.4059 - false_positives_2: 44282.0000 - precision_13: 0.0028 - val_loss: 0.1402 - val_false_positives_2: 12493.0000 - val_precision_13: 0.0045\n",
      "Epoch 66/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.4389 - false_positives_2: 44121.0000 - precision_13: 0.0028 - val_loss: 0.1201 - val_false_positives_2: 10717.0000 - val_precision_13: 0.0046\n",
      "Epoch 67/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.5278 - false_positives_2: 42344.0000 - precision_13: 0.0024 - val_loss: 0.1295 - val_false_positives_2: 11614.0000 - val_precision_13: 0.0045\n",
      "Epoch 68/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.3472 - false_positives_2: 44066.0000 - precision_13: 0.0029 - val_loss: 0.1353 - val_false_positives_2: 12037.0000 - val_precision_13: 0.0045\n",
      "Epoch 69/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.4080 - false_positives_2: 44581.0000 - precision_13: 0.0027 - val_loss: 0.1313 - val_false_positives_2: 11696.0000 - val_precision_13: 0.0045\n",
      "Epoch 70/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.3114 - false_positives_2: 43707.0000 - precision_13: 0.0030 - val_loss: 0.1145 - val_false_positives_2: 9869.0000 - val_precision_13: 0.0042\n",
      "Epoch 71/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.3738 - false_positives_2: 42016.0000 - precision_13: 0.0028 - val_loss: 0.1049 - val_false_positives_2: 8408.0000 - val_precision_13: 0.0032\n",
      "Epoch 72/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.3177 - false_positives_2: 42144.0000 - precision_13: 0.0028 - val_loss: 0.1245 - val_false_positives_2: 10804.0000 - val_precision_13: 0.0046\n",
      "Epoch 73/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.3032 - false_positives_2: 45184.0000 - precision_13: 0.0027 - val_loss: 0.1353 - val_false_positives_2: 11785.0000 - val_precision_13: 0.0046\n",
      "Epoch 74/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.3821 - false_positives_2: 45177.0000 - precision_13: 0.0025 - val_loss: 0.1331 - val_false_positives_2: 11547.0000 - val_precision_13: 0.0045\n",
      "Epoch 75/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.2894 - false_positives_2: 46199.0000 - precision_13: 0.0028 - val_loss: 0.1444 - val_false_positives_2: 12422.0000 - val_precision_13: 0.0046\n",
      "Epoch 76/250\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 1.4061 - false_positives_2: 47009.0000 - precision_13: 0.0026 - val_loss: 0.1301 - val_false_positives_2: 11167.0000 - val_precision_13: 0.0046\n",
      "Epoch 77/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.3551 - false_positives_2: 46228.0000 - precision_13: 0.0025 - val_loss: 0.1283 - val_false_positives_2: 10889.0000 - val_precision_13: 0.0047\n",
      "Epoch 78/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.2201 - false_positives_2: 46788.0000 - precision_13: 0.0028 - val_loss: 0.1416 - val_false_positives_2: 12162.0000 - val_precision_13: 0.0045\n",
      "Epoch 79/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.3243 - false_positives_2: 48074.0000 - precision_13: 0.0023 - val_loss: 0.1628 - val_false_positives_2: 13671.0000 - val_precision_13: 0.0042\n",
      "Epoch 80/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1888 - false_positives_2: 50065.0000 - precision_13: 0.0028 - val_loss: 0.1475 - val_false_positives_2: 12605.0000 - val_precision_13: 0.0045\n",
      "Epoch 81/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.2187 - false_positives_2: 50752.0000 - precision_13: 0.0025 - val_loss: 0.1708 - val_false_positives_2: 14219.0000 - val_precision_13: 0.0041\n",
      "Epoch 82/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.3555 - false_positives_2: 50652.0000 - precision_13: 0.0024 - val_loss: 0.1584 - val_false_positives_2: 13350.0000 - val_precision_13: 0.0043\n",
      "Epoch 83/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1749 - false_positives_2: 50474.0000 - precision_13: 0.0028 - val_loss: 0.1592 - val_false_positives_2: 13337.0000 - val_precision_13: 0.0043\n",
      "Epoch 84/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.2797 - false_positives_2: 49943.0000 - precision_13: 0.0023 - val_loss: 0.1551 - val_false_positives_2: 13072.0000 - val_precision_13: 0.0043\n",
      "Epoch 85/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.3044 - false_positives_2: 50080.0000 - precision_13: 0.0025 - val_loss: 0.1404 - val_false_positives_2: 11699.0000 - val_precision_13: 0.0046\n",
      "Epoch 86/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.2524 - false_positives_2: 49368.0000 - precision_13: 0.0024 - val_loss: 0.1374 - val_false_positives_2: 11331.0000 - val_precision_13: 0.0047\n",
      "Epoch 87/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.2069 - false_positives_2: 50693.0000 - precision_13: 0.0024 - val_loss: 0.1611 - val_false_positives_2: 13384.0000 - val_precision_13: 0.0043\n",
      "Epoch 88/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.2625 - false_positives_2: 53718.0000 - precision_13: 0.0021 - val_loss: 0.1620 - val_false_positives_2: 13493.0000 - val_precision_13: 0.0043\n",
      "Epoch 89/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.2705 - false_positives_2: 54654.0000 - precision_13: 0.0022 - val_loss: 0.1886 - val_false_positives_2: 15162.0000 - val_precision_13: 0.0040\n",
      "Epoch 90/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.1823 - false_positives_2: 53419.0000 - precision_13: 0.0024 - val_loss: 0.1646 - val_false_positives_2: 13691.0000 - val_precision_13: 0.0042\n",
      "Epoch 91/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.1908 - false_positives_2: 51303.0000 - precision_13: 0.0025 - val_loss: 0.1474 - val_false_positives_2: 12206.0000 - val_precision_13: 0.0046\n",
      "Epoch 92/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0886 - false_positives_2: 52949.0000 - precision_13: 0.0025 - val_loss: 0.1628 - val_false_positives_2: 13642.0000 - val_precision_13: 0.0043\n",
      "Epoch 93/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1281 - false_positives_2: 53926.0000 - precision_13: 0.0025 - val_loss: 0.1596 - val_false_positives_2: 13326.0000 - val_precision_13: 0.0044\n",
      "Epoch 94/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1472 - false_positives_2: 55918.0000 - precision_13: 0.0024 - val_loss: 0.1742 - val_false_positives_2: 14558.0000 - val_precision_13: 0.0041\n",
      "Epoch 95/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1264 - false_positives_2: 54640.0000 - precision_13: 0.0025 - val_loss: 0.1808 - val_false_positives_2: 14955.0000 - val_precision_13: 0.0041\n",
      "Epoch 96/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0608 - false_positives_2: 54284.0000 - precision_13: 0.0025 - val_loss: 0.1770 - val_false_positives_2: 14794.0000 - val_precision_13: 0.0040\n",
      "Epoch 97/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1074 - false_positives_2: 55650.0000 - precision_13: 0.0025 - val_loss: 0.1719 - val_false_positives_2: 14535.0000 - val_precision_13: 0.0041\n",
      "Epoch 98/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0146 - false_positives_2: 53921.0000 - precision_13: 0.0030 - val_loss: 0.1690 - val_false_positives_2: 14332.0000 - val_precision_13: 0.0042\n",
      "Epoch 99/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1266 - false_positives_2: 52438.0000 - precision_13: 0.0025 - val_loss: 0.1651 - val_false_positives_2: 14019.0000 - val_precision_13: 0.0043\n",
      "Epoch 100/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.1003 - false_positives_2: 53799.0000 - precision_13: 0.0024 - val_loss: 0.1579 - val_false_positives_2: 13303.0000 - val_precision_13: 0.0044\n",
      "Epoch 101/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.0669 - false_positives_2: 53459.0000 - precision_13: 0.0025 - val_loss: 0.1707 - val_false_positives_2: 14380.0000 - val_precision_13: 0.0042\n",
      "Epoch 102/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0288 - false_positives_2: 53062.0000 - precision_13: 0.0027 - val_loss: 0.1552 - val_false_positives_2: 12966.0000 - val_precision_13: 0.0045\n",
      "Epoch 103/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0413 - false_positives_2: 53283.0000 - precision_13: 0.0027 - val_loss: 0.1611 - val_false_positives_2: 13487.0000 - val_precision_13: 0.0044\n",
      "Epoch 104/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0394 - false_positives_2: 52642.0000 - precision_13: 0.0026 - val_loss: 0.1552 - val_false_positives_2: 12890.0000 - val_precision_13: 0.0046\n",
      "Epoch 105/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9590 - false_positives_2: 54583.0000 - precision_13: 0.0027 - val_loss: 0.1643 - val_false_positives_2: 13794.0000 - val_precision_13: 0.0043\n",
      "Epoch 106/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0278 - false_positives_2: 56636.0000 - precision_13: 0.0023 - val_loss: 0.1697 - val_false_positives_2: 14167.0000 - val_precision_13: 0.0042\n",
      "Epoch 107/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9815 - false_positives_2: 57033.0000 - precision_13: 0.0025 - val_loss: 0.1754 - val_false_positives_2: 14710.0000 - val_precision_13: 0.0042\n",
      "Epoch 108/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9433 - false_positives_2: 58300.0000 - precision_13: 0.0026 - val_loss: 0.1733 - val_false_positives_2: 14491.0000 - val_precision_13: 0.0043\n",
      "Epoch 109/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9870 - false_positives_2: 57840.0000 - precision_13: 0.0024 - val_loss: 0.1730 - val_false_positives_2: 14402.0000 - val_precision_13: 0.0043\n",
      "Epoch 110/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9300 - false_positives_2: 57576.0000 - precision_13: 0.0027 - val_loss: 0.1840 - val_false_positives_2: 15161.0000 - val_precision_13: 0.0041\n",
      "Epoch 111/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0042 - false_positives_2: 59834.0000 - precision_13: 0.0022 - val_loss: 0.1834 - val_false_positives_2: 15226.0000 - val_precision_13: 0.0042\n",
      "Epoch 112/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0016 - false_positives_2: 59415.0000 - precision_13: 0.0024 - val_loss: 0.1700 - val_false_positives_2: 14123.0000 - val_precision_13: 0.0044\n",
      "Epoch 113/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9789 - false_positives_2: 59138.0000 - precision_13: 0.0024 - val_loss: 0.1939 - val_false_positives_2: 15900.0000 - val_precision_13: 0.0041\n",
      "Epoch 114/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9798 - false_positives_2: 59614.0000 - precision_13: 0.0024 - val_loss: 0.1745 - val_false_positives_2: 14470.0000 - val_precision_13: 0.0043\n",
      "Epoch 115/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 1.0012 - false_positives_2: 58148.0000 - precision_13: 0.0023 - val_loss: 0.1916 - val_false_positives_2: 15655.0000 - val_precision_13: 0.0041\n",
      "Epoch 116/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 1.0124 - false_positives_2: 58764.0000 - precision_13: 0.0023 - val_loss: 0.1817 - val_false_positives_2: 15001.0000 - val_precision_13: 0.0042\n",
      "Epoch 117/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9751 - false_positives_2: 58521.0000 - precision_13: 0.0022 - val_loss: 0.1844 - val_false_positives_2: 15273.0000 - val_precision_13: 0.0042\n",
      "Epoch 118/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.9392 - false_positives_2: 59516.0000 - precision_13: 0.0024 - val_loss: 0.1866 - val_false_positives_2: 15451.0000 - val_precision_13: 0.0041\n",
      "Epoch 119/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.9996 - false_positives_2: 59566.0000 - precision_13: 0.0023 - val_loss: 0.1791 - val_false_positives_2: 14843.0000 - val_precision_13: 0.0043\n",
      "Epoch 120/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8778 - false_positives_2: 58849.0000 - precision_13: 0.0026 - val_loss: 0.1895 - val_false_positives_2: 15798.0000 - val_precision_13: 0.0041\n",
      "Epoch 121/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.8397 - false_positives_2: 62139.0000 - precision_13: 0.0026 - val_loss: 0.2143 - val_false_positives_2: 17431.0000 - val_precision_13: 0.0041\n",
      "Epoch 122/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.9119 - false_positives_2: 64619.0000 - precision_13: 0.0024 - val_loss: 0.2070 - val_false_positives_2: 17115.0000 - val_precision_13: 0.0040\n",
      "Epoch 123/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9256 - false_positives_2: 60998.0000 - precision_13: 0.0025 - val_loss: 0.1808 - val_false_positives_2: 15190.0000 - val_precision_13: 0.0042\n",
      "Epoch 124/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7973 - false_positives_2: 59712.0000 - precision_13: 0.0027 - val_loss: 0.1979 - val_false_positives_2: 16538.0000 - val_precision_13: 0.0041\n",
      "Epoch 125/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.8638 - false_positives_2: 60245.0000 - precision_13: 0.0025 - val_loss: 0.1863 - val_false_positives_2: 15582.0000 - val_precision_13: 0.0042\n",
      "Epoch 126/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9392 - false_positives_2: 58978.0000 - precision_13: 0.0024 - val_loss: 0.1678 - val_false_positives_2: 13415.0000 - val_precision_13: 0.0045\n",
      "Epoch 127/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8720 - false_positives_2: 58713.0000 - precision_13: 0.0025 - val_loss: 0.2095 - val_false_positives_2: 16982.0000 - val_precision_13: 0.0042\n",
      "Epoch 128/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9232 - false_positives_2: 60996.0000 - precision_13: 0.0023 - val_loss: 0.1869 - val_false_positives_2: 15347.0000 - val_precision_13: 0.0042\n",
      "Epoch 129/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8949 - false_positives_2: 60069.0000 - precision_13: 0.0022 - val_loss: 0.1959 - val_false_positives_2: 16031.0000 - val_precision_13: 0.0041\n",
      "Epoch 130/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8161 - false_positives_2: 64165.0000 - precision_13: 0.0025 - val_loss: 0.2221 - val_false_positives_2: 17430.0000 - val_precision_13: 0.0042\n",
      "Epoch 131/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.9193 - false_positives_2: 61734.0000 - precision_13: 0.0024 - val_loss: 0.1999 - val_false_positives_2: 16232.0000 - val_precision_13: 0.0042\n",
      "Epoch 132/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8455 - false_positives_2: 61080.0000 - precision_13: 0.0026 - val_loss: 0.1944 - val_false_positives_2: 15893.0000 - val_precision_13: 0.0042\n",
      "Epoch 133/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.8740 - false_positives_2: 60423.0000 - precision_13: 0.0024 - val_loss: 0.1861 - val_false_positives_2: 15180.0000 - val_precision_13: 0.0042\n",
      "Epoch 134/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8395 - false_positives_2: 60327.0000 - precision_13: 0.0026 - val_loss: 0.2063 - val_false_positives_2: 16739.0000 - val_precision_13: 0.0042\n",
      "Epoch 135/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.8074 - false_positives_2: 61033.0000 - precision_13: 0.0027 - val_loss: 0.2269 - val_false_positives_2: 17957.0000 - val_precision_13: 0.0041\n",
      "Epoch 136/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8542 - false_positives_2: 61507.0000 - precision_13: 0.0024 - val_loss: 0.2072 - val_false_positives_2: 16969.0000 - val_precision_13: 0.0041\n",
      "Epoch 137/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7399 - false_positives_2: 58312.0000 - precision_13: 0.0029 - val_loss: 0.1906 - val_false_positives_2: 15649.0000 - val_precision_13: 0.0041\n",
      "Epoch 138/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8122 - false_positives_2: 60151.0000 - precision_13: 0.0025 - val_loss: 0.1939 - val_false_positives_2: 15899.0000 - val_precision_13: 0.0041\n",
      "Epoch 139/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7721 - false_positives_2: 61767.0000 - precision_13: 0.0026 - val_loss: 0.2338 - val_false_positives_2: 18329.0000 - val_precision_13: 0.0040\n",
      "Epoch 140/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8378 - false_positives_2: 62384.0000 - precision_13: 0.0024 - val_loss: 0.1967 - val_false_positives_2: 15947.0000 - val_precision_13: 0.0041\n",
      "Epoch 141/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7930 - false_positives_2: 61865.0000 - precision_13: 0.0027 - val_loss: 0.1966 - val_false_positives_2: 15801.0000 - val_precision_13: 0.0042\n",
      "Epoch 142/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.8078 - false_positives_2: 61982.0000 - precision_13: 0.0024 - val_loss: 0.1928 - val_false_positives_2: 15405.0000 - val_precision_13: 0.0042\n",
      "Epoch 143/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7758 - false_positives_2: 60121.0000 - precision_13: 0.0027 - val_loss: 0.1993 - val_false_positives_2: 16176.0000 - val_precision_13: 0.0041\n",
      "Epoch 144/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8166 - false_positives_2: 59296.0000 - precision_13: 0.0025 - val_loss: 0.2042 - val_false_positives_2: 16523.0000 - val_precision_13: 0.0042\n",
      "Epoch 145/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.8029 - false_positives_2: 67553.0000 - precision_13: 0.0022 - val_loss: 0.1966 - val_false_positives_2: 15669.0000 - val_precision_13: 0.0042\n",
      "Epoch 146/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7903 - false_positives_2: 69653.0000 - precision_13: 0.0023 - val_loss: 0.1925 - val_false_positives_2: 14985.0000 - val_precision_13: 0.0043\n",
      "Epoch 147/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7663 - false_positives_2: 72076.0000 - precision_13: 0.0022 - val_loss: 0.2219 - val_false_positives_2: 17681.0000 - val_precision_13: 0.0042\n",
      "Epoch 148/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7356 - false_positives_2: 70420.0000 - precision_13: 0.0025 - val_loss: 0.2108 - val_false_positives_2: 16909.0000 - val_precision_13: 0.0041\n",
      "Epoch 149/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7783 - false_positives_2: 71544.0000 - precision_13: 0.0023 - val_loss: 0.2239 - val_false_positives_2: 17957.0000 - val_precision_13: 0.0042\n",
      "Epoch 150/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7939 - false_positives_2: 72212.0000 - precision_13: 0.0023 - val_loss: 0.2164 - val_false_positives_2: 17455.0000 - val_precision_13: 0.0042\n",
      "Epoch 151/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7619 - false_positives_2: 69540.0000 - precision_13: 0.0024 - val_loss: 0.1883 - val_false_positives_2: 14581.0000 - val_precision_13: 0.0044\n",
      "Epoch 152/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7534 - false_positives_2: 67925.0000 - precision_13: 0.0024 - val_loss: 0.2273 - val_false_positives_2: 18140.0000 - val_precision_13: 0.0041\n",
      "Epoch 153/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7789 - false_positives_2: 70218.0000 - precision_13: 0.0022 - val_loss: 0.2030 - val_false_positives_2: 16346.0000 - val_precision_13: 0.0041\n",
      "Epoch 154/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7126 - false_positives_2: 69500.0000 - precision_13: 0.0025 - val_loss: 0.2086 - val_false_positives_2: 16818.0000 - val_precision_13: 0.0040\n",
      "Epoch 155/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7342 - false_positives_2: 71070.0000 - precision_13: 0.0024 - val_loss: 0.2085 - val_false_positives_2: 16623.0000 - val_precision_13: 0.0040\n",
      "Epoch 156/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7636 - false_positives_2: 68917.0000 - precision_13: 0.0023 - val_loss: 0.2191 - val_false_positives_2: 17365.0000 - val_precision_13: 0.0041\n",
      "Epoch 157/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7648 - false_positives_2: 70514.0000 - precision_13: 0.0023 - val_loss: 0.2162 - val_false_positives_2: 17140.0000 - val_precision_13: 0.0040\n",
      "Epoch 158/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7037 - false_positives_2: 67413.0000 - precision_13: 0.0024 - val_loss: 0.2034 - val_false_positives_2: 15888.0000 - val_precision_13: 0.0041\n",
      "Epoch 159/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7180 - false_positives_2: 71077.0000 - precision_13: 0.0024 - val_loss: 0.2049 - val_false_positives_2: 15860.0000 - val_precision_13: 0.0041\n",
      "Epoch 160/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7290 - false_positives_2: 69472.0000 - precision_13: 0.0024 - val_loss: 0.2045 - val_false_positives_2: 15743.0000 - val_precision_13: 0.0042\n",
      "Epoch 161/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6833 - false_positives_2: 69264.0000 - precision_13: 0.0025 - val_loss: 0.2125 - val_false_positives_2: 16707.0000 - val_precision_13: 0.0040\n",
      "Epoch 162/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7119 - false_positives_2: 69650.0000 - precision_13: 0.0025 - val_loss: 0.2122 - val_false_positives_2: 16556.0000 - val_precision_13: 0.0040\n",
      "Epoch 163/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7649 - false_positives_2: 68650.0000 - precision_13: 0.0021 - val_loss: 0.2069 - val_false_positives_2: 15948.0000 - val_precision_13: 0.0041\n",
      "Epoch 164/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7262 - false_positives_2: 71765.0000 - precision_13: 0.0023 - val_loss: 0.2281 - val_false_positives_2: 17489.0000 - val_precision_13: 0.0040\n",
      "Epoch 165/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6972 - false_positives_2: 70182.0000 - precision_13: 0.0024 - val_loss: 0.2137 - val_false_positives_2: 16300.0000 - val_precision_13: 0.0041\n",
      "Epoch 166/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.7026 - false_positives_2: 70501.0000 - precision_13: 0.0023 - val_loss: 0.2229 - val_false_positives_2: 16993.0000 - val_precision_13: 0.0039\n",
      "Epoch 167/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6864 - false_positives_2: 68631.0000 - precision_13: 0.0025 - val_loss: 0.2089 - val_false_positives_2: 15765.0000 - val_precision_13: 0.0041\n",
      "Epoch 168/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6960 - false_positives_2: 68934.0000 - precision_13: 0.0022 - val_loss: 0.2020 - val_false_positives_2: 14662.0000 - val_precision_13: 0.0044\n",
      "Epoch 169/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6574 - false_positives_2: 72073.0000 - precision_13: 0.0024 - val_loss: 0.2355 - val_false_positives_2: 17738.0000 - val_precision_13: 0.0039\n",
      "Epoch 170/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6970 - false_positives_2: 71674.0000 - precision_13: 0.0024 - val_loss: 0.2302 - val_false_positives_2: 17369.0000 - val_precision_13: 0.0039\n",
      "Epoch 171/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6743 - false_positives_2: 72649.0000 - precision_13: 0.0024 - val_loss: 0.2264 - val_false_positives_2: 17183.0000 - val_precision_13: 0.0039\n",
      "Epoch 172/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6699 - false_positives_2: 71950.0000 - precision_13: 0.0023 - val_loss: 0.2285 - val_false_positives_2: 17217.0000 - val_precision_13: 0.0039\n",
      "Epoch 173/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.7193 - false_positives_2: 72405.0000 - precision_13: 0.0021 - val_loss: 0.2374 - val_false_positives_2: 17742.0000 - val_precision_13: 0.0039\n",
      "Epoch 174/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6982 - false_positives_2: 72676.0000 - precision_13: 0.0024 - val_loss: 0.2370 - val_false_positives_2: 17657.0000 - val_precision_13: 0.0039\n",
      "Epoch 175/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6599 - false_positives_2: 72215.0000 - precision_13: 0.0023 - val_loss: 0.2456 - val_false_positives_2: 18235.0000 - val_precision_13: 0.0039\n",
      "Epoch 176/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6933 - false_positives_2: 71827.0000 - precision_13: 0.0022 - val_loss: 0.2437 - val_false_positives_2: 18124.0000 - val_precision_13: 0.0039\n",
      "Epoch 177/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6359 - false_positives_2: 74027.0000 - precision_13: 0.0025 - val_loss: 0.2390 - val_false_positives_2: 17598.0000 - val_precision_13: 0.0040\n",
      "Epoch 178/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6853 - false_positives_2: 72789.0000 - precision_13: 0.0022 - val_loss: 0.2157 - val_false_positives_2: 14814.0000 - val_precision_13: 0.0044\n",
      "Epoch 179/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6460 - false_positives_2: 72028.0000 - precision_13: 0.0024 - val_loss: 0.2333 - val_false_positives_2: 16966.0000 - val_precision_13: 0.0039\n",
      "Epoch 180/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6122 - false_positives_2: 70112.0000 - precision_13: 0.0026 - val_loss: 0.2350 - val_false_positives_2: 17330.0000 - val_precision_13: 0.0040\n",
      "Epoch 181/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6415 - false_positives_2: 72777.0000 - precision_13: 0.0024 - val_loss: 0.2437 - val_false_positives_2: 18011.0000 - val_precision_13: 0.0039\n",
      "Epoch 182/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6513 - false_positives_2: 71140.0000 - precision_13: 0.0024 - val_loss: 0.2420 - val_false_positives_2: 17719.0000 - val_precision_13: 0.0039\n",
      "Epoch 183/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6190 - false_positives_2: 72331.0000 - precision_13: 0.0025 - val_loss: 0.2269 - val_false_positives_2: 16230.0000 - val_precision_13: 0.0041\n",
      "Epoch 184/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6504 - false_positives_2: 68652.0000 - precision_13: 0.0024 - val_loss: 0.2598 - val_false_positives_2: 18759.0000 - val_precision_13: 0.0038\n",
      "Epoch 185/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6551 - false_positives_2: 71177.0000 - precision_13: 0.0024 - val_loss: 0.2414 - val_false_positives_2: 17501.0000 - val_precision_13: 0.0039\n",
      "Epoch 186/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6123 - false_positives_2: 71661.0000 - precision_13: 0.0025 - val_loss: 0.2418 - val_false_positives_2: 17422.0000 - val_precision_13: 0.0039\n",
      "Epoch 187/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6467 - false_positives_2: 71706.0000 - precision_13: 0.0023 - val_loss: 0.2483 - val_false_positives_2: 17792.0000 - val_precision_13: 0.0039\n",
      "Epoch 188/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6468 - false_positives_2: 71968.0000 - precision_13: 0.0023 - val_loss: 0.2389 - val_false_positives_2: 16622.0000 - val_precision_13: 0.0040\n",
      "Epoch 189/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5929 - false_positives_2: 70978.0000 - precision_13: 0.0026 - val_loss: 0.2269 - val_false_positives_2: 15974.0000 - val_precision_13: 0.0041\n",
      "Epoch 190/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6195 - false_positives_2: 70129.0000 - precision_13: 0.0026 - val_loss: 0.2291 - val_false_positives_2: 16290.0000 - val_precision_13: 0.0040\n",
      "Epoch 191/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6442 - false_positives_2: 70976.0000 - precision_13: 0.0025 - val_loss: 0.2553 - val_false_positives_2: 18124.0000 - val_precision_13: 0.0038\n",
      "Epoch 192/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6131 - false_positives_2: 69381.0000 - precision_13: 0.0026 - val_loss: 0.2304 - val_false_positives_2: 16188.0000 - val_precision_13: 0.0041\n",
      "Epoch 193/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6320 - false_positives_2: 69233.0000 - precision_13: 0.0025 - val_loss: 0.2499 - val_false_positives_2: 17880.0000 - val_precision_13: 0.0038\n",
      "Epoch 194/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6129 - false_positives_2: 70545.0000 - precision_13: 0.0025 - val_loss: 0.2575 - val_false_positives_2: 18216.0000 - val_precision_13: 0.0038\n",
      "Epoch 195/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.6138 - false_positives_2: 70468.0000 - precision_13: 0.0026 - val_loss: 0.2565 - val_false_positives_2: 18078.0000 - val_precision_13: 0.0038\n",
      "Epoch 196/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6435 - false_positives_2: 69644.0000 - precision_13: 0.0022 - val_loss: 0.2314 - val_false_positives_2: 15663.0000 - val_precision_13: 0.0042\n",
      "Epoch 197/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5652 - false_positives_2: 71646.0000 - precision_13: 0.0026 - val_loss: 0.2771 - val_false_positives_2: 19330.0000 - val_precision_13: 0.0039\n",
      "Epoch 198/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5987 - false_positives_2: 74143.0000 - precision_13: 0.0024 - val_loss: 0.2837 - val_false_positives_2: 19550.0000 - val_precision_13: 0.0039\n",
      "Epoch 199/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5857 - false_positives_2: 74802.0000 - precision_13: 0.0025 - val_loss: 0.2648 - val_false_positives_2: 18473.0000 - val_precision_13: 0.0038\n",
      "Epoch 200/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5904 - false_positives_2: 73844.0000 - precision_13: 0.0025 - val_loss: 0.2601 - val_false_positives_2: 18095.0000 - val_precision_13: 0.0039\n",
      "Epoch 201/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5818 - false_positives_2: 71299.0000 - precision_13: 0.0025 - val_loss: 0.2420 - val_false_positives_2: 16601.0000 - val_precision_13: 0.0040\n",
      "Epoch 202/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5990 - false_positives_2: 70991.0000 - precision_13: 0.0025 - val_loss: 0.2570 - val_false_positives_2: 17930.0000 - val_precision_13: 0.0039\n",
      "Epoch 203/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5534 - false_positives_2: 71267.0000 - precision_13: 0.0027 - val_loss: 0.2462 - val_false_positives_2: 16801.0000 - val_precision_13: 0.0040\n",
      "Epoch 204/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6381 - false_positives_2: 70921.0000 - precision_13: 0.0023 - val_loss: 0.2436 - val_false_positives_2: 16577.0000 - val_precision_13: 0.0040\n",
      "Epoch 205/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5894 - false_positives_2: 69445.0000 - precision_13: 0.0025 - val_loss: 0.2368 - val_false_positives_2: 15567.0000 - val_precision_13: 0.0043\n",
      "Epoch 206/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5753 - false_positives_2: 68453.0000 - precision_13: 0.0026 - val_loss: 0.2540 - val_false_positives_2: 17694.0000 - val_precision_13: 0.0039\n",
      "Epoch 207/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.6027 - false_positives_2: 71681.0000 - precision_13: 0.0025 - val_loss: 0.2453 - val_false_positives_2: 16461.0000 - val_precision_13: 0.0041\n",
      "Epoch 208/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5926 - false_positives_2: 70440.0000 - precision_13: 0.0024 - val_loss: 0.2579 - val_false_positives_2: 17728.0000 - val_precision_13: 0.0039\n",
      "Epoch 209/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5923 - false_positives_2: 71107.0000 - precision_13: 0.0025 - val_loss: 0.2677 - val_false_positives_2: 18018.0000 - val_precision_13: 0.0039\n",
      "Epoch 210/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5796 - false_positives_2: 70461.0000 - precision_13: 0.0027 - val_loss: 0.2601 - val_false_positives_2: 17826.0000 - val_precision_13: 0.0039\n",
      "Epoch 211/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5568 - false_positives_2: 69486.0000 - precision_13: 0.0025 - val_loss: 0.2601 - val_false_positives_2: 17574.0000 - val_precision_13: 0.0039\n",
      "Epoch 212/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5969 - false_positives_2: 70698.0000 - precision_13: 0.0025 - val_loss: 0.2561 - val_false_positives_2: 17060.0000 - val_precision_13: 0.0040\n",
      "Epoch 213/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5657 - false_positives_2: 69100.0000 - precision_13: 0.0026 - val_loss: 0.2609 - val_false_positives_2: 17800.0000 - val_precision_13: 0.0039\n",
      "Epoch 214/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5784 - false_positives_2: 68724.0000 - precision_13: 0.0026 - val_loss: 0.2529 - val_false_positives_2: 16539.0000 - val_precision_13: 0.0040\n",
      "Epoch 215/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5472 - false_positives_2: 69752.0000 - precision_13: 0.0028 - val_loss: 0.2670 - val_false_positives_2: 18083.0000 - val_precision_13: 0.0039\n",
      "Epoch 216/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5605 - false_positives_2: 69845.0000 - precision_13: 0.0026 - val_loss: 0.2414 - val_false_positives_2: 14889.0000 - val_precision_13: 0.0044\n",
      "Epoch 217/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5665 - false_positives_2: 67272.0000 - precision_13: 0.0026 - val_loss: 0.2698 - val_false_positives_2: 17988.0000 - val_precision_13: 0.0039\n",
      "Epoch 218/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5566 - false_positives_2: 69503.0000 - precision_13: 0.0026 - val_loss: 0.2597 - val_false_positives_2: 16793.0000 - val_precision_13: 0.0040\n",
      "Epoch 219/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5564 - false_positives_2: 69256.0000 - precision_13: 0.0027 - val_loss: 0.2750 - val_false_positives_2: 18277.0000 - val_precision_13: 0.0038\n",
      "Epoch 220/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5427 - false_positives_2: 70907.0000 - precision_13: 0.0027 - val_loss: 0.2694 - val_false_positives_2: 17562.0000 - val_precision_13: 0.0039\n",
      "Epoch 221/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5678 - false_positives_2: 68427.0000 - precision_13: 0.0026 - val_loss: 0.2530 - val_false_positives_2: 16501.0000 - val_precision_13: 0.0040\n",
      "Epoch 222/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5647 - false_positives_2: 68758.0000 - precision_13: 0.0025 - val_loss: 0.2658 - val_false_positives_2: 17167.0000 - val_precision_13: 0.0039\n",
      "Epoch 223/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5209 - false_positives_2: 70322.0000 - precision_13: 0.0029 - val_loss: 0.2698 - val_false_positives_2: 17919.0000 - val_precision_13: 0.0038\n",
      "Epoch 224/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5748 - false_positives_2: 70642.0000 - precision_13: 0.0024 - val_loss: 0.2622 - val_false_positives_2: 16823.0000 - val_precision_13: 0.0040\n",
      "Epoch 225/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5696 - false_positives_2: 70544.0000 - precision_13: 0.0025 - val_loss: 0.2650 - val_false_positives_2: 16411.0000 - val_precision_13: 0.0041\n",
      "Epoch 226/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5428 - false_positives_2: 67536.0000 - precision_13: 0.0028 - val_loss: 0.2868 - val_false_positives_2: 18842.0000 - val_precision_13: 0.0037\n",
      "Epoch 227/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5489 - false_positives_2: 68995.0000 - precision_13: 0.0027 - val_loss: 0.2795 - val_false_positives_2: 17806.0000 - val_precision_13: 0.0039\n",
      "Epoch 228/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5151 - false_positives_2: 69891.0000 - precision_13: 0.0027 - val_loss: 0.2854 - val_false_positives_2: 18223.0000 - val_precision_13: 0.0038\n",
      "Epoch 229/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5558 - false_positives_2: 69067.0000 - precision_13: 0.0026 - val_loss: 0.2776 - val_false_positives_2: 17673.0000 - val_precision_13: 0.0039\n",
      "Epoch 230/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5455 - false_positives_2: 68414.0000 - precision_13: 0.0027 - val_loss: 0.2748 - val_false_positives_2: 17803.0000 - val_precision_13: 0.0039\n",
      "Epoch 231/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5194 - false_positives_2: 68458.0000 - precision_13: 0.0027 - val_loss: 0.2911 - val_false_positives_2: 18531.0000 - val_precision_13: 0.0038\n",
      "Epoch 232/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5521 - false_positives_2: 71678.0000 - precision_13: 0.0027 - val_loss: 0.2838 - val_false_positives_2: 17259.0000 - val_precision_13: 0.0040\n",
      "Epoch 233/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5592 - false_positives_2: 66496.0000 - precision_13: 0.0026 - val_loss: 0.2760 - val_false_positives_2: 17344.0000 - val_precision_13: 0.0040\n",
      "Epoch 234/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5535 - false_positives_2: 68550.0000 - precision_13: 0.0026 - val_loss: 0.2892 - val_false_positives_2: 17767.0000 - val_precision_13: 0.0039\n",
      "Epoch 235/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5421 - false_positives_2: 70322.0000 - precision_13: 0.0027 - val_loss: 0.3036 - val_false_positives_2: 18458.0000 - val_precision_13: 0.0038\n",
      "Epoch 236/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5334 - false_positives_2: 70422.0000 - precision_13: 0.0026 - val_loss: 0.3077 - val_false_positives_2: 19046.0000 - val_precision_13: 0.0037\n",
      "Epoch 237/250\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5383 - false_positives_2: 72127.0000 - precision_13: 0.0028 - val_loss: 0.3165 - val_false_positives_2: 19451.0000 - val_precision_13: 0.0036\n",
      "Epoch 238/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5438 - false_positives_2: 69422.0000 - precision_13: 0.0025 - val_loss: 0.2968 - val_false_positives_2: 17670.0000 - val_precision_13: 0.0039\n",
      "Epoch 239/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5043 - false_positives_2: 70665.0000 - precision_13: 0.0030 - val_loss: 0.3194 - val_false_positives_2: 19852.0000 - val_precision_13: 0.0037\n",
      "Epoch 240/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5406 - false_positives_2: 72177.0000 - precision_13: 0.0026 - val_loss: 0.3143 - val_false_positives_2: 19370.0000 - val_precision_13: 0.0036\n",
      "Epoch 241/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5079 - false_positives_2: 71314.0000 - precision_13: 0.0028 - val_loss: 0.2997 - val_false_positives_2: 18191.0000 - val_precision_13: 0.0038\n",
      "Epoch 242/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5392 - false_positives_2: 70777.0000 - precision_13: 0.0026 - val_loss: 0.2972 - val_false_positives_2: 18213.0000 - val_precision_13: 0.0038\n",
      "Epoch 243/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5367 - false_positives_2: 69072.0000 - precision_13: 0.0027 - val_loss: 0.3022 - val_false_positives_2: 18902.0000 - val_precision_13: 0.0037\n",
      "Epoch 244/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5520 - false_positives_2: 70137.0000 - precision_13: 0.0027 - val_loss: 0.2873 - val_false_positives_2: 17697.0000 - val_precision_13: 0.0039\n",
      "Epoch 245/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5420 - false_positives_2: 66608.0000 - precision_13: 0.0026 - val_loss: 0.3181 - val_false_positives_2: 19630.0000 - val_precision_13: 0.0036\n",
      "Epoch 246/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5185 - false_positives_2: 72503.0000 - precision_13: 0.0025 - val_loss: 0.3155 - val_false_positives_2: 18786.0000 - val_precision_13: 0.0037\n",
      "Epoch 247/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5237 - false_positives_2: 72035.0000 - precision_13: 0.0027 - val_loss: 0.3163 - val_false_positives_2: 19182.0000 - val_precision_13: 0.0037\n",
      "Epoch 248/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5338 - false_positives_2: 71234.0000 - precision_13: 0.0028 - val_loss: 0.3159 - val_false_positives_2: 19303.0000 - val_precision_13: 0.0036\n",
      "Epoch 249/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5286 - false_positives_2: 71391.0000 - precision_13: 0.0028 - val_loss: 0.3113 - val_false_positives_2: 17841.0000 - val_precision_13: 0.0039\n",
      "Epoch 250/250\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.5100 - false_positives_2: 67724.0000 - precision_13: 0.0029 - val_loss: 0.3075 - val_false_positives_2: 18794.0000 - val_precision_13: 0.0037\n"
     ]
    }
   ],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "EPOCHS = 250\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:53:31.582196: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 6ms/step\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3072 - false_positives_2: 23447.0000 - precision_13: 0.0043\n",
      "loss :  0.30719923973083496\n",
      "false_positives_2 :  23447.0\n",
      "precision_13 :  0.004289111588150263\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  186059\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  1315\n",
      "Fraudulent Transactions Missed (False Negatives):  111\n",
      "Fraudulent Transactions Detected (True Positives):  15\n",
      "Total Fraudulent Transactions:  126\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
    "                                           batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_weighted,threshold=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mac",
   "language": "python",
   "name": "tf_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
