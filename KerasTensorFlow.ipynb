{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.layers import Flatten\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>nearest_time</th>\n",
       "      <th>lightning</th>\n",
       "      <th>CMI_C01</th>\n",
       "      <th>CMI_C02</th>\n",
       "      <th>CMI_C03</th>\n",
       "      <th>CMI_C04</th>\n",
       "      <th>CMI_C05</th>\n",
       "      <th>CMI_C06</th>\n",
       "      <th>...</th>\n",
       "      <th>CMI_C15</th>\n",
       "      <th>CMI_C16</th>\n",
       "      <th>ACM</th>\n",
       "      <th>BCM</th>\n",
       "      <th>Cloud_Probabilities</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th>time_int</th>\n",
       "      <th>Lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(40.13103323474366, -93.38155072424266)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481706</td>\n",
       "      <td>0.431289</td>\n",
       "      <td>0.579424</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.478710</td>\n",
       "      <td>0.376825</td>\n",
       "      <td>...</td>\n",
       "      <td>274.17140</td>\n",
       "      <td>263.11536</td>\n",
       "      <td>2.156176</td>\n",
       "      <td>0.937424</td>\n",
       "      <td>0.762866</td>\n",
       "      <td>40.131033</td>\n",
       "      <td>-93.381551</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(40.12698592712501, -93.2741436595977)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365158</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.495337</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.376627</td>\n",
       "      <td>0.285793</td>\n",
       "      <td>...</td>\n",
       "      <td>274.72607</td>\n",
       "      <td>263.44934</td>\n",
       "      <td>1.843675</td>\n",
       "      <td>0.843675</td>\n",
       "      <td>0.530524</td>\n",
       "      <td>40.126986</td>\n",
       "      <td>-93.274144</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(40.122965705716815, -93.16685328500078)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318968</td>\n",
       "      <td>0.255297</td>\n",
       "      <td>0.471785</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.333135</td>\n",
       "      <td>0.245873</td>\n",
       "      <td>...</td>\n",
       "      <td>274.57343</td>\n",
       "      <td>263.16013</td>\n",
       "      <td>1.874843</td>\n",
       "      <td>0.812655</td>\n",
       "      <td>0.615035</td>\n",
       "      <td>40.122966</td>\n",
       "      <td>-93.166853</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(40.11897247748837, -93.05967862352706)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310932</td>\n",
       "      <td>0.245516</td>\n",
       "      <td>0.473551</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.323313</td>\n",
       "      <td>0.240774</td>\n",
       "      <td>...</td>\n",
       "      <td>272.76428</td>\n",
       "      <td>261.35620</td>\n",
       "      <td>2.905629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980994</td>\n",
       "      <td>40.118972</td>\n",
       "      <td>-93.059679</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(40.115006150366405, -92.95261870531907)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.373254</td>\n",
       "      <td>0.310456</td>\n",
       "      <td>0.511190</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>0.365952</td>\n",
       "      <td>0.287559</td>\n",
       "      <td>...</td>\n",
       "      <td>265.78076</td>\n",
       "      <td>255.51756</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999029</td>\n",
       "      <td>40.115006</td>\n",
       "      <td>-92.952619</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               Coordinates nearest_time  \\\n",
       "0           0   (40.13103323474366, -93.38155072424266)            0   \n",
       "1           1    (40.12698592712501, -93.2741436595977)            0   \n",
       "2           2  (40.122965705716815, -93.16685328500078)            0   \n",
       "3           3   (40.11897247748837, -93.05967862352706)            0   \n",
       "4           4  (40.115006150366405, -92.95261870531907)            0   \n",
       "\n",
       "   lightning   CMI_C01   CMI_C02   CMI_C03   CMI_C04   CMI_C05   CMI_C06  ...  \\\n",
       "0        0.0  0.481706  0.431289  0.579424  0.002143  0.478710  0.376825  ...   \n",
       "1        0.0  0.365158  0.305932  0.495337  0.002024  0.376627  0.285793  ...   \n",
       "2        0.0  0.318968  0.255297  0.471785  0.003135  0.333135  0.245873  ...   \n",
       "3        0.0  0.310932  0.245516  0.473551  0.006746  0.323313  0.240774  ...   \n",
       "4        0.0  0.373254  0.310456  0.511190  0.020992  0.365952  0.287559  ...   \n",
       "\n",
       "     CMI_C15    CMI_C16       ACM       BCM  Cloud_Probabilities        lat  \\\n",
       "0  274.17140  263.11536  2.156176  0.937424             0.762866  40.131033   \n",
       "1  274.72607  263.44934  1.843675  0.843675             0.530524  40.126986   \n",
       "2  274.57343  263.16013  1.874843  0.812655             0.615035  40.122966   \n",
       "3  272.76428  261.35620  2.905629  1.000000             0.980994  40.118972   \n",
       "4  265.78076  255.51756  3.000000  1.000000             0.999029  40.115006   \n",
       "\n",
       "         lon                           time             time_int  Lightning  \n",
       "0 -93.381551  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "1 -93.274144  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "2 -93.166853  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "3 -93.059679  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "4 -92.952619  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/robbiefeldstein/Documents/Programming/Research/Datasets/group_May_22.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 78125\n",
      "    Positive: 2673 (3.42% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Look at class imbalance\n",
    "\n",
    "neg, pos = np.bincount(df['Lightning'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"CMI_C01\", \"CMI_C02\", \"CMI_C03\",\"CMI_C04\", \"CMI_C05\",\"CMI_C06\", \"CMI_C07\",\"CMI_C15\",\"Cloud_Probabilities\",\"Lightning\"]\n",
    "#let's just do less features\n",
    "#Predictors\n",
    "\n",
    "copy_df = df.copy()\n",
    "copy_df = copy_df[features]\n",
    "\n",
    "X = copy_df[features]\n",
    "\n",
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(copy_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Lightning'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Lightning'))\n",
    "test_labels = np.array(test_df.pop('Lightning'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class probability in training set:   0.0341\n",
      "Average class probability in validation set: 0.0347\n",
      "Average class probability in test set:       0.0342\n"
     ]
    }
   ],
   "source": [
    "#Averages are roughly similar\n",
    "\n",
    "print(f'Average class probability in training set:   {train_labels.mean():.4f}')\n",
    "print(f'Average class probability in validation set: {val_labels.mean():.4f}')\n",
    "print(f'Average class probability in test set:       {test_labels.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (50000,)\n",
      "Validation labels shape: (12500,)\n",
      "Test labels shape: (15625,)\n",
      "Training features shape: (50000, 9)\n",
      "Validation features shape: (12500, 9)\n",
      "Test features shape: (15625, 9)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommended parameters for imbalanced model\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "      keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Dense(len(features), activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    #Output layer\n",
    "    keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 128\n",
    "BATCH_SIZE = 16384\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.37510867]\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 10)                100       \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 10)                40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 16)                176       \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501 (1.96 KB)\n",
      "Trainable params: 481 (1.88 KB)\n",
      "Non-trainable params: 20 (80.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initial_bias = np.log([pos/len(df)])\n",
    "print(initial_bias)\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:23:15.397842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:23:17.870140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 301ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08872552],\n",
       "       [0.04310598],\n",
       "       [0.05035729],\n",
       "       [0.02392522],\n",
       "       [0.01058494],\n",
       "       [0.01598056],\n",
       "       [0.01143484],\n",
       "       [0.05784532],\n",
       "       [0.04771417],\n",
       "       [0.04257099]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n",
    "\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model()\n",
    "# model.load_weights(initial_weights)\n",
    "# model.layers[-1].bias.assign([0.0])\n",
    "# zero_bias_history = model.fit(\n",
    "#     train_features,\n",
    "#     train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=16,\n",
    "#     validation_data=(val_features, val_labels), \n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model()\n",
    "# model.load_weights(initial_weights)\n",
    "# careful_bias_history = model.fit(\n",
    "#     train_features,\n",
    "#     train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=16,\n",
    "#     validation_data=(val_features, val_labels), \n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
    "# plot_loss(careful_bias_history, \"Careful Bias\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'precision',]\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > threshold)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(threshold))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.52\n",
      "Weight for class 1: 14.61\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:23:19.132123: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 2.2477 - precision_8: 0.0448 - recall_5: 0.1373 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:23:26.876312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 9s 2s/step - loss: 2.2477 - precision_8: 0.0448 - recall_5: 0.1373 - val_loss: 0.1482 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.1138 - precision_8: 0.0514 - recall_5: 0.1590 - val_loss: 0.1427 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.0229 - precision_8: 0.0511 - recall_5: 0.1590 - val_loss: 0.1390 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9701 - precision_8: 0.0496 - recall_5: 0.1573 - val_loss: 0.1361 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.9396 - precision_8: 0.0562 - recall_5: 0.1778 - val_loss: 0.1340 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.8237 - precision_8: 0.0597 - recall_5: 0.1901 - val_loss: 0.1325 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.9115 - precision_8: 0.0544 - recall_5: 0.1761 - val_loss: 0.1312 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8116 - precision_8: 0.0595 - recall_5: 0.1937 - val_loss: 0.1304 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.8070 - precision_8: 0.0541 - recall_5: 0.1755 - val_loss: 0.1301 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7717 - precision_8: 0.0547 - recall_5: 0.1778 - val_loss: 0.1302 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.7352 - precision_8: 0.0588 - recall_5: 0.1937 - val_loss: 0.1304 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6925 - precision_8: 0.0624 - recall_5: 0.2113 - val_loss: 0.1310 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6978 - precision_8: 0.0590 - recall_5: 0.2013 - val_loss: 0.1318 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6767 - precision_8: 0.0641 - recall_5: 0.2201 - val_loss: 0.1330 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.7215 - precision_8: 0.0567 - recall_5: 0.1972 - val_loss: 0.1343 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6555 - precision_8: 0.0598 - recall_5: 0.2095 - val_loss: 0.1359 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.7083 - precision_8: 0.0649 - recall_5: 0.2295 - val_loss: 0.1375 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6388 - precision_8: 0.0611 - recall_5: 0.2183 - val_loss: 0.1390 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.7032 - precision_8: 0.0605 - recall_5: 0.2177 - val_loss: 0.1406 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.6635 - precision_8: 0.0613 - recall_5: 0.2224 - val_loss: 0.1424 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6967 - precision_8: 0.0610 - recall_5: 0.2254 - val_loss: 0.1443 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6574 - precision_8: 0.0599 - recall_5: 0.2224 - val_loss: 0.1462 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6749 - precision_8: 0.0577 - recall_5: 0.2154 - val_loss: 0.1480 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6462 - precision_8: 0.0638 - recall_5: 0.2406 - val_loss: 0.1497 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6488 - precision_8: 0.0609 - recall_5: 0.2289 - val_loss: 0.1509 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6366 - precision_8: 0.0640 - recall_5: 0.2383 - val_loss: 0.1521 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6430 - precision_8: 0.0589 - recall_5: 0.2230 - val_loss: 0.1537 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6298 - precision_8: 0.0645 - recall_5: 0.2435 - val_loss: 0.1555 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.6555 - precision_8: 0.0609 - recall_5: 0.2306 - val_loss: 0.1574 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.5991 - precision_8: 0.0642 - recall_5: 0.2459 - val_loss: 0.1594 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.6533 - precision_8: 0.0623 - recall_5: 0.2412 - val_loss: 0.1609 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6080 - precision_8: 0.0621 - recall_5: 0.2388 - val_loss: 0.1627 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6013 - precision_8: 0.0631 - recall_5: 0.2453 - val_loss: 0.1646 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6280 - precision_8: 0.0609 - recall_5: 0.2383 - val_loss: 0.1664 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6515 - precision_8: 0.0583 - recall_5: 0.2271 - val_loss: 0.1682 - val_precision_8: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5980 - precision_8: 0.0615 - recall_5: 0.2406 - val_loss: 0.1701 - val_precision_8: 0.1538 - val_recall_5: 0.0046\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6145 - precision_8: 0.0631 - recall_5: 0.2482 - val_loss: 0.1715 - val_precision_8: 0.1176 - val_recall_5: 0.0046\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6069 - precision_8: 0.0596 - recall_5: 0.2347 - val_loss: 0.1727 - val_precision_8: 0.2963 - val_recall_5: 0.0184\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.5554 - precision_8: 0.0661 - recall_5: 0.2582 - val_loss: 0.1743 - val_precision_8: 0.2381 - val_recall_5: 0.0230\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6228 - precision_8: 0.0583 - recall_5: 0.2347 - val_loss: 0.1767 - val_precision_8: 0.2609 - val_recall_5: 0.0415\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.5269 - precision_8: 0.0671 - recall_5: 0.2705 - val_loss: 0.1787 - val_precision_8: 0.2340 - val_recall_5: 0.0507\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.5905 - precision_8: 0.0592 - recall_5: 0.2365 - val_loss: 0.1797 - val_precision_8: 0.2277 - val_recall_5: 0.0530\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.5554 - precision_8: 0.0628 - recall_5: 0.2482 - val_loss: 0.1809 - val_precision_8: 0.2000 - val_recall_5: 0.0553\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5522 - precision_8: 0.0641 - recall_5: 0.2576 - val_loss: 0.1823 - val_precision_8: 0.1753 - val_recall_5: 0.0622\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5681 - precision_8: 0.0598 - recall_5: 0.2383 - val_loss: 0.1842 - val_precision_8: 0.2139 - val_recall_5: 0.0922\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5365 - precision_8: 0.0649 - recall_5: 0.2623 - val_loss: 0.1875 - val_precision_8: 0.2222 - val_recall_5: 0.1429\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.5252 - precision_8: 0.0632 - recall_5: 0.2570 - val_loss: 0.1906 - val_precision_8: 0.2285 - val_recall_5: 0.1959\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5649 - precision_8: 0.0605 - recall_5: 0.2453 - val_loss: 0.1933 - val_precision_8: 0.2242 - val_recall_5: 0.2304\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5360 - precision_8: 0.0632 - recall_5: 0.2612 - val_loss: 0.1952 - val_precision_8: 0.2187 - val_recall_5: 0.2535\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5621 - precision_8: 0.0602 - recall_5: 0.2447 - val_loss: 0.1976 - val_precision_8: 0.2118 - val_recall_5: 0.2719\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5028 - precision_8: 0.0657 - recall_5: 0.2682 - val_loss: 0.2005 - val_precision_8: 0.2083 - val_recall_5: 0.3111\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4795 - precision_8: 0.0653 - recall_5: 0.2705 - val_loss: 0.2029 - val_precision_8: 0.2065 - val_recall_5: 0.3387\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5027 - precision_8: 0.0645 - recall_5: 0.2705 - val_loss: 0.2050 - val_precision_8: 0.2024 - val_recall_5: 0.3548\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4996 - precision_8: 0.0658 - recall_5: 0.2723 - val_loss: 0.2080 - val_precision_8: 0.1935 - val_recall_5: 0.3825\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4967 - precision_8: 0.0663 - recall_5: 0.2758 - val_loss: 0.2117 - val_precision_8: 0.1986 - val_recall_5: 0.4539\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4982 - precision_8: 0.0639 - recall_5: 0.2664 - val_loss: 0.2150 - val_precision_8: 0.2004 - val_recall_5: 0.4954\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.5142 - precision_8: 0.0615 - recall_5: 0.2617 - val_loss: 0.2180 - val_precision_8: 0.2003 - val_recall_5: 0.5346\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.5236 - precision_8: 0.0647 - recall_5: 0.2682 - val_loss: 0.2204 - val_precision_8: 0.1983 - val_recall_5: 0.5484\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.4710 - precision_8: 0.0645 - recall_5: 0.2735 - val_loss: 0.2235 - val_precision_8: 0.1971 - val_recall_5: 0.5714\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4818 - precision_8: 0.0643 - recall_5: 0.2711 - val_loss: 0.2274 - val_precision_8: 0.1923 - val_recall_5: 0.5991\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.4807 - precision_8: 0.0668 - recall_5: 0.2840 - val_loss: 0.2309 - val_precision_8: 0.1892 - val_recall_5: 0.6129\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4902 - precision_8: 0.0672 - recall_5: 0.2805 - val_loss: 0.2338 - val_precision_8: 0.1906 - val_recall_5: 0.6336\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.4777 - precision_8: 0.0629 - recall_5: 0.2658 - val_loss: 0.2364 - val_precision_8: 0.1884 - val_recall_5: 0.6452\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4567 - precision_8: 0.0707 - recall_5: 0.2987 - val_loss: 0.2386 - val_precision_8: 0.1911 - val_recall_5: 0.6705\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4373 - precision_8: 0.0681 - recall_5: 0.2905 - val_loss: 0.2405 - val_precision_8: 0.1879 - val_recall_5: 0.6705\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4161 - precision_8: 0.0709 - recall_5: 0.3034 - val_loss: 0.2424 - val_precision_8: 0.1860 - val_recall_5: 0.6751\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4345 - precision_8: 0.0665 - recall_5: 0.2823 - val_loss: 0.2445 - val_precision_8: 0.1846 - val_recall_5: 0.6797\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4357 - precision_8: 0.0654 - recall_5: 0.2788 - val_loss: 0.2469 - val_precision_8: 0.1838 - val_recall_5: 0.6935\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4278 - precision_8: 0.0655 - recall_5: 0.2770 - val_loss: 0.2496 - val_precision_8: 0.1833 - val_recall_5: 0.7028\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4167 - precision_8: 0.0690 - recall_5: 0.2887 - val_loss: 0.2512 - val_precision_8: 0.1817 - val_recall_5: 0.7074\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.4340 - precision_8: 0.0661 - recall_5: 0.2811 - val_loss: 0.2529 - val_precision_8: 0.1815 - val_recall_5: 0.7143\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.4412 - precision_8: 0.0648 - recall_5: 0.2705 - val_loss: 0.2547 - val_precision_8: 0.1806 - val_recall_5: 0.7212\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4156 - precision_8: 0.0711 - recall_5: 0.3016 - val_loss: 0.2565 - val_precision_8: 0.1788 - val_recall_5: 0.7212\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.4161 - precision_8: 0.0672 - recall_5: 0.2846 - val_loss: 0.2599 - val_precision_8: 0.1757 - val_recall_5: 0.7281\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3938 - precision_8: 0.0697 - recall_5: 0.2958 - val_loss: 0.2626 - val_precision_8: 0.1757 - val_recall_5: 0.7373\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4617 - precision_8: 0.0613 - recall_5: 0.2600 - val_loss: 0.2643 - val_precision_8: 0.1741 - val_recall_5: 0.7373\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4070 - precision_8: 0.0675 - recall_5: 0.2864 - val_loss: 0.2650 - val_precision_8: 0.1738 - val_recall_5: 0.7373\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.4018 - precision_8: 0.0693 - recall_5: 0.2940 - val_loss: 0.2652 - val_precision_8: 0.1736 - val_recall_5: 0.7373\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3768 - precision_8: 0.0683 - recall_5: 0.2911 - val_loss: 0.2657 - val_precision_8: 0.1740 - val_recall_5: 0.7396\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4032 - precision_8: 0.0663 - recall_5: 0.2782 - val_loss: 0.2662 - val_precision_8: 0.1739 - val_recall_5: 0.7396\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3543 - precision_8: 0.0709 - recall_5: 0.3011 - val_loss: 0.2666 - val_precision_8: 0.1739 - val_recall_5: 0.7396\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3605 - precision_8: 0.0686 - recall_5: 0.2893 - val_loss: 0.2669 - val_precision_8: 0.1740 - val_recall_5: 0.7396\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3781 - precision_8: 0.0680 - recall_5: 0.2876 - val_loss: 0.2679 - val_precision_8: 0.1744 - val_recall_5: 0.7442\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3533 - precision_8: 0.0692 - recall_5: 0.2946 - val_loss: 0.2687 - val_precision_8: 0.1737 - val_recall_5: 0.7442\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3634 - precision_8: 0.0686 - recall_5: 0.2928 - val_loss: 0.2697 - val_precision_8: 0.1732 - val_recall_5: 0.7442\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3358 - precision_8: 0.0686 - recall_5: 0.2911 - val_loss: 0.2699 - val_precision_8: 0.1730 - val_recall_5: 0.7442\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3610 - precision_8: 0.0654 - recall_5: 0.2782 - val_loss: 0.2705 - val_precision_8: 0.1724 - val_recall_5: 0.7442\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3153 - precision_8: 0.0721 - recall_5: 0.3069 - val_loss: 0.2714 - val_precision_8: 0.1716 - val_recall_5: 0.7442\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3297 - precision_8: 0.0702 - recall_5: 0.2975 - val_loss: 0.2724 - val_precision_8: 0.1721 - val_recall_5: 0.7512\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3247 - precision_8: 0.0715 - recall_5: 0.3052 - val_loss: 0.2727 - val_precision_8: 0.1718 - val_recall_5: 0.7512\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3029 - precision_8: 0.0705 - recall_5: 0.3016 - val_loss: 0.2731 - val_precision_8: 0.1712 - val_recall_5: 0.7488\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3212 - precision_8: 0.0694 - recall_5: 0.2946 - val_loss: 0.2725 - val_precision_8: 0.1715 - val_recall_5: 0.7442\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3048 - precision_8: 0.0717 - recall_5: 0.3069 - val_loss: 0.2716 - val_precision_8: 0.1728 - val_recall_5: 0.7442\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3543 - precision_8: 0.0657 - recall_5: 0.2776 - val_loss: 0.2701 - val_precision_8: 0.1751 - val_recall_5: 0.7419\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2967 - precision_8: 0.0705 - recall_5: 0.3028 - val_loss: 0.2702 - val_precision_8: 0.1746 - val_recall_5: 0.7396\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2944 - precision_8: 0.0688 - recall_5: 0.2911 - val_loss: 0.2711 - val_precision_8: 0.1741 - val_recall_5: 0.7396\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2958 - precision_8: 0.0699 - recall_5: 0.3005 - val_loss: 0.2722 - val_precision_8: 0.1741 - val_recall_5: 0.7442\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.2901 - precision_8: 0.0711 - recall_5: 0.3028 - val_loss: 0.2731 - val_precision_8: 0.1734 - val_recall_5: 0.7442\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2972 - precision_8: 0.0669 - recall_5: 0.2858 - val_loss: 0.2736 - val_precision_8: 0.1731 - val_recall_5: 0.7442\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3066 - precision_8: 0.0680 - recall_5: 0.2893 - val_loss: 0.2728 - val_precision_8: 0.1738 - val_recall_5: 0.7419\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2907 - precision_8: 0.0699 - recall_5: 0.2923 - val_loss: 0.2705 - val_precision_8: 0.1762 - val_recall_5: 0.7373\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3176 - precision_8: 0.0669 - recall_5: 0.2852 - val_loss: 0.2698 - val_precision_8: 0.1764 - val_recall_5: 0.7304\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2890 - precision_8: 0.0674 - recall_5: 0.2876 - val_loss: 0.2715 - val_precision_8: 0.1763 - val_recall_5: 0.7373\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2972 - precision_8: 0.0675 - recall_5: 0.2881 - val_loss: 0.2722 - val_precision_8: 0.1762 - val_recall_5: 0.7373\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2610 - precision_8: 0.0688 - recall_5: 0.2905 - val_loss: 0.2729 - val_precision_8: 0.1760 - val_recall_5: 0.7373\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2781 - precision_8: 0.0688 - recall_5: 0.2946 - val_loss: 0.2728 - val_precision_8: 0.1764 - val_recall_5: 0.7373\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2598 - precision_8: 0.0701 - recall_5: 0.3016 - val_loss: 0.2716 - val_precision_8: 0.1770 - val_recall_5: 0.7327\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2547 - precision_8: 0.0725 - recall_5: 0.3087 - val_loss: 0.2704 - val_precision_8: 0.1780 - val_recall_5: 0.7281\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2558 - precision_8: 0.0680 - recall_5: 0.2940 - val_loss: 0.2690 - val_precision_8: 0.1791 - val_recall_5: 0.7235\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2610 - precision_8: 0.0677 - recall_5: 0.2905 - val_loss: 0.2676 - val_precision_8: 0.1800 - val_recall_5: 0.7166\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2440 - precision_8: 0.0719 - recall_5: 0.3058 - val_loss: 0.2670 - val_precision_8: 0.1801 - val_recall_5: 0.7143\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2396 - precision_8: 0.0707 - recall_5: 0.3028 - val_loss: 0.2663 - val_precision_8: 0.1808 - val_recall_5: 0.7097\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2393 - precision_8: 0.0707 - recall_5: 0.3022 - val_loss: 0.2655 - val_precision_8: 0.1813 - val_recall_5: 0.7051\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2599 - precision_8: 0.0659 - recall_5: 0.2805 - val_loss: 0.2656 - val_precision_8: 0.1814 - val_recall_5: 0.7051\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2265 - precision_8: 0.0731 - recall_5: 0.3116 - val_loss: 0.2669 - val_precision_8: 0.1813 - val_recall_5: 0.7097\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2140 - precision_8: 0.0707 - recall_5: 0.3022 - val_loss: 0.2691 - val_precision_8: 0.1790 - val_recall_5: 0.7143\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2422 - precision_8: 0.0666 - recall_5: 0.2858 - val_loss: 0.2706 - val_precision_8: 0.1783 - val_recall_5: 0.7189\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2268 - precision_8: 0.0691 - recall_5: 0.3016 - val_loss: 0.2712 - val_precision_8: 0.1787 - val_recall_5: 0.7235\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1978 - precision_8: 0.0727 - recall_5: 0.3110 - val_loss: 0.2710 - val_precision_8: 0.1781 - val_recall_5: 0.7189\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2202 - precision_8: 0.0718 - recall_5: 0.3063 - val_loss: 0.2716 - val_precision_8: 0.1779 - val_recall_5: 0.7212\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2177 - precision_8: 0.0696 - recall_5: 0.2975 - val_loss: 0.2720 - val_precision_8: 0.1779 - val_recall_5: 0.7235\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2610 - precision_8: 0.0657 - recall_5: 0.2799 - val_loss: 0.2722 - val_precision_8: 0.1782 - val_recall_5: 0.7281\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2261 - precision_8: 0.0679 - recall_5: 0.2893 - val_loss: 0.2720 - val_precision_8: 0.1780 - val_recall_5: 0.7281\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1961 - precision_8: 0.0747 - recall_5: 0.3134 - val_loss: 0.2720 - val_precision_8: 0.1783 - val_recall_5: 0.7304\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2081 - precision_8: 0.0693 - recall_5: 0.2934 - val_loss: 0.2730 - val_precision_8: 0.1764 - val_recall_5: 0.7304\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1893 - precision_8: 0.0728 - recall_5: 0.3011 - val_loss: 0.2731 - val_precision_8: 0.1763 - val_recall_5: 0.7304\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2090 - precision_8: 0.0679 - recall_5: 0.2817 - val_loss: 0.2732 - val_precision_8: 0.1766 - val_recall_5: 0.7304\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.2177 - precision_8: 0.0690 - recall_5: 0.2952 - val_loss: 0.2725 - val_precision_8: 0.1777 - val_recall_5: 0.7304\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1777 - precision_8: 0.0725 - recall_5: 0.3075 - val_loss: 0.2717 - val_precision_8: 0.1785 - val_recall_5: 0.7281\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.2042 - precision_8: 0.0720 - recall_5: 0.3005 - val_loss: 0.2707 - val_precision_8: 0.1787 - val_recall_5: 0.7212\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2179 - precision_8: 0.0696 - recall_5: 0.2881 - val_loss: 0.2694 - val_precision_8: 0.1795 - val_recall_5: 0.7166\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1613 - precision_8: 0.0750 - recall_5: 0.3134 - val_loss: 0.2679 - val_precision_8: 0.1808 - val_recall_5: 0.7120\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1571 - precision_8: 0.0766 - recall_5: 0.3157 - val_loss: 0.2668 - val_precision_8: 0.1799 - val_recall_5: 0.7028\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1594 - precision_8: 0.0715 - recall_5: 0.2993 - val_loss: 0.2662 - val_precision_8: 0.1799 - val_recall_5: 0.6982\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1686 - precision_8: 0.0743 - recall_5: 0.3034 - val_loss: 0.2658 - val_precision_8: 0.1801 - val_recall_5: 0.6959\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1929 - precision_8: 0.0698 - recall_5: 0.2893 - val_loss: 0.2653 - val_precision_8: 0.1811 - val_recall_5: 0.6935\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1526 - precision_8: 0.0760 - recall_5: 0.3087 - val_loss: 0.2647 - val_precision_8: 0.1823 - val_recall_5: 0.6912\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1569 - precision_8: 0.0739 - recall_5: 0.3034 - val_loss: 0.2640 - val_precision_8: 0.1841 - val_recall_5: 0.6866\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1588 - precision_8: 0.0746 - recall_5: 0.3034 - val_loss: 0.2631 - val_precision_8: 0.1845 - val_recall_5: 0.6705\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1505 - precision_8: 0.0731 - recall_5: 0.3046 - val_loss: 0.2619 - val_precision_8: 0.1847 - val_recall_5: 0.6567\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1623 - precision_8: 0.0718 - recall_5: 0.2946 - val_loss: 0.2609 - val_precision_8: 0.1847 - val_recall_5: 0.6452\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1654 - precision_8: 0.0718 - recall_5: 0.2917 - val_loss: 0.2600 - val_precision_8: 0.1869 - val_recall_5: 0.6382\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1220 - precision_8: 0.0774 - recall_5: 0.3163 - val_loss: 0.2590 - val_precision_8: 0.1870 - val_recall_5: 0.6313\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1453 - precision_8: 0.0719 - recall_5: 0.2928 - val_loss: 0.2581 - val_precision_8: 0.1899 - val_recall_5: 0.6267\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1553 - precision_8: 0.0687 - recall_5: 0.2770 - val_loss: 0.2575 - val_precision_8: 0.1908 - val_recall_5: 0.6244\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1465 - precision_8: 0.0741 - recall_5: 0.2952 - val_loss: 0.2567 - val_precision_8: 0.1899 - val_recall_5: 0.6129\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1102 - precision_8: 0.0761 - recall_5: 0.3081 - val_loss: 0.2562 - val_precision_8: 0.1890 - val_recall_5: 0.6037\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1511 - precision_8: 0.0673 - recall_5: 0.2711 - val_loss: 0.2560 - val_precision_8: 0.1880 - val_recall_5: 0.5968\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1259 - precision_8: 0.0754 - recall_5: 0.3028 - val_loss: 0.2556 - val_precision_8: 0.1874 - val_recall_5: 0.5899\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1274 - precision_8: 0.0740 - recall_5: 0.2969 - val_loss: 0.2550 - val_precision_8: 0.1889 - val_recall_5: 0.5876\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1384 - precision_8: 0.0691 - recall_5: 0.2746 - val_loss: 0.2544 - val_precision_8: 0.1887 - val_recall_5: 0.5783\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0916 - precision_8: 0.0806 - recall_5: 0.3228 - val_loss: 0.2539 - val_precision_8: 0.1914 - val_recall_5: 0.5760\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1031 - precision_8: 0.0772 - recall_5: 0.3058 - val_loss: 0.2536 - val_precision_8: 0.1910 - val_recall_5: 0.5691\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1317 - precision_8: 0.0716 - recall_5: 0.2805 - val_loss: 0.2529 - val_precision_8: 0.1904 - val_recall_5: 0.5553\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1106 - precision_8: 0.0763 - recall_5: 0.3069 - val_loss: 0.2524 - val_precision_8: 0.1897 - val_recall_5: 0.5438\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0901 - precision_8: 0.0816 - recall_5: 0.3192 - val_loss: 0.2526 - val_precision_8: 0.1898 - val_recall_5: 0.5484\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1185 - precision_8: 0.0720 - recall_5: 0.2840 - val_loss: 0.2526 - val_precision_8: 0.1903 - val_recall_5: 0.5507\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0722 - precision_8: 0.0809 - recall_5: 0.3187 - val_loss: 0.2526 - val_precision_8: 0.1904 - val_recall_5: 0.5507\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1247 - precision_8: 0.0723 - recall_5: 0.2829 - val_loss: 0.2519 - val_precision_8: 0.1918 - val_recall_5: 0.5415\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1362 - precision_8: 0.0692 - recall_5: 0.2717 - val_loss: 0.2506 - val_precision_8: 0.1931 - val_recall_5: 0.5253\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0974 - precision_8: 0.0736 - recall_5: 0.2858 - val_loss: 0.2496 - val_precision_8: 0.1937 - val_recall_5: 0.5092\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0892 - precision_8: 0.0773 - recall_5: 0.2969 - val_loss: 0.2495 - val_precision_8: 0.1951 - val_recall_5: 0.5138\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1053 - precision_8: 0.0731 - recall_5: 0.2793 - val_loss: 0.2492 - val_precision_8: 0.1952 - val_recall_5: 0.5092\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1145 - precision_8: 0.0726 - recall_5: 0.2711 - val_loss: 0.2485 - val_precision_8: 0.1938 - val_recall_5: 0.4931\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0958 - precision_8: 0.0748 - recall_5: 0.2864 - val_loss: 0.2477 - val_precision_8: 0.1978 - val_recall_5: 0.4862\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1056 - precision_8: 0.0727 - recall_5: 0.2758 - val_loss: 0.2472 - val_precision_8: 0.1979 - val_recall_5: 0.4724\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0695 - precision_8: 0.0777 - recall_5: 0.2964 - val_loss: 0.2463 - val_precision_8: 0.1970 - val_recall_5: 0.4493\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0878 - precision_8: 0.0768 - recall_5: 0.2923 - val_loss: 0.2461 - val_precision_8: 0.1963 - val_recall_5: 0.4378\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0563 - precision_8: 0.0828 - recall_5: 0.3110 - val_loss: 0.2458 - val_precision_8: 0.1964 - val_recall_5: 0.4309\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0751 - precision_8: 0.0772 - recall_5: 0.2887 - val_loss: 0.2455 - val_precision_8: 0.1989 - val_recall_5: 0.4309\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1016 - precision_8: 0.0727 - recall_5: 0.2758 - val_loss: 0.2451 - val_precision_8: 0.1982 - val_recall_5: 0.4171\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0698 - precision_8: 0.0802 - recall_5: 0.3005 - val_loss: 0.2447 - val_precision_8: 0.1978 - val_recall_5: 0.4078\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0710 - precision_8: 0.0746 - recall_5: 0.2799 - val_loss: 0.2443 - val_precision_8: 0.1986 - val_recall_5: 0.3986\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0753 - precision_8: 0.0743 - recall_5: 0.2723 - val_loss: 0.2440 - val_precision_8: 0.2009 - val_recall_5: 0.3940\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0877 - precision_8: 0.0763 - recall_5: 0.2782 - val_loss: 0.2437 - val_precision_8: 0.2022 - val_recall_5: 0.3894\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0585 - precision_8: 0.0773 - recall_5: 0.2823 - val_loss: 0.2432 - val_precision_8: 0.2015 - val_recall_5: 0.3779\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0733 - precision_8: 0.0769 - recall_5: 0.2782 - val_loss: 0.2427 - val_precision_8: 0.1990 - val_recall_5: 0.3618\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0362 - precision_8: 0.0832 - recall_5: 0.3075 - val_loss: 0.2419 - val_precision_8: 0.1987 - val_recall_5: 0.3456\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0787 - precision_8: 0.0723 - recall_5: 0.2623 - val_loss: 0.2413 - val_precision_8: 0.1928 - val_recall_5: 0.3203\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0469 - precision_8: 0.0764 - recall_5: 0.2788 - val_loss: 0.2410 - val_precision_8: 0.1955 - val_recall_5: 0.3180\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0479 - precision_8: 0.0828 - recall_5: 0.2958 - val_loss: 0.2404 - val_precision_8: 0.1955 - val_recall_5: 0.2972\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0541 - precision_8: 0.0777 - recall_5: 0.2840 - val_loss: 0.2392 - val_precision_8: 0.1966 - val_recall_5: 0.2696\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0316 - precision_8: 0.0804 - recall_5: 0.2881 - val_loss: 0.2385 - val_precision_8: 0.2004 - val_recall_5: 0.2558\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0676 - precision_8: 0.0753 - recall_5: 0.2705 - val_loss: 0.2381 - val_precision_8: 0.2008 - val_recall_5: 0.2419\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0524 - precision_8: 0.0756 - recall_5: 0.2746 - val_loss: 0.2379 - val_precision_8: 0.1988 - val_recall_5: 0.2304\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0577 - precision_8: 0.0742 - recall_5: 0.2705 - val_loss: 0.2378 - val_precision_8: 0.1975 - val_recall_5: 0.2212\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0345 - precision_8: 0.0794 - recall_5: 0.2840 - val_loss: 0.2380 - val_precision_8: 0.1936 - val_recall_5: 0.2097\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0348 - precision_8: 0.0793 - recall_5: 0.2905 - val_loss: 0.2379 - val_precision_8: 0.1890 - val_recall_5: 0.1820\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0411 - precision_8: 0.0800 - recall_5: 0.2870 - val_loss: 0.2376 - val_precision_8: 0.1958 - val_recall_5: 0.1705\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0572 - precision_8: 0.0727 - recall_5: 0.2588 - val_loss: 0.2372 - val_precision_8: 0.1970 - val_recall_5: 0.1521\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0363 - precision_8: 0.0785 - recall_5: 0.2758 - val_loss: 0.2366 - val_precision_8: 0.1802 - val_recall_5: 0.1175\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0444 - precision_8: 0.0755 - recall_5: 0.2717 - val_loss: 0.2360 - val_precision_8: 0.1837 - val_recall_5: 0.1037\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0336 - precision_8: 0.0778 - recall_5: 0.2788 - val_loss: 0.2353 - val_precision_8: 0.1827 - val_recall_5: 0.0876\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0443 - precision_8: 0.0740 - recall_5: 0.2606 - val_loss: 0.2346 - val_precision_8: 0.1813 - val_recall_5: 0.0760\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0397 - precision_8: 0.0747 - recall_5: 0.2688 - val_loss: 0.2343 - val_precision_8: 0.1852 - val_recall_5: 0.0691\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0135 - precision_8: 0.0842 - recall_5: 0.2958 - val_loss: 0.2340 - val_precision_8: 0.1921 - val_recall_5: 0.0668\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0304 - precision_8: 0.0760 - recall_5: 0.2647 - val_loss: 0.2337 - val_precision_8: 0.2086 - val_recall_5: 0.0668\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0110 - precision_8: 0.0768 - recall_5: 0.2670 - val_loss: 0.2336 - val_precision_8: 0.2090 - val_recall_5: 0.0645\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0228 - precision_8: 0.0779 - recall_5: 0.2741 - val_loss: 0.2336 - val_precision_8: 0.2137 - val_recall_5: 0.0645\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0210 - precision_8: 0.0751 - recall_5: 0.2606 - val_loss: 0.2338 - val_precision_8: 0.2154 - val_recall_5: 0.0645\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0265 - precision_8: 0.0775 - recall_5: 0.2752 - val_loss: 0.2338 - val_precision_8: 0.2171 - val_recall_5: 0.0645\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0308 - precision_8: 0.0747 - recall_5: 0.2559 - val_loss: 0.2337 - val_precision_8: 0.2231 - val_recall_5: 0.0622\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0354 - precision_8: 0.0773 - recall_5: 0.2670 - val_loss: 0.2338 - val_precision_8: 0.2308 - val_recall_5: 0.0622\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9965 - precision_8: 0.0806 - recall_5: 0.2793 - val_loss: 0.2338 - val_precision_8: 0.2301 - val_recall_5: 0.0599\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0198 - precision_8: 0.0772 - recall_5: 0.2623 - val_loss: 0.2341 - val_precision_8: 0.2301 - val_recall_5: 0.0599\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0028 - precision_8: 0.0771 - recall_5: 0.2647 - val_loss: 0.2342 - val_precision_8: 0.2342 - val_recall_5: 0.0599\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9897 - precision_8: 0.0836 - recall_5: 0.2864 - val_loss: 0.2339 - val_precision_8: 0.2474 - val_recall_5: 0.0553\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0380 - precision_8: 0.0726 - recall_5: 0.2471 - val_loss: 0.2337 - val_precision_8: 0.2360 - val_recall_5: 0.0484\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0154 - precision_8: 0.0772 - recall_5: 0.2612 - val_loss: 0.2337 - val_precision_8: 0.2317 - val_recall_5: 0.0438\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0088 - precision_8: 0.0786 - recall_5: 0.2623 - val_loss: 0.2338 - val_precision_8: 0.2125 - val_recall_5: 0.0392\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0084 - precision_8: 0.0762 - recall_5: 0.2565 - val_loss: 0.2340 - val_precision_8: 0.2152 - val_recall_5: 0.0392\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0261 - precision_8: 0.0730 - recall_5: 0.2482 - val_loss: 0.2338 - val_precision_8: 0.2206 - val_recall_5: 0.0346\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9730 - precision_8: 0.0877 - recall_5: 0.2899 - val_loss: 0.2336 - val_precision_8: 0.2143 - val_recall_5: 0.0276\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0110 - precision_8: 0.0754 - recall_5: 0.2494 - val_loss: 0.2334 - val_precision_8: 0.2245 - val_recall_5: 0.0253\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9963 - precision_8: 0.0811 - recall_5: 0.2729 - val_loss: 0.2336 - val_precision_8: 0.2093 - val_recall_5: 0.0207\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0413 - precision_8: 0.0684 - recall_5: 0.2271 - val_loss: 0.2338 - val_precision_8: 0.1795 - val_recall_5: 0.0161\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9979 - precision_8: 0.0750 - recall_5: 0.2506 - val_loss: 0.2340 - val_precision_8: 0.1622 - val_recall_5: 0.0138\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0075 - precision_8: 0.0768 - recall_5: 0.2488 - val_loss: 0.2341 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0113 - precision_8: 0.0771 - recall_5: 0.2553 - val_loss: 0.2341 - val_precision_8: 0.1515 - val_recall_5: 0.0115\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0074 - precision_8: 0.0752 - recall_5: 0.2482 - val_loss: 0.2340 - val_precision_8: 0.1786 - val_recall_5: 0.0115\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9762 - precision_8: 0.0839 - recall_5: 0.2799 - val_loss: 0.2340 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9925 - precision_8: 0.0781 - recall_5: 0.2576 - val_loss: 0.2341 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9900 - precision_8: 0.0774 - recall_5: 0.2541 - val_loss: 0.2345 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9829 - precision_8: 0.0773 - recall_5: 0.2482 - val_loss: 0.2347 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9788 - precision_8: 0.0795 - recall_5: 0.2600 - val_loss: 0.2350 - val_precision_8: 0.2000 - val_recall_5: 0.0115\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9793 - precision_8: 0.0766 - recall_5: 0.2512 - val_loss: 0.2350 - val_precision_8: 0.2174 - val_recall_5: 0.0115\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9831 - precision_8: 0.0807 - recall_5: 0.2582 - val_loss: 0.2352 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9915 - precision_8: 0.0745 - recall_5: 0.2406 - val_loss: 0.2352 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9832 - precision_8: 0.0788 - recall_5: 0.2506 - val_loss: 0.2353 - val_precision_8: 0.2105 - val_recall_5: 0.0092\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9738 - precision_8: 0.0809 - recall_5: 0.2600 - val_loss: 0.2356 - val_precision_8: 0.2222 - val_recall_5: 0.0092\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9683 - precision_8: 0.0845 - recall_5: 0.2793 - val_loss: 0.2360 - val_precision_8: 0.2222 - val_recall_5: 0.0092\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9791 - precision_8: 0.0797 - recall_5: 0.2594 - val_loss: 0.2364 - val_precision_8: 0.2222 - val_recall_5: 0.0092\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9748 - precision_8: 0.0789 - recall_5: 0.2535 - val_loss: 0.2368 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9638 - precision_8: 0.0821 - recall_5: 0.2653 - val_loss: 0.2372 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9804 - precision_8: 0.0780 - recall_5: 0.2518 - val_loss: 0.2375 - val_precision_8: 0.2222 - val_recall_5: 0.0092\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9881 - precision_8: 0.0748 - recall_5: 0.2424 - val_loss: 0.2380 - val_precision_8: 0.2222 - val_recall_5: 0.0092\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9526 - precision_8: 0.0841 - recall_5: 0.2723 - val_loss: 0.2385 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9764 - precision_8: 0.0781 - recall_5: 0.2523 - val_loss: 0.2390 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9587 - precision_8: 0.0839 - recall_5: 0.2735 - val_loss: 0.2391 - val_precision_8: 0.2222 - val_recall_5: 0.0092\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9942 - precision_8: 0.0732 - recall_5: 0.2330 - val_loss: 0.2393 - val_precision_8: 0.2353 - val_recall_5: 0.0092\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9410 - precision_8: 0.0829 - recall_5: 0.2641 - val_loss: 0.2396 - val_precision_8: 0.2353 - val_recall_5: 0.0092\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9672 - precision_8: 0.0791 - recall_5: 0.2559 - val_loss: 0.2399 - val_precision_8: 0.2857 - val_recall_5: 0.0092\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9735 - precision_8: 0.0757 - recall_5: 0.2447 - val_loss: 0.2402 - val_precision_8: 0.3000 - val_recall_5: 0.0069\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9518 - precision_8: 0.0801 - recall_5: 0.2594 - val_loss: 0.2409 - val_precision_8: 0.3000 - val_recall_5: 0.0069\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9548 - precision_8: 0.0801 - recall_5: 0.2635 - val_loss: 0.2414 - val_precision_8: 0.3000 - val_recall_5: 0.0069\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9316 - precision_8: 0.0852 - recall_5: 0.2788 - val_loss: 0.2418 - val_precision_8: 0.3000 - val_recall_5: 0.0069\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9567 - precision_8: 0.0809 - recall_5: 0.2641 - val_loss: 0.2423 - val_precision_8: 0.3000 - val_recall_5: 0.0069\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9716 - precision_8: 0.0739 - recall_5: 0.2400 - val_loss: 0.2427 - val_precision_8: 0.2727 - val_recall_5: 0.0069\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9481 - precision_8: 0.0789 - recall_5: 0.2529 - val_loss: 0.2432 - val_precision_8: 0.2222 - val_recall_5: 0.0046\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9503 - precision_8: 0.0812 - recall_5: 0.2623 - val_loss: 0.2436 - val_precision_8: 0.2222 - val_recall_5: 0.0046\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9418 - precision_8: 0.0819 - recall_5: 0.2752 - val_loss: 0.2440 - val_precision_8: 0.2000 - val_recall_5: 0.0046\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9574 - precision_8: 0.0758 - recall_5: 0.2488 - val_loss: 0.2445 - val_precision_8: 0.2500 - val_recall_5: 0.0069\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9476 - precision_8: 0.0786 - recall_5: 0.2547 - val_loss: 0.2449 - val_precision_8: 0.2308 - val_recall_5: 0.0069\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9268 - precision_8: 0.0825 - recall_5: 0.2717 - val_loss: 0.2454 - val_precision_8: 0.2667 - val_recall_5: 0.0092\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9479 - precision_8: 0.0813 - recall_5: 0.2658 - val_loss: 0.2456 - val_precision_8: 0.2667 - val_recall_5: 0.0092\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9492 - precision_8: 0.0797 - recall_5: 0.2612 - val_loss: 0.2461 - val_precision_8: 0.2105 - val_recall_5: 0.0092\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9447 - precision_8: 0.0806 - recall_5: 0.2682 - val_loss: 0.2471 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9487 - precision_8: 0.0811 - recall_5: 0.2647 - val_loss: 0.2481 - val_precision_8: 0.2273 - val_recall_5: 0.0115\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9481 - precision_8: 0.0778 - recall_5: 0.2559 - val_loss: 0.2486 - val_precision_8: 0.2000 - val_recall_5: 0.0115\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9467 - precision_8: 0.0789 - recall_5: 0.2594 - val_loss: 0.2492 - val_precision_8: 0.2000 - val_recall_5: 0.0115\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9262 - precision_8: 0.0810 - recall_5: 0.2647 - val_loss: 0.2496 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9370 - precision_8: 0.0822 - recall_5: 0.2676 - val_loss: 0.2500 - val_precision_8: 0.1852 - val_recall_5: 0.0115\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9508 - precision_8: 0.0782 - recall_5: 0.2553 - val_loss: 0.2503 - val_precision_8: 0.1786 - val_recall_5: 0.0115\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9507 - precision_8: 0.0790 - recall_5: 0.2617 - val_loss: 0.2506 - val_precision_8: 0.1786 - val_recall_5: 0.0115\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9380 - precision_8: 0.0788 - recall_5: 0.2629 - val_loss: 0.2508 - val_precision_8: 0.1852 - val_recall_5: 0.0115\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9396 - precision_8: 0.0789 - recall_5: 0.2576 - val_loss: 0.2510 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9597 - precision_8: 0.0768 - recall_5: 0.2518 - val_loss: 0.2513 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9328 - precision_8: 0.0792 - recall_5: 0.2594 - val_loss: 0.2517 - val_precision_8: 0.2000 - val_recall_5: 0.0115\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9214 - precision_8: 0.0852 - recall_5: 0.2776 - val_loss: 0.2519 - val_precision_8: 0.2000 - val_recall_5: 0.0115\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9365 - precision_8: 0.0769 - recall_5: 0.2506 - val_loss: 0.2521 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9328 - precision_8: 0.0768 - recall_5: 0.2512 - val_loss: 0.2525 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9313 - precision_8: 0.0811 - recall_5: 0.2653 - val_loss: 0.2532 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9190 - precision_8: 0.0837 - recall_5: 0.2793 - val_loss: 0.2539 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9068 - precision_8: 0.0845 - recall_5: 0.2835 - val_loss: 0.2546 - val_precision_8: 0.2273 - val_recall_5: 0.0115\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9061 - precision_8: 0.0830 - recall_5: 0.2782 - val_loss: 0.2553 - val_precision_8: 0.2000 - val_recall_5: 0.0115\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9300 - precision_8: 0.0776 - recall_5: 0.2570 - val_loss: 0.2560 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9251 - precision_8: 0.0812 - recall_5: 0.2729 - val_loss: 0.2566 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9294 - precision_8: 0.0769 - recall_5: 0.2570 - val_loss: 0.2571 - val_precision_8: 0.1724 - val_recall_5: 0.0115\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9289 - precision_8: 0.0785 - recall_5: 0.2606 - val_loss: 0.2577 - val_precision_8: 0.1613 - val_recall_5: 0.0115\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9136 - precision_8: 0.0796 - recall_5: 0.2694 - val_loss: 0.2581 - val_precision_8: 0.1667 - val_recall_5: 0.0115\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9261 - precision_8: 0.0784 - recall_5: 0.2612 - val_loss: 0.2583 - val_precision_8: 0.1724 - val_recall_5: 0.0115\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9192 - precision_8: 0.0778 - recall_5: 0.2629 - val_loss: 0.2585 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9340 - precision_8: 0.0770 - recall_5: 0.2582 - val_loss: 0.2588 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9090 - precision_8: 0.0781 - recall_5: 0.2635 - val_loss: 0.2592 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8985 - precision_8: 0.0827 - recall_5: 0.2752 - val_loss: 0.2598 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9048 - precision_8: 0.0828 - recall_5: 0.2723 - val_loss: 0.2599 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9129 - precision_8: 0.0791 - recall_5: 0.2635 - val_loss: 0.2601 - val_precision_8: 0.2174 - val_recall_5: 0.0115\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9088 - precision_8: 0.0806 - recall_5: 0.2694 - val_loss: 0.2602 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9096 - precision_8: 0.0803 - recall_5: 0.2670 - val_loss: 0.2603 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9089 - precision_8: 0.0814 - recall_5: 0.2694 - val_loss: 0.2607 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9055 - precision_8: 0.0801 - recall_5: 0.2664 - val_loss: 0.2611 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9226 - precision_8: 0.0808 - recall_5: 0.2647 - val_loss: 0.2614 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9213 - precision_8: 0.0764 - recall_5: 0.2565 - val_loss: 0.2618 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9157 - precision_8: 0.0784 - recall_5: 0.2617 - val_loss: 0.2622 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8850 - precision_8: 0.0835 - recall_5: 0.2782 - val_loss: 0.2624 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9204 - precision_8: 0.0786 - recall_5: 0.2606 - val_loss: 0.2622 - val_precision_8: 0.2222 - val_recall_5: 0.0092\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8918 - precision_8: 0.0820 - recall_5: 0.2711 - val_loss: 0.2624 - val_precision_8: 0.2667 - val_recall_5: 0.0092\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9088 - precision_8: 0.0793 - recall_5: 0.2606 - val_loss: 0.2629 - val_precision_8: 0.2667 - val_recall_5: 0.0092\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9197 - precision_8: 0.0749 - recall_5: 0.2494 - val_loss: 0.2635 - val_precision_8: 0.2500 - val_recall_5: 0.0092\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9012 - precision_8: 0.0782 - recall_5: 0.2576 - val_loss: 0.2643 - val_precision_8: 0.2105 - val_recall_5: 0.0092\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9085 - precision_8: 0.0771 - recall_5: 0.2559 - val_loss: 0.2653 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9068 - precision_8: 0.0777 - recall_5: 0.2547 - val_loss: 0.2661 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8813 - precision_8: 0.0847 - recall_5: 0.2829 - val_loss: 0.2668 - val_precision_8: 0.2273 - val_recall_5: 0.0115\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8959 - precision_8: 0.0794 - recall_5: 0.2700 - val_loss: 0.2675 - val_precision_8: 0.2000 - val_recall_5: 0.0115\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8885 - precision_8: 0.0779 - recall_5: 0.2653 - val_loss: 0.2681 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8941 - precision_8: 0.0790 - recall_5: 0.2676 - val_loss: 0.2687 - val_precision_8: 0.1724 - val_recall_5: 0.0115\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8893 - precision_8: 0.0826 - recall_5: 0.2776 - val_loss: 0.2693 - val_precision_8: 0.1613 - val_recall_5: 0.0115\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9200 - precision_8: 0.0713 - recall_5: 0.2441 - val_loss: 0.2699 - val_precision_8: 0.1875 - val_recall_5: 0.0138\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8897 - precision_8: 0.0804 - recall_5: 0.2764 - val_loss: 0.2705 - val_precision_8: 0.1765 - val_recall_5: 0.0138\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8777 - precision_8: 0.0816 - recall_5: 0.2776 - val_loss: 0.2707 - val_precision_8: 0.1875 - val_recall_5: 0.0138\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8760 - precision_8: 0.0835 - recall_5: 0.2852 - val_loss: 0.2704 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8989 - precision_8: 0.0791 - recall_5: 0.2664 - val_loss: 0.2702 - val_precision_8: 0.2273 - val_recall_5: 0.0115\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8926 - precision_8: 0.0827 - recall_5: 0.2788 - val_loss: 0.2704 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8921 - precision_8: 0.0825 - recall_5: 0.2770 - val_loss: 0.2707 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8899 - precision_8: 0.0800 - recall_5: 0.2676 - val_loss: 0.2710 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8742 - precision_8: 0.0839 - recall_5: 0.2840 - val_loss: 0.2714 - val_precision_8: 0.2500 - val_recall_5: 0.0115\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8794 - precision_8: 0.0795 - recall_5: 0.2694 - val_loss: 0.2721 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8723 - precision_8: 0.0838 - recall_5: 0.2805 - val_loss: 0.2729 - val_precision_8: 0.2381 - val_recall_5: 0.0115\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8898 - precision_8: 0.0789 - recall_5: 0.2635 - val_loss: 0.2737 - val_precision_8: 0.2000 - val_recall_5: 0.0115\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8763 - precision_8: 0.0808 - recall_5: 0.2741 - val_loss: 0.2747 - val_precision_8: 0.1786 - val_recall_5: 0.0115\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8972 - precision_8: 0.0752 - recall_5: 0.2541 - val_loss: 0.2753 - val_precision_8: 0.1613 - val_recall_5: 0.0115\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8975 - precision_8: 0.0749 - recall_5: 0.2553 - val_loss: 0.2755 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8686 - precision_8: 0.0851 - recall_5: 0.2870 - val_loss: 0.2757 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8798 - precision_8: 0.0790 - recall_5: 0.2688 - val_loss: 0.2762 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8859 - precision_8: 0.0793 - recall_5: 0.2705 - val_loss: 0.2767 - val_precision_8: 0.1923 - val_recall_5: 0.0115\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8712 - precision_8: 0.0840 - recall_5: 0.2893 - val_loss: 0.2773 - val_precision_8: 0.1786 - val_recall_5: 0.0115\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8872 - precision_8: 0.0765 - recall_5: 0.2606 - val_loss: 0.2778 - val_precision_8: 0.1667 - val_recall_5: 0.0115\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8831 - precision_8: 0.0775 - recall_5: 0.2641 - val_loss: 0.2785 - val_precision_8: 0.1875 - val_recall_5: 0.0138\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8731 - precision_8: 0.0803 - recall_5: 0.2776 - val_loss: 0.2793 - val_precision_8: 0.1765 - val_recall_5: 0.0138\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9018 - precision_8: 0.0727 - recall_5: 0.2482 - val_loss: 0.2800 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8795 - precision_8: 0.0793 - recall_5: 0.2746 - val_loss: 0.2805 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8784 - precision_8: 0.0789 - recall_5: 0.2694 - val_loss: 0.2808 - val_precision_8: 0.1765 - val_recall_5: 0.0138\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8615 - precision_8: 0.0790 - recall_5: 0.2729 - val_loss: 0.2813 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8914 - precision_8: 0.0751 - recall_5: 0.2600 - val_loss: 0.2818 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8747 - precision_8: 0.0799 - recall_5: 0.2717 - val_loss: 0.2822 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8652 - precision_8: 0.0773 - recall_5: 0.2670 - val_loss: 0.2826 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8759 - precision_8: 0.0771 - recall_5: 0.2664 - val_loss: 0.2831 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8806 - precision_8: 0.0770 - recall_5: 0.2700 - val_loss: 0.2837 - val_precision_8: 0.1538 - val_recall_5: 0.0138\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8714 - precision_8: 0.0793 - recall_5: 0.2752 - val_loss: 0.2843 - val_precision_8: 0.1860 - val_recall_5: 0.0184\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8860 - precision_8: 0.0731 - recall_5: 0.2547 - val_loss: 0.2850 - val_precision_8: 0.2041 - val_recall_5: 0.0230\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8768 - precision_8: 0.0768 - recall_5: 0.2700 - val_loss: 0.2853 - val_precision_8: 0.2157 - val_recall_5: 0.0253\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8755 - precision_8: 0.0771 - recall_5: 0.2676 - val_loss: 0.2859 - val_precision_8: 0.2373 - val_recall_5: 0.0323\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8736 - precision_8: 0.0794 - recall_5: 0.2758 - val_loss: 0.2864 - val_precision_8: 0.2273 - val_recall_5: 0.0346\n",
      "Epoch 344/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8636 - precision_8: 0.0778 - recall_5: 0.2729 - val_loss: 0.2870 - val_precision_8: 0.2083 - val_recall_5: 0.0346\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8750 - precision_8: 0.0768 - recall_5: 0.2694 - val_loss: 0.2874 - val_precision_8: 0.2078 - val_recall_5: 0.0369\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8693 - precision_8: 0.0745 - recall_5: 0.2594 - val_loss: 0.2879 - val_precision_8: 0.2099 - val_recall_5: 0.0392\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8666 - precision_8: 0.0784 - recall_5: 0.2770 - val_loss: 0.2885 - val_precision_8: 0.2235 - val_recall_5: 0.0438\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8569 - precision_8: 0.0791 - recall_5: 0.2829 - val_loss: 0.2891 - val_precision_8: 0.2198 - val_recall_5: 0.0461\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8685 - precision_8: 0.0792 - recall_5: 0.2805 - val_loss: 0.2895 - val_precision_8: 0.2188 - val_recall_5: 0.0484\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8704 - precision_8: 0.0746 - recall_5: 0.2688 - val_loss: 0.2900 - val_precision_8: 0.2188 - val_recall_5: 0.0484\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8836 - precision_8: 0.0768 - recall_5: 0.2700 - val_loss: 0.2905 - val_precision_8: 0.2178 - val_recall_5: 0.0507\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8646 - precision_8: 0.0808 - recall_5: 0.2840 - val_loss: 0.2908 - val_precision_8: 0.2268 - val_recall_5: 0.0507\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8602 - precision_8: 0.0766 - recall_5: 0.2723 - val_loss: 0.2912 - val_precision_8: 0.2245 - val_recall_5: 0.0507\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8647 - precision_8: 0.0796 - recall_5: 0.2811 - val_loss: 0.2915 - val_precision_8: 0.2188 - val_recall_5: 0.0484\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8487 - precision_8: 0.0802 - recall_5: 0.2864 - val_loss: 0.2919 - val_precision_8: 0.2188 - val_recall_5: 0.0484\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8577 - precision_8: 0.0807 - recall_5: 0.2881 - val_loss: 0.2926 - val_precision_8: 0.2222 - val_recall_5: 0.0507\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8631 - precision_8: 0.0773 - recall_5: 0.2741 - val_loss: 0.2929 - val_precision_8: 0.2188 - val_recall_5: 0.0484\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8453 - precision_8: 0.0802 - recall_5: 0.2858 - val_loss: 0.2934 - val_precision_8: 0.2174 - val_recall_5: 0.0461\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8526 - precision_8: 0.0772 - recall_5: 0.2752 - val_loss: 0.2937 - val_precision_8: 0.2247 - val_recall_5: 0.0461\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8508 - precision_8: 0.0799 - recall_5: 0.2840 - val_loss: 0.2940 - val_precision_8: 0.2235 - val_recall_5: 0.0438\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8558 - precision_8: 0.0774 - recall_5: 0.2782 - val_loss: 0.2943 - val_precision_8: 0.2195 - val_recall_5: 0.0415\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8449 - precision_8: 0.0810 - recall_5: 0.2899 - val_loss: 0.2946 - val_precision_8: 0.2222 - val_recall_5: 0.0415\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8500 - precision_8: 0.0785 - recall_5: 0.2793 - val_loss: 0.2947 - val_precision_8: 0.2027 - val_recall_5: 0.0346\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8523 - precision_8: 0.0782 - recall_5: 0.2793 - val_loss: 0.2949 - val_precision_8: 0.2206 - val_recall_5: 0.0346\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8522 - precision_8: 0.0747 - recall_5: 0.2647 - val_loss: 0.2952 - val_precision_8: 0.2206 - val_recall_5: 0.0346\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8521 - precision_8: 0.0770 - recall_5: 0.2770 - val_loss: 0.2955 - val_precision_8: 0.2143 - val_recall_5: 0.0346\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8437 - precision_8: 0.0798 - recall_5: 0.2817 - val_loss: 0.2959 - val_precision_8: 0.2055 - val_recall_5: 0.0346\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8654 - precision_8: 0.0748 - recall_5: 0.2647 - val_loss: 0.2965 - val_precision_8: 0.2078 - val_recall_5: 0.0369\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8609 - precision_8: 0.0768 - recall_5: 0.2735 - val_loss: 0.2971 - val_precision_8: 0.2195 - val_recall_5: 0.0415\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8523 - precision_8: 0.0775 - recall_5: 0.2770 - val_loss: 0.2971 - val_precision_8: 0.2027 - val_recall_5: 0.0346\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8412 - precision_8: 0.0803 - recall_5: 0.2876 - val_loss: 0.2965 - val_precision_8: 0.1778 - val_recall_5: 0.0184\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8390 - precision_8: 0.0819 - recall_5: 0.2899 - val_loss: 0.2964 - val_precision_8: 0.1667 - val_recall_5: 0.0138\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8470 - precision_8: 0.0770 - recall_5: 0.2705 - val_loss: 0.2967 - val_precision_8: 0.1714 - val_recall_5: 0.0138\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8467 - precision_8: 0.0778 - recall_5: 0.2741 - val_loss: 0.2972 - val_precision_8: 0.1667 - val_recall_5: 0.0138\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8263 - precision_8: 0.0844 - recall_5: 0.3005 - val_loss: 0.2979 - val_precision_8: 0.1579 - val_recall_5: 0.0138\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8466 - precision_8: 0.0764 - recall_5: 0.2694 - val_loss: 0.2987 - val_precision_8: 0.1818 - val_recall_5: 0.0184\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8491 - precision_8: 0.0771 - recall_5: 0.2723 - val_loss: 0.2990 - val_precision_8: 0.1628 - val_recall_5: 0.0161\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8314 - precision_8: 0.0834 - recall_5: 0.2958 - val_loss: 0.2984 - val_precision_8: 0.1613 - val_recall_5: 0.0115\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8261 - precision_8: 0.0826 - recall_5: 0.2911 - val_loss: 0.2983 - val_precision_8: 0.2083 - val_recall_5: 0.0115\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8462 - precision_8: 0.0772 - recall_5: 0.2700 - val_loss: 0.2989 - val_precision_8: 0.2083 - val_recall_5: 0.0115\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8313 - precision_8: 0.0791 - recall_5: 0.2764 - val_loss: 0.2999 - val_precision_8: 0.1852 - val_recall_5: 0.0115\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8294 - precision_8: 0.0828 - recall_5: 0.2876 - val_loss: 0.3008 - val_precision_8: 0.1724 - val_recall_5: 0.0115\n",
      "Epoch 383/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8461 - precision_8: 0.0752 - recall_5: 0.2617 - val_loss: 0.3016 - val_precision_8: 0.1515 - val_recall_5: 0.0115\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8419 - precision_8: 0.0781 - recall_5: 0.2764 - val_loss: 0.3025 - val_precision_8: 0.1667 - val_recall_5: 0.0138\n",
      "Epoch 385/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8272 - precision_8: 0.0800 - recall_5: 0.2899 - val_loss: 0.3034 - val_precision_8: 0.1500 - val_recall_5: 0.0138\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8453 - precision_8: 0.0757 - recall_5: 0.2694 - val_loss: 0.3042 - val_precision_8: 0.1702 - val_recall_5: 0.0184\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8269 - precision_8: 0.0782 - recall_5: 0.2823 - val_loss: 0.3047 - val_precision_8: 0.1800 - val_recall_5: 0.0207\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8311 - precision_8: 0.0776 - recall_5: 0.2823 - val_loss: 0.3054 - val_precision_8: 0.1964 - val_recall_5: 0.0253\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8490 - precision_8: 0.0734 - recall_5: 0.2559 - val_loss: 0.3061 - val_precision_8: 0.2154 - val_recall_5: 0.0323\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8200 - precision_8: 0.0830 - recall_5: 0.2969 - val_loss: 0.3069 - val_precision_8: 0.2267 - val_recall_5: 0.0392\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8401 - precision_8: 0.0788 - recall_5: 0.2864 - val_loss: 0.3073 - val_precision_8: 0.2237 - val_recall_5: 0.0392\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8263 - precision_8: 0.0795 - recall_5: 0.2864 - val_loss: 0.3079 - val_precision_8: 0.2208 - val_recall_5: 0.0392\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8121 - precision_8: 0.0852 - recall_5: 0.3099 - val_loss: 0.3084 - val_precision_8: 0.2024 - val_recall_5: 0.0392\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8288 - precision_8: 0.0790 - recall_5: 0.2846 - val_loss: 0.3089 - val_precision_8: 0.2045 - val_recall_5: 0.0415\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8287 - precision_8: 0.0785 - recall_5: 0.2864 - val_loss: 0.3095 - val_precision_8: 0.2062 - val_recall_5: 0.0461\n",
      "Epoch 396/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8477 - precision_8: 0.0762 - recall_5: 0.2735 - val_loss: 0.3099 - val_precision_8: 0.2157 - val_recall_5: 0.0507\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8380 - precision_8: 0.0716 - recall_5: 0.2635 - val_loss: 0.3105 - val_precision_8: 0.2174 - val_recall_5: 0.0576\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8291 - precision_8: 0.0774 - recall_5: 0.2840 - val_loss: 0.3111 - val_precision_8: 0.2185 - val_recall_5: 0.0599\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8265 - precision_8: 0.0770 - recall_5: 0.2805 - val_loss: 0.3117 - val_precision_8: 0.2154 - val_recall_5: 0.0645\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8146 - precision_8: 0.0799 - recall_5: 0.2899 - val_loss: 0.3125 - val_precision_8: 0.2041 - val_recall_5: 0.0691\n",
      "Epoch 401/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8406 - precision_8: 0.0760 - recall_5: 0.2793 - val_loss: 0.3130 - val_precision_8: 0.1961 - val_recall_5: 0.0691\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8208 - precision_8: 0.0806 - recall_5: 0.2987 - val_loss: 0.3131 - val_precision_8: 0.2000 - val_recall_5: 0.0691\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8280 - precision_8: 0.0777 - recall_5: 0.2835 - val_loss: 0.3129 - val_precision_8: 0.2057 - val_recall_5: 0.0668\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8333 - precision_8: 0.0750 - recall_5: 0.2741 - val_loss: 0.3121 - val_precision_8: 0.2174 - val_recall_5: 0.0576\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8273 - precision_8: 0.0773 - recall_5: 0.2805 - val_loss: 0.3118 - val_precision_8: 0.1959 - val_recall_5: 0.0438\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8379 - precision_8: 0.0757 - recall_5: 0.2694 - val_loss: 0.3117 - val_precision_8: 0.2045 - val_recall_5: 0.0415\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8336 - precision_8: 0.0765 - recall_5: 0.2711 - val_loss: 0.3119 - val_precision_8: 0.2069 - val_recall_5: 0.0415\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8250 - precision_8: 0.0802 - recall_5: 0.2858 - val_loss: 0.3123 - val_precision_8: 0.2045 - val_recall_5: 0.0415\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8239 - precision_8: 0.0812 - recall_5: 0.2911 - val_loss: 0.3129 - val_precision_8: 0.1979 - val_recall_5: 0.0438\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8291 - precision_8: 0.0764 - recall_5: 0.2711 - val_loss: 0.3137 - val_precision_8: 0.2110 - val_recall_5: 0.0530\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8196 - precision_8: 0.0782 - recall_5: 0.2817 - val_loss: 0.3145 - val_precision_8: 0.2167 - val_recall_5: 0.0599\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8191 - precision_8: 0.0790 - recall_5: 0.2829 - val_loss: 0.3155 - val_precision_8: 0.2071 - val_recall_5: 0.0668\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8173 - precision_8: 0.0798 - recall_5: 0.2911 - val_loss: 0.3166 - val_precision_8: 0.1852 - val_recall_5: 0.0691\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8137 - precision_8: 0.0811 - recall_5: 0.2952 - val_loss: 0.3175 - val_precision_8: 0.1802 - val_recall_5: 0.0714\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8151 - precision_8: 0.0788 - recall_5: 0.2905 - val_loss: 0.3183 - val_precision_8: 0.1789 - val_recall_5: 0.0783\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8208 - precision_8: 0.0777 - recall_5: 0.2870 - val_loss: 0.3191 - val_precision_8: 0.1765 - val_recall_5: 0.0829\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8130 - precision_8: 0.0783 - recall_5: 0.2923 - val_loss: 0.3197 - val_precision_8: 0.1806 - val_recall_5: 0.0899\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7986 - precision_8: 0.0826 - recall_5: 0.3028 - val_loss: 0.3207 - val_precision_8: 0.1833 - val_recall_5: 0.1014\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8102 - precision_8: 0.0805 - recall_5: 0.3040 - val_loss: 0.3217 - val_precision_8: 0.1798 - val_recall_5: 0.1106\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7981 - precision_8: 0.0823 - recall_5: 0.3058 - val_loss: 0.3229 - val_precision_8: 0.1684 - val_recall_5: 0.1152\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8070 - precision_8: 0.0804 - recall_5: 0.2993 - val_loss: 0.3241 - val_precision_8: 0.1766 - val_recall_5: 0.1359\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8080 - precision_8: 0.0801 - recall_5: 0.3075 - val_loss: 0.3249 - val_precision_8: 0.1738 - val_recall_5: 0.1406\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8115 - precision_8: 0.0781 - recall_5: 0.2969 - val_loss: 0.3255 - val_precision_8: 0.1757 - val_recall_5: 0.1498\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8141 - precision_8: 0.0776 - recall_5: 0.2969 - val_loss: 0.3260 - val_precision_8: 0.1804 - val_recall_5: 0.1567\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8175 - precision_8: 0.0771 - recall_5: 0.2905 - val_loss: 0.3266 - val_precision_8: 0.1777 - val_recall_5: 0.1613\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8133 - precision_8: 0.0777 - recall_5: 0.2993 - val_loss: 0.3270 - val_precision_8: 0.1741 - val_recall_5: 0.1613\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7939 - precision_8: 0.0836 - recall_5: 0.3222 - val_loss: 0.3274 - val_precision_8: 0.1711 - val_recall_5: 0.1613\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8105 - precision_8: 0.0768 - recall_5: 0.2940 - val_loss: 0.3279 - val_precision_8: 0.1710 - val_recall_5: 0.1682\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8037 - precision_8: 0.0803 - recall_5: 0.3087 - val_loss: 0.3284 - val_precision_8: 0.1735 - val_recall_5: 0.1751\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8157 - precision_8: 0.0771 - recall_5: 0.2999 - val_loss: 0.3291 - val_precision_8: 0.1753 - val_recall_5: 0.1866\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8019 - precision_8: 0.0794 - recall_5: 0.3116 - val_loss: 0.3294 - val_precision_8: 0.1776 - val_recall_5: 0.1935\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7992 - precision_8: 0.0804 - recall_5: 0.3128 - val_loss: 0.3299 - val_precision_8: 0.1768 - val_recall_5: 0.2005\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8168 - precision_8: 0.0739 - recall_5: 0.2928 - val_loss: 0.3303 - val_precision_8: 0.1784 - val_recall_5: 0.2051\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7818 - precision_8: 0.0833 - recall_5: 0.3181 - val_loss: 0.3306 - val_precision_8: 0.1800 - val_recall_5: 0.2074\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8059 - precision_8: 0.0790 - recall_5: 0.3063 - val_loss: 0.3306 - val_precision_8: 0.1781 - val_recall_5: 0.2028\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8146 - precision_8: 0.0782 - recall_5: 0.3040 - val_loss: 0.3301 - val_precision_8: 0.1783 - val_recall_5: 0.1935\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8061 - precision_8: 0.0781 - recall_5: 0.3022 - val_loss: 0.3297 - val_precision_8: 0.1765 - val_recall_5: 0.1797\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7815 - precision_8: 0.0860 - recall_5: 0.3228 - val_loss: 0.3300 - val_precision_8: 0.1765 - val_recall_5: 0.1797\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8002 - precision_8: 0.0764 - recall_5: 0.2905 - val_loss: 0.3304 - val_precision_8: 0.1763 - val_recall_5: 0.1820\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8065 - precision_8: 0.0741 - recall_5: 0.2829 - val_loss: 0.3308 - val_precision_8: 0.1752 - val_recall_5: 0.1820\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8222 - precision_8: 0.0738 - recall_5: 0.2793 - val_loss: 0.3312 - val_precision_8: 0.1775 - val_recall_5: 0.1889\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7861 - precision_8: 0.0852 - recall_5: 0.3263 - val_loss: 0.3317 - val_precision_8: 0.1777 - val_recall_5: 0.1912\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8128 - precision_8: 0.0718 - recall_5: 0.2793 - val_loss: 0.3323 - val_precision_8: 0.1811 - val_recall_5: 0.1982\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8013 - precision_8: 0.0769 - recall_5: 0.2928 - val_loss: 0.3325 - val_precision_8: 0.1803 - val_recall_5: 0.1982\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7899 - precision_8: 0.0814 - recall_5: 0.3169 - val_loss: 0.3329 - val_precision_8: 0.1772 - val_recall_5: 0.2005\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8033 - precision_8: 0.0765 - recall_5: 0.2934 - val_loss: 0.3336 - val_precision_8: 0.1824 - val_recall_5: 0.2143\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8040 - precision_8: 0.0784 - recall_5: 0.2999 - val_loss: 0.3344 - val_precision_8: 0.1839 - val_recall_5: 0.2258\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7950 - precision_8: 0.0788 - recall_5: 0.3052 - val_loss: 0.3347 - val_precision_8: 0.1827 - val_recall_5: 0.2281\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7934 - precision_8: 0.0792 - recall_5: 0.3058 - val_loss: 0.3351 - val_precision_8: 0.1863 - val_recall_5: 0.2373\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8024 - precision_8: 0.0780 - recall_5: 0.3040 - val_loss: 0.3355 - val_precision_8: 0.1836 - val_recall_5: 0.2373\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7736 - precision_8: 0.0859 - recall_5: 0.3333 - val_loss: 0.3360 - val_precision_8: 0.1875 - val_recall_5: 0.2488\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7986 - precision_8: 0.0760 - recall_5: 0.2934 - val_loss: 0.3370 - val_precision_8: 0.1874 - val_recall_5: 0.2604\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7957 - precision_8: 0.0793 - recall_5: 0.3122 - val_loss: 0.3374 - val_precision_8: 0.1862 - val_recall_5: 0.2604\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7983 - precision_8: 0.0790 - recall_5: 0.3104 - val_loss: 0.3373 - val_precision_8: 0.1852 - val_recall_5: 0.2535\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7922 - precision_8: 0.0791 - recall_5: 0.3087 - val_loss: 0.3367 - val_precision_8: 0.1851 - val_recall_5: 0.2396\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7878 - precision_8: 0.0809 - recall_5: 0.3181 - val_loss: 0.3362 - val_precision_8: 0.1832 - val_recall_5: 0.2304\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7981 - precision_8: 0.0775 - recall_5: 0.2999 - val_loss: 0.3360 - val_precision_8: 0.1833 - val_recall_5: 0.2281\n",
      "Epoch 458/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7942 - precision_8: 0.0771 - recall_5: 0.2952 - val_loss: 0.3361 - val_precision_8: 0.1833 - val_recall_5: 0.2281\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7812 - precision_8: 0.0835 - recall_5: 0.3181 - val_loss: 0.3359 - val_precision_8: 0.1777 - val_recall_5: 0.2166\n",
      "Epoch 460/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7794 - precision_8: 0.0831 - recall_5: 0.3187 - val_loss: 0.3360 - val_precision_8: 0.1777 - val_recall_5: 0.2166\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7926 - precision_8: 0.0780 - recall_5: 0.2952 - val_loss: 0.3358 - val_precision_8: 0.1794 - val_recall_5: 0.2166\n",
      "Epoch 462/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7915 - precision_8: 0.0771 - recall_5: 0.2946 - val_loss: 0.3358 - val_precision_8: 0.1804 - val_recall_5: 0.2166\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7662 - precision_8: 0.0847 - recall_5: 0.3222 - val_loss: 0.3361 - val_precision_8: 0.1786 - val_recall_5: 0.2189\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7808 - precision_8: 0.0805 - recall_5: 0.3063 - val_loss: 0.3369 - val_precision_8: 0.1835 - val_recall_5: 0.2350\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7857 - precision_8: 0.0814 - recall_5: 0.3134 - val_loss: 0.3375 - val_precision_8: 0.1858 - val_recall_5: 0.2465\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7690 - precision_8: 0.0875 - recall_5: 0.3322 - val_loss: 0.3383 - val_precision_8: 0.1864 - val_recall_5: 0.2535\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7893 - precision_8: 0.0776 - recall_5: 0.3016 - val_loss: 0.3391 - val_precision_8: 0.1859 - val_recall_5: 0.2604\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8023 - precision_8: 0.0730 - recall_5: 0.2799 - val_loss: 0.3397 - val_precision_8: 0.1838 - val_recall_5: 0.2673\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7888 - precision_8: 0.0823 - recall_5: 0.3175 - val_loss: 0.3401 - val_precision_8: 0.1854 - val_recall_5: 0.2742\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7961 - precision_8: 0.0791 - recall_5: 0.3028 - val_loss: 0.3406 - val_precision_8: 0.1840 - val_recall_5: 0.2765\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7785 - precision_8: 0.0806 - recall_5: 0.3093 - val_loss: 0.3409 - val_precision_8: 0.1865 - val_recall_5: 0.2811\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7830 - precision_8: 0.0776 - recall_5: 0.2975 - val_loss: 0.3410 - val_precision_8: 0.1878 - val_recall_5: 0.2834\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7821 - precision_8: 0.0778 - recall_5: 0.3028 - val_loss: 0.3409 - val_precision_8: 0.1825 - val_recall_5: 0.2650\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7808 - precision_8: 0.0835 - recall_5: 0.3210 - val_loss: 0.3406 - val_precision_8: 0.1833 - val_recall_5: 0.2535\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7686 - precision_8: 0.0867 - recall_5: 0.3322 - val_loss: 0.3399 - val_precision_8: 0.1817 - val_recall_5: 0.2327\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7812 - precision_8: 0.0796 - recall_5: 0.3069 - val_loss: 0.3392 - val_precision_8: 0.1795 - val_recall_5: 0.2143\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7773 - precision_8: 0.0771 - recall_5: 0.2905 - val_loss: 0.3389 - val_precision_8: 0.1762 - val_recall_5: 0.1982\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7906 - precision_8: 0.0760 - recall_5: 0.2835 - val_loss: 0.3386 - val_precision_8: 0.1728 - val_recall_5: 0.1843\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7825 - precision_8: 0.0807 - recall_5: 0.3016 - val_loss: 0.3381 - val_precision_8: 0.1723 - val_recall_5: 0.1751\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7598 - precision_8: 0.0858 - recall_5: 0.3204 - val_loss: 0.3379 - val_precision_8: 0.1718 - val_recall_5: 0.1682\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7853 - precision_8: 0.0811 - recall_5: 0.2999 - val_loss: 0.3379 - val_precision_8: 0.1731 - val_recall_5: 0.1659\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7782 - precision_8: 0.0801 - recall_5: 0.2993 - val_loss: 0.3383 - val_precision_8: 0.1718 - val_recall_5: 0.1682\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7877 - precision_8: 0.0780 - recall_5: 0.2846 - val_loss: 0.3389 - val_precision_8: 0.1697 - val_recall_5: 0.1705\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7829 - precision_8: 0.0786 - recall_5: 0.2911 - val_loss: 0.3396 - val_precision_8: 0.1735 - val_recall_5: 0.1843\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7717 - precision_8: 0.0853 - recall_5: 0.3151 - val_loss: 0.3405 - val_precision_8: 0.1759 - val_recall_5: 0.1982\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7750 - precision_8: 0.0822 - recall_5: 0.3069 - val_loss: 0.3413 - val_precision_8: 0.1785 - val_recall_5: 0.2143\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7670 - precision_8: 0.0834 - recall_5: 0.3116 - val_loss: 0.3424 - val_precision_8: 0.1836 - val_recall_5: 0.2373\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7828 - precision_8: 0.0797 - recall_5: 0.3011 - val_loss: 0.3429 - val_precision_8: 0.1846 - val_recall_5: 0.2488\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7750 - precision_8: 0.0828 - recall_5: 0.3110 - val_loss: 0.3433 - val_precision_8: 0.1826 - val_recall_5: 0.2512\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7793 - precision_8: 0.0785 - recall_5: 0.2964 - val_loss: 0.3439 - val_precision_8: 0.1828 - val_recall_5: 0.2650\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7739 - precision_8: 0.0800 - recall_5: 0.3028 - val_loss: 0.3450 - val_precision_8: 0.1868 - val_recall_5: 0.2926\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7774 - precision_8: 0.0815 - recall_5: 0.3075 - val_loss: 0.3460 - val_precision_8: 0.1899 - val_recall_5: 0.3111\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7882 - precision_8: 0.0781 - recall_5: 0.2969 - val_loss: 0.3466 - val_precision_8: 0.1855 - val_recall_5: 0.3134\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7755 - precision_8: 0.0789 - recall_5: 0.3034 - val_loss: 0.3468 - val_precision_8: 0.1883 - val_recall_5: 0.3203\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7650 - precision_8: 0.0822 - recall_5: 0.3175 - val_loss: 0.3466 - val_precision_8: 0.1871 - val_recall_5: 0.3134\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7749 - precision_8: 0.0769 - recall_5: 0.2958 - val_loss: 0.3469 - val_precision_8: 0.1855 - val_recall_5: 0.3134\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7722 - precision_8: 0.0788 - recall_5: 0.3022 - val_loss: 0.3476 - val_precision_8: 0.1862 - val_recall_5: 0.3226\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7619 - precision_8: 0.0842 - recall_5: 0.3263 - val_loss: 0.3479 - val_precision_8: 0.1884 - val_recall_5: 0.3295\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7623 - precision_8: 0.0825 - recall_5: 0.3192 - val_loss: 0.3485 - val_precision_8: 0.1852 - val_recall_5: 0.3295\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7654 - precision_8: 0.0826 - recall_5: 0.3169 - val_loss: 0.3493 - val_precision_8: 0.1888 - val_recall_5: 0.3502\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7668 - precision_8: 0.0839 - recall_5: 0.3222 - val_loss: 0.3498 - val_precision_8: 0.1880 - val_recall_5: 0.3548\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7762 - precision_8: 0.0780 - recall_5: 0.3011 - val_loss: 0.3504 - val_precision_8: 0.1889 - val_recall_5: 0.3618\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7534 - precision_8: 0.0861 - recall_5: 0.3333 - val_loss: 0.3511 - val_precision_8: 0.1877 - val_recall_5: 0.3664\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7708 - precision_8: 0.0806 - recall_5: 0.3181 - val_loss: 0.3518 - val_precision_8: 0.1863 - val_recall_5: 0.3710\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7678 - precision_8: 0.0810 - recall_5: 0.3169 - val_loss: 0.3520 - val_precision_8: 0.1857 - val_recall_5: 0.3710\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7712 - precision_8: 0.0787 - recall_5: 0.3069 - val_loss: 0.3526 - val_precision_8: 0.1846 - val_recall_5: 0.3756\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7715 - precision_8: 0.0803 - recall_5: 0.3163 - val_loss: 0.3527 - val_precision_8: 0.1858 - val_recall_5: 0.3802\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7664 - precision_8: 0.0830 - recall_5: 0.3216 - val_loss: 0.3532 - val_precision_8: 0.1892 - val_recall_5: 0.3940\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7725 - precision_8: 0.0798 - recall_5: 0.3093 - val_loss: 0.3531 - val_precision_8: 0.1889 - val_recall_5: 0.3917\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7619 - precision_8: 0.0822 - recall_5: 0.3151 - val_loss: 0.3531 - val_precision_8: 0.1870 - val_recall_5: 0.3848\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7646 - precision_8: 0.0783 - recall_5: 0.3058 - val_loss: 0.3530 - val_precision_8: 0.1858 - val_recall_5: 0.3733\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7761 - precision_8: 0.0760 - recall_5: 0.2934 - val_loss: 0.3519 - val_precision_8: 0.1853 - val_recall_5: 0.3433\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7587 - precision_8: 0.0834 - recall_5: 0.3198 - val_loss: 0.3510 - val_precision_8: 0.1827 - val_recall_5: 0.3157\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7779 - precision_8: 0.0797 - recall_5: 0.3005 - val_loss: 0.3501 - val_precision_8: 0.1857 - val_recall_5: 0.2995\n",
      "Epoch 515/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7584 - precision_8: 0.0803 - recall_5: 0.3022 - val_loss: 0.3496 - val_precision_8: 0.1860 - val_recall_5: 0.2811\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7591 - precision_8: 0.0853 - recall_5: 0.3192 - val_loss: 0.3493 - val_precision_8: 0.1845 - val_recall_5: 0.2696\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7666 - precision_8: 0.0796 - recall_5: 0.2999 - val_loss: 0.3496 - val_precision_8: 0.1840 - val_recall_5: 0.2696\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7530 - precision_8: 0.0843 - recall_5: 0.3181 - val_loss: 0.3499 - val_precision_8: 0.1837 - val_recall_5: 0.2696\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7471 - precision_8: 0.0844 - recall_5: 0.3128 - val_loss: 0.3505 - val_precision_8: 0.1832 - val_recall_5: 0.2765\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7561 - precision_8: 0.0850 - recall_5: 0.3204 - val_loss: 0.3512 - val_precision_8: 0.1844 - val_recall_5: 0.2880\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7616 - precision_8: 0.0819 - recall_5: 0.3081 - val_loss: 0.3518 - val_precision_8: 0.1848 - val_recall_5: 0.2972\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7590 - precision_8: 0.0808 - recall_5: 0.3063 - val_loss: 0.3524 - val_precision_8: 0.1823 - val_recall_5: 0.3041\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7621 - precision_8: 0.0803 - recall_5: 0.3028 - val_loss: 0.3529 - val_precision_8: 0.1819 - val_recall_5: 0.3065\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7728 - precision_8: 0.0767 - recall_5: 0.2905 - val_loss: 0.3530 - val_precision_8: 0.1818 - val_recall_5: 0.3041\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7509 - precision_8: 0.0830 - recall_5: 0.3146 - val_loss: 0.3534 - val_precision_8: 0.1808 - val_recall_5: 0.3041\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7467 - precision_8: 0.0853 - recall_5: 0.3210 - val_loss: 0.3541 - val_precision_8: 0.1807 - val_recall_5: 0.3111\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7564 - precision_8: 0.0817 - recall_5: 0.3093 - val_loss: 0.3546 - val_precision_8: 0.1796 - val_recall_5: 0.3157\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7662 - precision_8: 0.0786 - recall_5: 0.2981 - val_loss: 0.3549 - val_precision_8: 0.1805 - val_recall_5: 0.3111\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7510 - precision_8: 0.0829 - recall_5: 0.3128 - val_loss: 0.3549 - val_precision_8: 0.1797 - val_recall_5: 0.3065\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7484 - precision_8: 0.0858 - recall_5: 0.3222 - val_loss: 0.3551 - val_precision_8: 0.1795 - val_recall_5: 0.3065\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7569 - precision_8: 0.0810 - recall_5: 0.3075 - val_loss: 0.3553 - val_precision_8: 0.1798 - val_recall_5: 0.3111\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7547 - precision_8: 0.0835 - recall_5: 0.3175 - val_loss: 0.3552 - val_precision_8: 0.1785 - val_recall_5: 0.3065\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7388 - precision_8: 0.0883 - recall_5: 0.3357 - val_loss: 0.3553 - val_precision_8: 0.1780 - val_recall_5: 0.3065\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7514 - precision_8: 0.0817 - recall_5: 0.3134 - val_loss: 0.3556 - val_precision_8: 0.1780 - val_recall_5: 0.3134\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7473 - precision_8: 0.0851 - recall_5: 0.3181 - val_loss: 0.3555 - val_precision_8: 0.1780 - val_recall_5: 0.3134\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7493 - precision_8: 0.0849 - recall_5: 0.3146 - val_loss: 0.3555 - val_precision_8: 0.1769 - val_recall_5: 0.3134\n",
      "Epoch 537/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7515 - precision_8: 0.0814 - recall_5: 0.3087 - val_loss: 0.3554 - val_precision_8: 0.1765 - val_recall_5: 0.3157\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7384 - precision_8: 0.0839 - recall_5: 0.3175 - val_loss: 0.3552 - val_precision_8: 0.1776 - val_recall_5: 0.3180\n",
      "Epoch 539/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7419 - precision_8: 0.0865 - recall_5: 0.3292 - val_loss: 0.3555 - val_precision_8: 0.1786 - val_recall_5: 0.3272\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7279 - precision_8: 0.0895 - recall_5: 0.3363 - val_loss: 0.3561 - val_precision_8: 0.1787 - val_recall_5: 0.3364\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7378 - precision_8: 0.0876 - recall_5: 0.3333 - val_loss: 0.3568 - val_precision_8: 0.1822 - val_recall_5: 0.3548\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7381 - precision_8: 0.0862 - recall_5: 0.3234 - val_loss: 0.3572 - val_precision_8: 0.1812 - val_recall_5: 0.3548\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7418 - precision_8: 0.0838 - recall_5: 0.3146 - val_loss: 0.3577 - val_precision_8: 0.1802 - val_recall_5: 0.3571\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7514 - precision_8: 0.0805 - recall_5: 0.3081 - val_loss: 0.3584 - val_precision_8: 0.1809 - val_recall_5: 0.3664\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7429 - precision_8: 0.0851 - recall_5: 0.3269 - val_loss: 0.3592 - val_precision_8: 0.1779 - val_recall_5: 0.3710\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7395 - precision_8: 0.0870 - recall_5: 0.3304 - val_loss: 0.3597 - val_precision_8: 0.1768 - val_recall_5: 0.3756\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7436 - precision_8: 0.0841 - recall_5: 0.3234 - val_loss: 0.3599 - val_precision_8: 0.1773 - val_recall_5: 0.3779\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7583 - precision_8: 0.0782 - recall_5: 0.2969 - val_loss: 0.3598 - val_precision_8: 0.1764 - val_recall_5: 0.3756\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7387 - precision_8: 0.0861 - recall_5: 0.3286 - val_loss: 0.3598 - val_precision_8: 0.1773 - val_recall_5: 0.3779\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7411 - precision_8: 0.0836 - recall_5: 0.3175 - val_loss: 0.3605 - val_precision_8: 0.1749 - val_recall_5: 0.3848\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7377 - precision_8: 0.0850 - recall_5: 0.3228 - val_loss: 0.3611 - val_precision_8: 0.1744 - val_recall_5: 0.3917\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7380 - precision_8: 0.0854 - recall_5: 0.3228 - val_loss: 0.3613 - val_precision_8: 0.1749 - val_recall_5: 0.4009\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7236 - precision_8: 0.0918 - recall_5: 0.3515 - val_loss: 0.3612 - val_precision_8: 0.1745 - val_recall_5: 0.4009\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7493 - precision_8: 0.0827 - recall_5: 0.3104 - val_loss: 0.3610 - val_precision_8: 0.1746 - val_recall_5: 0.3963\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7581 - precision_8: 0.0807 - recall_5: 0.3011 - val_loss: 0.3608 - val_precision_8: 0.1756 - val_recall_5: 0.3940\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7412 - precision_8: 0.0827 - recall_5: 0.3140 - val_loss: 0.3606 - val_precision_8: 0.1756 - val_recall_5: 0.3940\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7356 - precision_8: 0.0860 - recall_5: 0.3216 - val_loss: 0.3600 - val_precision_8: 0.1765 - val_recall_5: 0.3917\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7441 - precision_8: 0.0849 - recall_5: 0.3157 - val_loss: 0.3593 - val_precision_8: 0.1753 - val_recall_5: 0.3825\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7431 - precision_8: 0.0834 - recall_5: 0.3081 - val_loss: 0.3589 - val_precision_8: 0.1765 - val_recall_5: 0.3779\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7314 - precision_8: 0.0891 - recall_5: 0.3269 - val_loss: 0.3588 - val_precision_8: 0.1771 - val_recall_5: 0.3779\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7399 - precision_8: 0.0852 - recall_5: 0.3151 - val_loss: 0.3584 - val_precision_8: 0.1763 - val_recall_5: 0.3733\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7432 - precision_8: 0.0837 - recall_5: 0.3005 - val_loss: 0.3568 - val_precision_8: 0.1759 - val_recall_5: 0.3295\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7402 - precision_8: 0.0830 - recall_5: 0.2975 - val_loss: 0.3538 - val_precision_8: 0.1709 - val_recall_5: 0.2189\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7362 - precision_8: 0.0839 - recall_5: 0.2952 - val_loss: 0.3521 - val_precision_8: 0.1583 - val_recall_5: 0.1382\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7395 - precision_8: 0.0839 - recall_5: 0.2870 - val_loss: 0.3519 - val_precision_8: 0.1642 - val_recall_5: 0.1037\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7350 - precision_8: 0.0854 - recall_5: 0.2905 - val_loss: 0.3522 - val_precision_8: 0.1598 - val_recall_5: 0.0899\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7359 - precision_8: 0.0852 - recall_5: 0.2928 - val_loss: 0.3529 - val_precision_8: 0.1639 - val_recall_5: 0.0922\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7421 - precision_8: 0.0823 - recall_5: 0.2840 - val_loss: 0.3538 - val_precision_8: 0.1565 - val_recall_5: 0.0945\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7314 - precision_8: 0.0846 - recall_5: 0.2969 - val_loss: 0.3553 - val_precision_8: 0.1517 - val_recall_5: 0.1129\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7447 - precision_8: 0.0811 - recall_5: 0.2835 - val_loss: 0.3574 - val_precision_8: 0.1599 - val_recall_5: 0.1452\n",
      "Epoch 571/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7231 - precision_8: 0.0904 - recall_5: 0.3187 - val_loss: 0.3592 - val_precision_8: 0.1609 - val_recall_5: 0.1728\n",
      "Epoch 572/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7288 - precision_8: 0.0841 - recall_5: 0.3028 - val_loss: 0.3615 - val_precision_8: 0.1611 - val_recall_5: 0.2005\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7289 - precision_8: 0.0845 - recall_5: 0.3146 - val_loss: 0.3631 - val_precision_8: 0.1639 - val_recall_5: 0.2258\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7362 - precision_8: 0.0832 - recall_5: 0.3040 - val_loss: 0.3644 - val_precision_8: 0.1644 - val_recall_5: 0.2488\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7278 - precision_8: 0.0860 - recall_5: 0.3157 - val_loss: 0.3653 - val_precision_8: 0.1685 - val_recall_5: 0.2765\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7370 - precision_8: 0.0822 - recall_5: 0.3081 - val_loss: 0.3659 - val_precision_8: 0.1701 - val_recall_5: 0.3018\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7356 - precision_8: 0.0827 - recall_5: 0.3052 - val_loss: 0.3660 - val_precision_8: 0.1738 - val_recall_5: 0.3180\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7278 - precision_8: 0.0878 - recall_5: 0.3245 - val_loss: 0.3657 - val_precision_8: 0.1721 - val_recall_5: 0.3180\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7192 - precision_8: 0.0926 - recall_5: 0.3415 - val_loss: 0.3653 - val_precision_8: 0.1738 - val_recall_5: 0.3180\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7232 - precision_8: 0.0867 - recall_5: 0.3146 - val_loss: 0.3650 - val_precision_8: 0.1731 - val_recall_5: 0.3111\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7151 - precision_8: 0.0905 - recall_5: 0.3310 - val_loss: 0.3653 - val_precision_8: 0.1710 - val_recall_5: 0.3157\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7129 - precision_8: 0.0923 - recall_5: 0.3398 - val_loss: 0.3656 - val_precision_8: 0.1724 - val_recall_5: 0.3249\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7314 - precision_8: 0.0847 - recall_5: 0.3116 - val_loss: 0.3662 - val_precision_8: 0.1673 - val_recall_5: 0.3295\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7359 - precision_8: 0.0812 - recall_5: 0.2917 - val_loss: 0.3669 - val_precision_8: 0.1652 - val_recall_5: 0.3387\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7225 - precision_8: 0.0881 - recall_5: 0.3263 - val_loss: 0.3676 - val_precision_8: 0.1676 - val_recall_5: 0.3525\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7233 - precision_8: 0.0851 - recall_5: 0.3081 - val_loss: 0.3684 - val_precision_8: 0.1689 - val_recall_5: 0.3756\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7357 - precision_8: 0.0811 - recall_5: 0.2981 - val_loss: 0.3684 - val_precision_8: 0.1680 - val_recall_5: 0.3779\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7221 - precision_8: 0.0880 - recall_5: 0.3216 - val_loss: 0.3684 - val_precision_8: 0.1673 - val_recall_5: 0.3779\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7228 - precision_8: 0.0851 - recall_5: 0.3192 - val_loss: 0.3692 - val_precision_8: 0.1653 - val_recall_5: 0.3848\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7280 - precision_8: 0.0880 - recall_5: 0.3234 - val_loss: 0.3701 - val_precision_8: 0.1670 - val_recall_5: 0.4032\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7116 - precision_8: 0.0915 - recall_5: 0.3339 - val_loss: 0.3710 - val_precision_8: 0.1654 - val_recall_5: 0.4171\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7139 - precision_8: 0.0928 - recall_5: 0.3427 - val_loss: 0.3714 - val_precision_8: 0.1649 - val_recall_5: 0.4240\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7250 - precision_8: 0.0870 - recall_5: 0.3210 - val_loss: 0.3717 - val_precision_8: 0.1643 - val_recall_5: 0.4309\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7236 - precision_8: 0.0870 - recall_5: 0.3245 - val_loss: 0.3715 - val_precision_8: 0.1646 - val_recall_5: 0.4332\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7016 - precision_8: 0.0944 - recall_5: 0.3550 - val_loss: 0.3715 - val_precision_8: 0.1636 - val_recall_5: 0.4355\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7115 - precision_8: 0.0927 - recall_5: 0.3445 - val_loss: 0.3709 - val_precision_8: 0.1649 - val_recall_5: 0.4309\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7186 - precision_8: 0.0864 - recall_5: 0.3134 - val_loss: 0.3701 - val_precision_8: 0.1664 - val_recall_5: 0.4217\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7156 - precision_8: 0.0905 - recall_5: 0.3251 - val_loss: 0.3696 - val_precision_8: 0.1665 - val_recall_5: 0.4194\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7126 - precision_8: 0.0900 - recall_5: 0.3222 - val_loss: 0.3697 - val_precision_8: 0.1665 - val_recall_5: 0.4240\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7271 - precision_8: 0.0852 - recall_5: 0.3069 - val_loss: 0.3696 - val_precision_8: 0.1661 - val_recall_5: 0.4263\n",
      "Epoch 601/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7107 - precision_8: 0.0908 - recall_5: 0.3228 - val_loss: 0.3696 - val_precision_8: 0.1658 - val_recall_5: 0.4286\n",
      "Epoch 602/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7056 - precision_8: 0.0925 - recall_5: 0.3333 - val_loss: 0.3693 - val_precision_8: 0.1664 - val_recall_5: 0.4286\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7121 - precision_8: 0.0941 - recall_5: 0.3363 - val_loss: 0.3693 - val_precision_8: 0.1659 - val_recall_5: 0.4309\n",
      "Epoch 604/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7184 - precision_8: 0.0906 - recall_5: 0.3251 - val_loss: 0.3687 - val_precision_8: 0.1670 - val_recall_5: 0.4263\n",
      "Epoch 605/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7221 - precision_8: 0.0895 - recall_5: 0.3146 - val_loss: 0.3681 - val_precision_8: 0.1681 - val_recall_5: 0.4171\n",
      "Epoch 606/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7080 - precision_8: 0.0932 - recall_5: 0.3275 - val_loss: 0.3676 - val_precision_8: 0.1697 - val_recall_5: 0.4147\n",
      "Epoch 607/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7204 - precision_8: 0.0907 - recall_5: 0.3140 - val_loss: 0.3678 - val_precision_8: 0.1692 - val_recall_5: 0.4147\n",
      "Epoch 608/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7053 - precision_8: 0.0952 - recall_5: 0.3322 - val_loss: 0.3688 - val_precision_8: 0.1673 - val_recall_5: 0.4263\n",
      "Epoch 609/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7085 - precision_8: 0.0904 - recall_5: 0.3146 - val_loss: 0.3702 - val_precision_8: 0.1644 - val_recall_5: 0.4447\n",
      "Epoch 610/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7231 - precision_8: 0.0887 - recall_5: 0.3140 - val_loss: 0.3714 - val_precision_8: 0.1668 - val_recall_5: 0.4747\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7069 - precision_8: 0.0925 - recall_5: 0.3286 - val_loss: 0.3725 - val_precision_8: 0.1682 - val_recall_5: 0.5023\n",
      "Epoch 612/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7178 - precision_8: 0.0871 - recall_5: 0.3122 - val_loss: 0.3730 - val_precision_8: 0.1688 - val_recall_5: 0.5207\n",
      "Epoch 613/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7114 - precision_8: 0.0912 - recall_5: 0.3269 - val_loss: 0.3736 - val_precision_8: 0.1691 - val_recall_5: 0.5369\n",
      "Epoch 614/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7108 - precision_8: 0.0919 - recall_5: 0.3327 - val_loss: 0.3739 - val_precision_8: 0.1702 - val_recall_5: 0.5507\n",
      "Epoch 615/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7131 - precision_8: 0.0888 - recall_5: 0.3234 - val_loss: 0.3738 - val_precision_8: 0.1701 - val_recall_5: 0.5507\n",
      "Epoch 616/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7105 - precision_8: 0.0891 - recall_5: 0.3157 - val_loss: 0.3732 - val_precision_8: 0.1705 - val_recall_5: 0.5461\n",
      "Epoch 617/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7061 - precision_8: 0.0940 - recall_5: 0.3316 - val_loss: 0.3731 - val_precision_8: 0.1705 - val_recall_5: 0.5461\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7134 - precision_8: 0.0890 - recall_5: 0.3163 - val_loss: 0.3730 - val_precision_8: 0.1676 - val_recall_5: 0.5276\n",
      "Epoch 619/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7092 - precision_8: 0.0897 - recall_5: 0.3140 - val_loss: 0.3724 - val_precision_8: 0.1653 - val_recall_5: 0.4793\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7141 - precision_8: 0.0884 - recall_5: 0.3140 - val_loss: 0.3720 - val_precision_8: 0.1612 - val_recall_5: 0.4424\n",
      "Epoch 621/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7084 - precision_8: 0.0891 - recall_5: 0.3140 - val_loss: 0.3693 - val_precision_8: 0.1671 - val_recall_5: 0.3986\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7100 - precision_8: 0.0922 - recall_5: 0.3104 - val_loss: 0.3681 - val_precision_8: 0.1679 - val_recall_5: 0.3779\n",
      "Epoch 623/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6933 - precision_8: 0.0989 - recall_5: 0.3345 - val_loss: 0.3684 - val_precision_8: 0.1689 - val_recall_5: 0.3779\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7002 - precision_8: 0.0959 - recall_5: 0.3234 - val_loss: 0.3690 - val_precision_8: 0.1663 - val_recall_5: 0.3779\n",
      "Epoch 625/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6998 - precision_8: 0.0953 - recall_5: 0.3251 - val_loss: 0.3693 - val_precision_8: 0.1665 - val_recall_5: 0.3779\n",
      "Epoch 626/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7075 - precision_8: 0.0911 - recall_5: 0.3034 - val_loss: 0.3701 - val_precision_8: 0.1658 - val_recall_5: 0.3802\n",
      "Epoch 627/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6993 - precision_8: 0.0947 - recall_5: 0.3198 - val_loss: 0.3711 - val_precision_8: 0.1655 - val_recall_5: 0.3894\n",
      "Epoch 628/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7015 - precision_8: 0.0950 - recall_5: 0.3239 - val_loss: 0.3727 - val_precision_8: 0.1651 - val_recall_5: 0.4055\n",
      "Epoch 629/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7080 - precision_8: 0.0913 - recall_5: 0.3140 - val_loss: 0.3738 - val_precision_8: 0.1637 - val_recall_5: 0.4171\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7081 - precision_8: 0.0921 - recall_5: 0.3228 - val_loss: 0.3750 - val_precision_8: 0.1608 - val_recall_5: 0.4309\n",
      "Epoch 631/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7017 - precision_8: 0.0921 - recall_5: 0.3192 - val_loss: 0.3758 - val_precision_8: 0.1592 - val_recall_5: 0.4401\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7006 - precision_8: 0.0952 - recall_5: 0.3374 - val_loss: 0.3764 - val_precision_8: 0.1582 - val_recall_5: 0.4493\n",
      "Epoch 633/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7029 - precision_8: 0.0904 - recall_5: 0.3210 - val_loss: 0.3757 - val_precision_8: 0.1589 - val_recall_5: 0.4424\n",
      "Epoch 634/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7058 - precision_8: 0.0895 - recall_5: 0.3122 - val_loss: 0.3752 - val_precision_8: 0.1590 - val_recall_5: 0.4355\n",
      "Epoch 635/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7011 - precision_8: 0.0922 - recall_5: 0.3181 - val_loss: 0.3756 - val_precision_8: 0.1588 - val_recall_5: 0.4470\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6882 - precision_8: 0.1009 - recall_5: 0.3468 - val_loss: 0.3761 - val_precision_8: 0.1614 - val_recall_5: 0.4608\n",
      "Epoch 637/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7095 - precision_8: 0.0897 - recall_5: 0.3052 - val_loss: 0.3767 - val_precision_8: 0.1576 - val_recall_5: 0.4447\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6935 - precision_8: 0.0954 - recall_5: 0.3316 - val_loss: 0.3779 - val_precision_8: 0.1596 - val_recall_5: 0.4608\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6931 - precision_8: 0.0956 - recall_5: 0.3357 - val_loss: 0.3792 - val_precision_8: 0.1606 - val_recall_5: 0.4747\n",
      "Epoch 640/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6889 - precision_8: 0.1003 - recall_5: 0.3480 - val_loss: 0.3798 - val_precision_8: 0.1604 - val_recall_5: 0.4839\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6994 - precision_8: 0.0932 - recall_5: 0.3286 - val_loss: 0.3798 - val_precision_8: 0.1593 - val_recall_5: 0.4839\n",
      "Epoch 642/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6957 - precision_8: 0.0958 - recall_5: 0.3333 - val_loss: 0.3799 - val_precision_8: 0.1613 - val_recall_5: 0.5000\n",
      "Epoch 643/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6860 - precision_8: 0.1000 - recall_5: 0.3492 - val_loss: 0.3804 - val_precision_8: 0.1628 - val_recall_5: 0.5230\n",
      "Epoch 644/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6904 - precision_8: 0.0959 - recall_5: 0.3351 - val_loss: 0.3814 - val_precision_8: 0.1663 - val_recall_5: 0.5599\n",
      "Epoch 645/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6995 - precision_8: 0.0928 - recall_5: 0.3269 - val_loss: 0.3820 - val_precision_8: 0.1676 - val_recall_5: 0.5806\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6924 - precision_8: 0.0967 - recall_5: 0.3421 - val_loss: 0.3823 - val_precision_8: 0.1685 - val_recall_5: 0.5876\n",
      "Epoch 647/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6919 - precision_8: 0.0955 - recall_5: 0.3310 - val_loss: 0.3824 - val_precision_8: 0.1679 - val_recall_5: 0.5899\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6974 - precision_8: 0.0948 - recall_5: 0.3369 - val_loss: 0.3823 - val_precision_8: 0.1683 - val_recall_5: 0.5922\n",
      "Epoch 649/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6842 - precision_8: 0.1011 - recall_5: 0.3603 - val_loss: 0.3820 - val_precision_8: 0.1682 - val_recall_5: 0.5899\n",
      "Epoch 650/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6803 - precision_8: 0.1001 - recall_5: 0.3550 - val_loss: 0.3828 - val_precision_8: 0.1662 - val_recall_5: 0.6037\n",
      "Epoch 651/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6867 - precision_8: 0.0967 - recall_5: 0.3474 - val_loss: 0.3844 - val_precision_8: 0.1637 - val_recall_5: 0.6244\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6979 - precision_8: 0.0950 - recall_5: 0.3380 - val_loss: 0.3858 - val_precision_8: 0.1619 - val_recall_5: 0.6406\n",
      "Epoch 653/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6785 - precision_8: 0.0994 - recall_5: 0.3562 - val_loss: 0.3871 - val_precision_8: 0.1635 - val_recall_5: 0.6705\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6913 - precision_8: 0.0957 - recall_5: 0.3445 - val_loss: 0.3879 - val_precision_8: 0.1628 - val_recall_5: 0.6843\n",
      "Epoch 655/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6853 - precision_8: 0.0957 - recall_5: 0.3504 - val_loss: 0.3880 - val_precision_8: 0.1626 - val_recall_5: 0.6820\n",
      "Epoch 656/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6869 - precision_8: 0.0940 - recall_5: 0.3421 - val_loss: 0.3880 - val_precision_8: 0.1627 - val_recall_5: 0.6843\n",
      "Epoch 657/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6968 - precision_8: 0.0911 - recall_5: 0.3333 - val_loss: 0.3878 - val_precision_8: 0.1628 - val_recall_5: 0.6843\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6937 - precision_8: 0.0917 - recall_5: 0.3286 - val_loss: 0.3871 - val_precision_8: 0.1632 - val_recall_5: 0.6843\n",
      "Epoch 659/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6822 - precision_8: 0.0986 - recall_5: 0.3509 - val_loss: 0.3860 - val_precision_8: 0.1640 - val_recall_5: 0.6774\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6877 - precision_8: 0.0951 - recall_5: 0.3351 - val_loss: 0.3859 - val_precision_8: 0.1639 - val_recall_5: 0.6843\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6737 - precision_8: 0.1038 - recall_5: 0.3680 - val_loss: 0.3859 - val_precision_8: 0.1634 - val_recall_5: 0.6843\n",
      "Epoch 662/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6798 - precision_8: 0.0981 - recall_5: 0.3480 - val_loss: 0.3864 - val_precision_8: 0.1619 - val_recall_5: 0.6935\n",
      "Epoch 663/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6985 - precision_8: 0.0931 - recall_5: 0.3286 - val_loss: 0.3865 - val_precision_8: 0.1605 - val_recall_5: 0.6959\n",
      "Epoch 664/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6883 - precision_8: 0.0955 - recall_5: 0.3380 - val_loss: 0.3863 - val_precision_8: 0.1607 - val_recall_5: 0.7005\n",
      "Epoch 665/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6863 - precision_8: 0.0957 - recall_5: 0.3351 - val_loss: 0.3860 - val_precision_8: 0.1604 - val_recall_5: 0.7005\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6710 - precision_8: 0.1036 - recall_5: 0.3615 - val_loss: 0.3858 - val_precision_8: 0.1597 - val_recall_5: 0.7005\n",
      "Epoch 667/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6880 - precision_8: 0.0973 - recall_5: 0.3392 - val_loss: 0.3867 - val_precision_8: 0.1579 - val_recall_5: 0.7051\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6842 - precision_8: 0.0978 - recall_5: 0.3439 - val_loss: 0.3874 - val_precision_8: 0.1566 - val_recall_5: 0.7120\n",
      "Epoch 669/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6799 - precision_8: 0.1003 - recall_5: 0.3515 - val_loss: 0.3877 - val_precision_8: 0.1555 - val_recall_5: 0.7120\n",
      "Epoch 670/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6818 - precision_8: 0.0999 - recall_5: 0.3550 - val_loss: 0.3876 - val_precision_8: 0.1549 - val_recall_5: 0.7120\n",
      "Epoch 671/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6725 - precision_8: 0.0992 - recall_5: 0.3498 - val_loss: 0.3872 - val_precision_8: 0.1549 - val_recall_5: 0.7120\n",
      "Epoch 672/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6765 - precision_8: 0.0955 - recall_5: 0.3380 - val_loss: 0.3868 - val_precision_8: 0.1552 - val_recall_5: 0.7120\n",
      "Epoch 673/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6827 - precision_8: 0.0974 - recall_5: 0.3410 - val_loss: 0.3861 - val_precision_8: 0.1563 - val_recall_5: 0.7120\n",
      "Epoch 674/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6850 - precision_8: 0.0982 - recall_5: 0.3445 - val_loss: 0.3853 - val_precision_8: 0.1567 - val_recall_5: 0.7097\n",
      "Epoch 675/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6892 - precision_8: 0.0958 - recall_5: 0.3210 - val_loss: 0.3850 - val_precision_8: 0.1565 - val_recall_5: 0.7097\n",
      "Epoch 676/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6838 - precision_8: 0.1012 - recall_5: 0.3457 - val_loss: 0.3851 - val_precision_8: 0.1561 - val_recall_5: 0.7120\n",
      "Epoch 677/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6736 - precision_8: 0.1018 - recall_5: 0.3515 - val_loss: 0.3862 - val_precision_8: 0.1552 - val_recall_5: 0.7235\n",
      "Epoch 678/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6804 - precision_8: 0.0974 - recall_5: 0.3433 - val_loss: 0.3878 - val_precision_8: 0.1545 - val_recall_5: 0.7350\n",
      "Epoch 679/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6781 - precision_8: 0.1022 - recall_5: 0.3556 - val_loss: 0.3882 - val_precision_8: 0.1539 - val_recall_5: 0.7327\n",
      "Epoch 680/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6824 - precision_8: 0.0979 - recall_5: 0.3474 - val_loss: 0.3874 - val_precision_8: 0.1535 - val_recall_5: 0.7235\n",
      "Epoch 681/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6826 - precision_8: 0.1005 - recall_5: 0.3486 - val_loss: 0.3858 - val_precision_8: 0.1549 - val_recall_5: 0.7097\n",
      "Epoch 682/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6786 - precision_8: 0.1000 - recall_5: 0.3421 - val_loss: 0.3863 - val_precision_8: 0.1542 - val_recall_5: 0.7097\n",
      "Epoch 683/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6786 - precision_8: 0.0941 - recall_5: 0.3216 - val_loss: 0.3859 - val_precision_8: 0.1556 - val_recall_5: 0.7074\n",
      "Epoch 684/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6754 - precision_8: 0.1000 - recall_5: 0.3457 - val_loss: 0.3872 - val_precision_8: 0.1535 - val_recall_5: 0.7097\n",
      "Epoch 685/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6742 - precision_8: 0.1032 - recall_5: 0.3550 - val_loss: 0.3880 - val_precision_8: 0.1518 - val_recall_5: 0.7097\n",
      "Epoch 686/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6844 - precision_8: 0.0972 - recall_5: 0.3392 - val_loss: 0.3882 - val_precision_8: 0.1510 - val_recall_5: 0.7097\n",
      "Epoch 687/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6707 - precision_8: 0.1001 - recall_5: 0.3451 - val_loss: 0.3875 - val_precision_8: 0.1526 - val_recall_5: 0.7097\n",
      "Epoch 688/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6698 - precision_8: 0.0995 - recall_5: 0.3474 - val_loss: 0.3856 - val_precision_8: 0.1558 - val_recall_5: 0.6935\n",
      "Epoch 689/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6737 - precision_8: 0.0992 - recall_5: 0.3339 - val_loss: 0.3848 - val_precision_8: 0.1577 - val_recall_5: 0.6843\n",
      "Epoch 690/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6678 - precision_8: 0.1014 - recall_5: 0.3451 - val_loss: 0.3843 - val_precision_8: 0.1570 - val_recall_5: 0.6682\n",
      "Epoch 691/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6540 - precision_8: 0.1118 - recall_5: 0.3785 - val_loss: 0.3839 - val_precision_8: 0.1584 - val_recall_5: 0.6659\n",
      "Epoch 692/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6653 - precision_8: 0.1020 - recall_5: 0.3515 - val_loss: 0.3848 - val_precision_8: 0.1566 - val_recall_5: 0.6820\n",
      "Epoch 693/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6670 - precision_8: 0.1017 - recall_5: 0.3527 - val_loss: 0.3857 - val_precision_8: 0.1547 - val_recall_5: 0.6912\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6668 - precision_8: 0.1024 - recall_5: 0.3498 - val_loss: 0.3857 - val_precision_8: 0.1546 - val_recall_5: 0.6935\n",
      "Epoch 695/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6593 - precision_8: 0.1066 - recall_5: 0.3680 - val_loss: 0.3862 - val_precision_8: 0.1542 - val_recall_5: 0.6959\n",
      "Epoch 696/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6767 - precision_8: 0.0955 - recall_5: 0.3234 - val_loss: 0.3860 - val_precision_8: 0.1538 - val_recall_5: 0.6935\n",
      "Epoch 697/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6658 - precision_8: 0.1037 - recall_5: 0.3556 - val_loss: 0.3858 - val_precision_8: 0.1537 - val_recall_5: 0.6912\n",
      "Epoch 698/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6541 - precision_8: 0.1049 - recall_5: 0.3633 - val_loss: 0.3863 - val_precision_8: 0.1527 - val_recall_5: 0.6935\n",
      "Epoch 699/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6651 - precision_8: 0.1057 - recall_5: 0.3615 - val_loss: 0.3877 - val_precision_8: 0.1514 - val_recall_5: 0.7028\n",
      "Epoch 700/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6773 - precision_8: 0.0989 - recall_5: 0.3457 - val_loss: 0.3887 - val_precision_8: 0.1495 - val_recall_5: 0.7051\n",
      "Epoch 701/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6779 - precision_8: 0.0981 - recall_5: 0.3468 - val_loss: 0.3897 - val_precision_8: 0.1474 - val_recall_5: 0.7097\n",
      "Epoch 702/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6760 - precision_8: 0.0985 - recall_5: 0.3468 - val_loss: 0.3893 - val_precision_8: 0.1477 - val_recall_5: 0.7097\n",
      "Epoch 703/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6596 - precision_8: 0.1062 - recall_5: 0.3768 - val_loss: 0.3876 - val_precision_8: 0.1495 - val_recall_5: 0.7028\n",
      "Epoch 704/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6609 - precision_8: 0.1075 - recall_5: 0.3662 - val_loss: 0.3847 - val_precision_8: 0.1528 - val_recall_5: 0.6820\n",
      "Epoch 705/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6586 - precision_8: 0.1062 - recall_5: 0.3592 - val_loss: 0.3831 - val_precision_8: 0.1528 - val_recall_5: 0.6567\n",
      "Epoch 706/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6676 - precision_8: 0.1025 - recall_5: 0.3427 - val_loss: 0.3837 - val_precision_8: 0.1508 - val_recall_5: 0.6613\n",
      "Epoch 707/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6706 - precision_8: 0.1026 - recall_5: 0.3498 - val_loss: 0.3848 - val_precision_8: 0.1500 - val_recall_5: 0.6682\n",
      "Epoch 708/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6582 - precision_8: 0.1106 - recall_5: 0.3832 - val_loss: 0.3871 - val_precision_8: 0.1487 - val_recall_5: 0.6982\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6604 - precision_8: 0.1034 - recall_5: 0.3562 - val_loss: 0.3885 - val_precision_8: 0.1461 - val_recall_5: 0.7028\n",
      "Epoch 710/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6626 - precision_8: 0.1054 - recall_5: 0.3662 - val_loss: 0.3882 - val_precision_8: 0.1458 - val_recall_5: 0.7028\n",
      "Epoch 711/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6668 - precision_8: 0.1040 - recall_5: 0.3545 - val_loss: 0.3864 - val_precision_8: 0.1487 - val_recall_5: 0.6982\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6614 - precision_8: 0.1049 - recall_5: 0.3580 - val_loss: 0.3862 - val_precision_8: 0.1484 - val_recall_5: 0.6982\n",
      "Epoch 713/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6614 - precision_8: 0.1099 - recall_5: 0.3791 - val_loss: 0.3867 - val_precision_8: 0.1474 - val_recall_5: 0.7005\n",
      "Epoch 714/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6599 - precision_8: 0.1050 - recall_5: 0.3562 - val_loss: 0.3862 - val_precision_8: 0.1476 - val_recall_5: 0.7005\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6623 - precision_8: 0.1046 - recall_5: 0.3574 - val_loss: 0.3853 - val_precision_8: 0.1479 - val_recall_5: 0.7005\n",
      "Epoch 716/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6616 - precision_8: 0.1057 - recall_5: 0.3627 - val_loss: 0.3853 - val_precision_8: 0.1477 - val_recall_5: 0.7028\n",
      "Epoch 717/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6525 - precision_8: 0.1085 - recall_5: 0.3580 - val_loss: 0.3844 - val_precision_8: 0.1481 - val_recall_5: 0.7028\n",
      "Epoch 718/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6531 - precision_8: 0.1094 - recall_5: 0.3615 - val_loss: 0.3853 - val_precision_8: 0.1453 - val_recall_5: 0.7074\n",
      "Epoch 719/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6608 - precision_8: 0.1072 - recall_5: 0.3568 - val_loss: 0.3864 - val_precision_8: 0.1456 - val_recall_5: 0.7235\n",
      "Epoch 720/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6496 - precision_8: 0.1081 - recall_5: 0.3715 - val_loss: 0.3884 - val_precision_8: 0.1438 - val_recall_5: 0.7373\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6544 - precision_8: 0.1082 - recall_5: 0.3727 - val_loss: 0.3900 - val_precision_8: 0.1427 - val_recall_5: 0.7512\n",
      "Epoch 722/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6639 - precision_8: 0.1035 - recall_5: 0.3621 - val_loss: 0.3882 - val_precision_8: 0.1431 - val_recall_5: 0.7373\n",
      "Epoch 723/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6495 - precision_8: 0.1081 - recall_5: 0.3756 - val_loss: 0.3847 - val_precision_8: 0.1449 - val_recall_5: 0.7097\n",
      "Epoch 724/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6549 - precision_8: 0.1072 - recall_5: 0.3597 - val_loss: 0.3828 - val_precision_8: 0.1470 - val_recall_5: 0.7005\n",
      "Epoch 725/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6558 - precision_8: 0.1096 - recall_5: 0.3550 - val_loss: 0.3813 - val_precision_8: 0.1501 - val_recall_5: 0.6982\n",
      "Epoch 726/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6601 - precision_8: 0.1087 - recall_5: 0.3509 - val_loss: 0.3806 - val_precision_8: 0.1497 - val_recall_5: 0.6797\n",
      "Epoch 727/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6578 - precision_8: 0.1050 - recall_5: 0.3310 - val_loss: 0.3818 - val_precision_8: 0.1495 - val_recall_5: 0.6959\n",
      "Epoch 728/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6579 - precision_8: 0.1075 - recall_5: 0.3504 - val_loss: 0.3837 - val_precision_8: 0.1455 - val_recall_5: 0.7005\n",
      "Epoch 729/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6560 - precision_8: 0.1115 - recall_5: 0.3662 - val_loss: 0.3853 - val_precision_8: 0.1439 - val_recall_5: 0.7143\n",
      "Epoch 730/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6566 - precision_8: 0.1062 - recall_5: 0.3527 - val_loss: 0.3857 - val_precision_8: 0.1431 - val_recall_5: 0.7120\n",
      "Epoch 731/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6636 - precision_8: 0.1057 - recall_5: 0.3462 - val_loss: 0.3840 - val_precision_8: 0.1450 - val_recall_5: 0.7005\n",
      "Epoch 732/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6473 - precision_8: 0.1105 - recall_5: 0.3568 - val_loss: 0.3840 - val_precision_8: 0.1443 - val_recall_5: 0.6982\n",
      "Epoch 733/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6589 - precision_8: 0.1064 - recall_5: 0.3474 - val_loss: 0.3825 - val_precision_8: 0.1451 - val_recall_5: 0.6797\n",
      "Epoch 734/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6542 - precision_8: 0.1097 - recall_5: 0.3480 - val_loss: 0.3807 - val_precision_8: 0.1451 - val_recall_5: 0.6313\n",
      "Epoch 735/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6580 - precision_8: 0.1090 - recall_5: 0.3392 - val_loss: 0.3803 - val_precision_8: 0.1432 - val_recall_5: 0.6083\n",
      "Epoch 736/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6551 - precision_8: 0.1081 - recall_5: 0.3427 - val_loss: 0.3823 - val_precision_8: 0.1427 - val_recall_5: 0.6406\n",
      "Epoch 737/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6531 - precision_8: 0.1078 - recall_5: 0.3410 - val_loss: 0.3835 - val_precision_8: 0.1423 - val_recall_5: 0.6636\n",
      "Epoch 738/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6577 - precision_8: 0.1072 - recall_5: 0.3445 - val_loss: 0.3849 - val_precision_8: 0.1424 - val_recall_5: 0.6912\n",
      "Epoch 739/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6541 - precision_8: 0.1098 - recall_5: 0.3568 - val_loss: 0.3869 - val_precision_8: 0.1417 - val_recall_5: 0.7166\n",
      "Epoch 740/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6533 - precision_8: 0.1126 - recall_5: 0.3744 - val_loss: 0.3886 - val_precision_8: 0.1407 - val_recall_5: 0.7350\n",
      "Epoch 741/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6507 - precision_8: 0.1106 - recall_5: 0.3574 - val_loss: 0.3892 - val_precision_8: 0.1404 - val_recall_5: 0.7419\n",
      "Epoch 742/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6552 - precision_8: 0.1063 - recall_5: 0.3574 - val_loss: 0.3904 - val_precision_8: 0.1402 - val_recall_5: 0.7558\n",
      "Epoch 743/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6492 - precision_8: 0.1076 - recall_5: 0.3574 - val_loss: 0.3907 - val_precision_8: 0.1398 - val_recall_5: 0.7604\n",
      "Epoch 744/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6471 - precision_8: 0.1107 - recall_5: 0.3779 - val_loss: 0.3912 - val_precision_8: 0.1386 - val_recall_5: 0.7627\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6481 - precision_8: 0.1111 - recall_5: 0.3809 - val_loss: 0.3901 - val_precision_8: 0.1389 - val_recall_5: 0.7604\n",
      "Epoch 746/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6577 - precision_8: 0.1024 - recall_5: 0.3451 - val_loss: 0.3904 - val_precision_8: 0.1381 - val_recall_5: 0.7627\n",
      "Epoch 747/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6555 - precision_8: 0.1045 - recall_5: 0.3550 - val_loss: 0.3884 - val_precision_8: 0.1399 - val_recall_5: 0.7558\n",
      "Epoch 748/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6619 - precision_8: 0.1043 - recall_5: 0.3421 - val_loss: 0.3849 - val_precision_8: 0.1420 - val_recall_5: 0.7327\n",
      "Epoch 749/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6455 - precision_8: 0.1117 - recall_5: 0.3580 - val_loss: 0.3802 - val_precision_8: 0.1462 - val_recall_5: 0.6982\n",
      "Epoch 750/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6711 - precision_8: 0.1042 - recall_5: 0.3146 - val_loss: 0.3782 - val_precision_8: 0.1465 - val_recall_5: 0.6682\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6639 - precision_8: 0.1047 - recall_5: 0.3069 - val_loss: 0.3775 - val_precision_8: 0.1478 - val_recall_5: 0.6636\n",
      "Epoch 752/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6482 - precision_8: 0.1097 - recall_5: 0.3316 - val_loss: 0.3803 - val_precision_8: 0.1450 - val_recall_5: 0.6982\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6397 - precision_8: 0.1151 - recall_5: 0.3527 - val_loss: 0.3839 - val_precision_8: 0.1423 - val_recall_5: 0.7304\n",
      "Epoch 754/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6498 - precision_8: 0.1110 - recall_5: 0.3627 - val_loss: 0.3889 - val_precision_8: 0.1385 - val_recall_5: 0.7650\n",
      "Epoch 755/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6451 - precision_8: 0.1117 - recall_5: 0.3721 - val_loss: 0.3895 - val_precision_8: 0.1371 - val_recall_5: 0.7627\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6433 - precision_8: 0.1102 - recall_5: 0.3744 - val_loss: 0.3867 - val_precision_8: 0.1393 - val_recall_5: 0.7442\n",
      "Epoch 757/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6484 - precision_8: 0.1093 - recall_5: 0.3597 - val_loss: 0.3834 - val_precision_8: 0.1403 - val_recall_5: 0.7166\n",
      "Epoch 758/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6417 - precision_8: 0.1108 - recall_5: 0.3609 - val_loss: 0.3808 - val_precision_8: 0.1409 - val_recall_5: 0.6820\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6437 - precision_8: 0.1096 - recall_5: 0.3421 - val_loss: 0.3801 - val_precision_8: 0.1410 - val_recall_5: 0.6544\n",
      "Epoch 760/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6447 - precision_8: 0.1109 - recall_5: 0.3415 - val_loss: 0.3836 - val_precision_8: 0.1390 - val_recall_5: 0.6959\n",
      "Epoch 761/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6406 - precision_8: 0.1098 - recall_5: 0.3521 - val_loss: 0.3875 - val_precision_8: 0.1373 - val_recall_5: 0.7281\n",
      "Epoch 762/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6358 - precision_8: 0.1161 - recall_5: 0.3873 - val_loss: 0.3904 - val_precision_8: 0.1357 - val_recall_5: 0.7488\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6409 - precision_8: 0.1122 - recall_5: 0.3773 - val_loss: 0.3932 - val_precision_8: 0.1331 - val_recall_5: 0.7627\n",
      "Epoch 764/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6436 - precision_8: 0.1086 - recall_5: 0.3738 - val_loss: 0.3911 - val_precision_8: 0.1346 - val_recall_5: 0.7535\n",
      "Epoch 765/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6433 - precision_8: 0.1094 - recall_5: 0.3638 - val_loss: 0.3876 - val_precision_8: 0.1369 - val_recall_5: 0.7281\n",
      "Epoch 766/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6453 - precision_8: 0.1104 - recall_5: 0.3609 - val_loss: 0.3865 - val_precision_8: 0.1371 - val_recall_5: 0.7235\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6498 - precision_8: 0.1081 - recall_5: 0.3480 - val_loss: 0.3870 - val_precision_8: 0.1374 - val_recall_5: 0.7281\n",
      "Epoch 768/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6392 - precision_8: 0.1106 - recall_5: 0.3603 - val_loss: 0.3875 - val_precision_8: 0.1379 - val_recall_5: 0.7396\n",
      "Epoch 769/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6413 - precision_8: 0.1119 - recall_5: 0.3680 - val_loss: 0.3881 - val_precision_8: 0.1370 - val_recall_5: 0.7396\n",
      "Epoch 770/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6410 - precision_8: 0.1136 - recall_5: 0.3662 - val_loss: 0.3853 - val_precision_8: 0.1372 - val_recall_5: 0.7028\n",
      "Epoch 771/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6298 - precision_8: 0.1220 - recall_5: 0.3826 - val_loss: 0.3854 - val_precision_8: 0.1355 - val_recall_5: 0.6866\n",
      "Epoch 772/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6425 - precision_8: 0.1135 - recall_5: 0.3633 - val_loss: 0.3873 - val_precision_8: 0.1344 - val_recall_5: 0.7051\n",
      "Epoch 773/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6441 - precision_8: 0.1104 - recall_5: 0.3562 - val_loss: 0.3895 - val_precision_8: 0.1337 - val_recall_5: 0.7212\n",
      "Epoch 774/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6390 - precision_8: 0.1123 - recall_5: 0.3738 - val_loss: 0.3900 - val_precision_8: 0.1338 - val_recall_5: 0.7212\n",
      "Epoch 775/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6476 - precision_8: 0.1105 - recall_5: 0.3603 - val_loss: 0.3884 - val_precision_8: 0.1339 - val_recall_5: 0.6935\n",
      "Epoch 776/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6427 - precision_8: 0.1124 - recall_5: 0.3533 - val_loss: 0.3896 - val_precision_8: 0.1339 - val_recall_5: 0.6959\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6489 - precision_8: 0.1057 - recall_5: 0.3374 - val_loss: 0.3933 - val_precision_8: 0.1329 - val_recall_5: 0.7258\n",
      "Epoch 778/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6511 - precision_8: 0.1057 - recall_5: 0.3509 - val_loss: 0.3957 - val_precision_8: 0.1313 - val_recall_5: 0.7396\n",
      "Epoch 779/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6376 - precision_8: 0.1132 - recall_5: 0.3691 - val_loss: 0.3970 - val_precision_8: 0.1315 - val_recall_5: 0.7535\n",
      "Epoch 780/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6333 - precision_8: 0.1104 - recall_5: 0.3691 - val_loss: 0.3989 - val_precision_8: 0.1311 - val_recall_5: 0.7696\n",
      "Epoch 781/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6376 - precision_8: 0.1111 - recall_5: 0.3750 - val_loss: 0.3979 - val_precision_8: 0.1317 - val_recall_5: 0.7650\n",
      "Epoch 782/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6403 - precision_8: 0.1114 - recall_5: 0.3597 - val_loss: 0.3909 - val_precision_8: 0.1370 - val_recall_5: 0.7051\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6385 - precision_8: 0.1091 - recall_5: 0.3327 - val_loss: 0.3928 - val_precision_8: 0.1363 - val_recall_5: 0.7166\n",
      "Epoch 784/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6295 - precision_8: 0.1154 - recall_5: 0.3627 - val_loss: 0.3967 - val_precision_8: 0.1336 - val_recall_5: 0.7488\n",
      "Epoch 785/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6456 - precision_8: 0.1065 - recall_5: 0.3486 - val_loss: 0.3992 - val_precision_8: 0.1318 - val_recall_5: 0.7627\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6517 - precision_8: 0.1039 - recall_5: 0.3521 - val_loss: 0.4051 - val_precision_8: 0.1293 - val_recall_5: 0.7972\n",
      "Epoch 787/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6368 - precision_8: 0.1133 - recall_5: 0.3955 - val_loss: 0.4069 - val_precision_8: 0.1282 - val_recall_5: 0.7972\n",
      "Epoch 788/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6462 - precision_8: 0.1044 - recall_5: 0.3644 - val_loss: 0.4026 - val_precision_8: 0.1301 - val_recall_5: 0.7857\n",
      "Epoch 789/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6408 - precision_8: 0.1092 - recall_5: 0.3732 - val_loss: 0.3996 - val_precision_8: 0.1313 - val_recall_5: 0.7604\n",
      "Epoch 790/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6254 - precision_8: 0.1194 - recall_5: 0.3908 - val_loss: 0.3971 - val_precision_8: 0.1349 - val_recall_5: 0.7488\n",
      "Epoch 791/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6359 - precision_8: 0.1120 - recall_5: 0.3550 - val_loss: 0.3967 - val_precision_8: 0.1357 - val_recall_5: 0.7442\n",
      "Epoch 792/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6434 - precision_8: 0.1065 - recall_5: 0.3392 - val_loss: 0.3970 - val_precision_8: 0.1349 - val_recall_5: 0.7396\n",
      "Epoch 793/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6366 - precision_8: 0.1098 - recall_5: 0.3574 - val_loss: 0.3997 - val_precision_8: 0.1319 - val_recall_5: 0.7535\n",
      "Epoch 794/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6347 - precision_8: 0.1124 - recall_5: 0.3750 - val_loss: 0.4053 - val_precision_8: 0.1280 - val_recall_5: 0.7788\n",
      "Epoch 795/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6369 - precision_8: 0.1090 - recall_5: 0.3791 - val_loss: 0.4091 - val_precision_8: 0.1261 - val_recall_5: 0.7857\n",
      "Epoch 796/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6434 - precision_8: 0.1052 - recall_5: 0.3803 - val_loss: 0.4062 - val_precision_8: 0.1274 - val_recall_5: 0.7765\n",
      "Epoch 797/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6287 - precision_8: 0.1133 - recall_5: 0.3914 - val_loss: 0.4009 - val_precision_8: 0.1293 - val_recall_5: 0.7373\n",
      "Epoch 798/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6474 - precision_8: 0.1057 - recall_5: 0.3457 - val_loss: 0.3957 - val_precision_8: 0.1334 - val_recall_5: 0.6797\n",
      "Epoch 799/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6378 - precision_8: 0.1107 - recall_5: 0.3445 - val_loss: 0.3940 - val_precision_8: 0.1327 - val_recall_5: 0.6359\n",
      "Epoch 800/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6340 - precision_8: 0.1122 - recall_5: 0.3304 - val_loss: 0.3941 - val_precision_8: 0.1283 - val_recall_5: 0.5991\n",
      "Epoch 801/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6335 - precision_8: 0.1109 - recall_5: 0.3369 - val_loss: 0.4009 - val_precision_8: 0.1310 - val_recall_5: 0.7212\n",
      "Epoch 802/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6361 - precision_8: 0.1073 - recall_5: 0.3592 - val_loss: 0.4109 - val_precision_8: 0.1265 - val_recall_5: 0.7834\n",
      "Epoch 803/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6285 - precision_8: 0.1144 - recall_5: 0.4102 - val_loss: 0.4130 - val_precision_8: 0.1248 - val_recall_5: 0.7857\n",
      "Epoch 804/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6371 - precision_8: 0.1084 - recall_5: 0.3826 - val_loss: 0.4029 - val_precision_8: 0.1321 - val_recall_5: 0.7281\n",
      "Epoch 805/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6280 - precision_8: 0.1138 - recall_5: 0.3615 - val_loss: 0.3997 - val_precision_8: 0.1360 - val_recall_5: 0.6705\n",
      "Epoch 806/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6387 - precision_8: 0.1057 - recall_5: 0.3157 - val_loss: 0.4049 - val_precision_8: 0.1338 - val_recall_5: 0.7373\n",
      "Epoch 807/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6392 - precision_8: 0.1070 - recall_5: 0.3415 - val_loss: 0.4132 - val_precision_8: 0.1292 - val_recall_5: 0.7972\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6309 - precision_8: 0.1110 - recall_5: 0.3856 - val_loss: 0.4255 - val_precision_8: 0.1202 - val_recall_5: 0.8041\n",
      "Epoch 809/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6308 - precision_8: 0.1088 - recall_5: 0.4049 - val_loss: 0.4293 - val_precision_8: 0.1190 - val_recall_5: 0.8111\n",
      "Epoch 810/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6327 - precision_8: 0.1072 - recall_5: 0.4020 - val_loss: 0.4266 - val_precision_8: 0.1195 - val_recall_5: 0.8041\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6292 - precision_8: 0.1076 - recall_5: 0.3961 - val_loss: 0.4188 - val_precision_8: 0.1239 - val_recall_5: 0.7972\n",
      "Epoch 812/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6371 - precision_8: 0.1065 - recall_5: 0.3732 - val_loss: 0.4127 - val_precision_8: 0.1280 - val_recall_5: 0.7811\n",
      "Epoch 813/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6314 - precision_8: 0.1077 - recall_5: 0.3633 - val_loss: 0.4116 - val_precision_8: 0.1290 - val_recall_5: 0.7742\n",
      "Epoch 814/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6349 - precision_8: 0.1079 - recall_5: 0.3568 - val_loss: 0.4127 - val_precision_8: 0.1285 - val_recall_5: 0.7811\n",
      "Epoch 815/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6346 - precision_8: 0.1037 - recall_5: 0.3474 - val_loss: 0.4153 - val_precision_8: 0.1281 - val_recall_5: 0.7972\n",
      "Epoch 816/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6272 - precision_8: 0.1073 - recall_5: 0.3697 - val_loss: 0.4184 - val_precision_8: 0.1241 - val_recall_5: 0.7972\n",
      "Epoch 817/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6217 - precision_8: 0.1132 - recall_5: 0.4032 - val_loss: 0.4216 - val_precision_8: 0.1218 - val_recall_5: 0.7995\n",
      "Epoch 818/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6279 - precision_8: 0.1080 - recall_5: 0.3926 - val_loss: 0.4242 - val_precision_8: 0.1207 - val_recall_5: 0.8018\n",
      "Epoch 819/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6305 - precision_8: 0.1060 - recall_5: 0.3850 - val_loss: 0.4211 - val_precision_8: 0.1224 - val_recall_5: 0.7972\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6285 - precision_8: 0.1075 - recall_5: 0.3809 - val_loss: 0.4180 - val_precision_8: 0.1261 - val_recall_5: 0.7926\n",
      "Epoch 821/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6302 - precision_8: 0.1064 - recall_5: 0.3633 - val_loss: 0.4148 - val_precision_8: 0.1306 - val_recall_5: 0.7857\n",
      "Epoch 822/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6325 - precision_8: 0.1114 - recall_5: 0.3515 - val_loss: 0.4156 - val_precision_8: 0.1301 - val_recall_5: 0.7857\n",
      "Epoch 823/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6314 - precision_8: 0.1043 - recall_5: 0.3521 - val_loss: 0.4269 - val_precision_8: 0.1212 - val_recall_5: 0.8088\n",
      "Epoch 824/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6238 - precision_8: 0.1101 - recall_5: 0.4020 - val_loss: 0.4364 - val_precision_8: 0.1173 - val_recall_5: 0.8203\n",
      "Epoch 825/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6229 - precision_8: 0.1112 - recall_5: 0.4302 - val_loss: 0.4356 - val_precision_8: 0.1175 - val_recall_5: 0.8180\n",
      "Epoch 826/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6227 - precision_8: 0.1142 - recall_5: 0.4255 - val_loss: 0.4243 - val_precision_8: 0.1224 - val_recall_5: 0.8018\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6324 - precision_8: 0.1054 - recall_5: 0.3703 - val_loss: 0.4188 - val_precision_8: 0.1278 - val_recall_5: 0.7903\n",
      "Epoch 828/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6195 - precision_8: 0.1172 - recall_5: 0.3973 - val_loss: 0.4245 - val_precision_8: 0.1222 - val_recall_5: 0.7995\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6220 - precision_8: 0.1113 - recall_5: 0.3979 - val_loss: 0.4305 - val_precision_8: 0.1196 - val_recall_5: 0.8088\n",
      "Epoch 830/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6301 - precision_8: 0.1083 - recall_5: 0.3979 - val_loss: 0.4221 - val_precision_8: 0.1246 - val_recall_5: 0.7972\n",
      "Epoch 831/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6264 - precision_8: 0.1071 - recall_5: 0.3697 - val_loss: 0.4168 - val_precision_8: 0.1285 - val_recall_5: 0.7742\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6179 - precision_8: 0.1084 - recall_5: 0.3756 - val_loss: 0.4245 - val_precision_8: 0.1221 - val_recall_5: 0.7995\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6264 - precision_8: 0.1093 - recall_5: 0.3955 - val_loss: 0.4280 - val_precision_8: 0.1201 - val_recall_5: 0.8041\n",
      "Epoch 834/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6268 - precision_8: 0.1094 - recall_5: 0.4032 - val_loss: 0.4263 - val_precision_8: 0.1214 - val_recall_5: 0.8018\n",
      "Epoch 835/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6158 - precision_8: 0.1142 - recall_5: 0.4237 - val_loss: 0.4234 - val_precision_8: 0.1236 - val_recall_5: 0.7972\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6238 - precision_8: 0.1092 - recall_5: 0.3914 - val_loss: 0.4200 - val_precision_8: 0.1277 - val_recall_5: 0.7903\n",
      "Epoch 837/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6100 - precision_8: 0.1181 - recall_5: 0.4079 - val_loss: 0.4214 - val_precision_8: 0.1261 - val_recall_5: 0.7926\n",
      "Epoch 838/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6157 - precision_8: 0.1144 - recall_5: 0.4137 - val_loss: 0.4291 - val_precision_8: 0.1199 - val_recall_5: 0.8041\n",
      "Epoch 839/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6242 - precision_8: 0.1073 - recall_5: 0.3996 - val_loss: 0.4248 - val_precision_8: 0.1226 - val_recall_5: 0.7995\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6251 - precision_8: 0.1067 - recall_5: 0.3873 - val_loss: 0.4185 - val_precision_8: 0.1280 - val_recall_5: 0.7719\n",
      "Epoch 841/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6190 - precision_8: 0.1132 - recall_5: 0.3850 - val_loss: 0.4220 - val_precision_8: 0.1262 - val_recall_5: 0.7926\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6239 - precision_8: 0.1083 - recall_5: 0.3879 - val_loss: 0.4256 - val_precision_8: 0.1227 - val_recall_5: 0.7995\n",
      "Epoch 843/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6178 - precision_8: 0.1096 - recall_5: 0.3991 - val_loss: 0.4243 - val_precision_8: 0.1241 - val_recall_5: 0.7995\n",
      "Epoch 844/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6276 - precision_8: 0.1063 - recall_5: 0.3785 - val_loss: 0.4245 - val_precision_8: 0.1238 - val_recall_5: 0.7995\n",
      "Epoch 845/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6179 - precision_8: 0.1120 - recall_5: 0.4167 - val_loss: 0.4267 - val_precision_8: 0.1219 - val_recall_5: 0.7995\n",
      "Epoch 846/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6275 - precision_8: 0.1055 - recall_5: 0.3850 - val_loss: 0.4230 - val_precision_8: 0.1263 - val_recall_5: 0.7972\n",
      "Epoch 847/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6119 - precision_8: 0.1145 - recall_5: 0.4161 - val_loss: 0.4267 - val_precision_8: 0.1219 - val_recall_5: 0.7995\n",
      "Epoch 848/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6243 - precision_8: 0.1074 - recall_5: 0.3979 - val_loss: 0.4236 - val_precision_8: 0.1255 - val_recall_5: 0.7972\n",
      "Epoch 849/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6204 - precision_8: 0.1108 - recall_5: 0.3944 - val_loss: 0.4181 - val_precision_8: 0.1286 - val_recall_5: 0.7373\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6243 - precision_8: 0.1122 - recall_5: 0.3609 - val_loss: 0.4158 - val_precision_8: 0.1310 - val_recall_5: 0.6705\n",
      "Epoch 851/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6284 - precision_8: 0.1091 - recall_5: 0.3539 - val_loss: 0.4232 - val_precision_8: 0.1251 - val_recall_5: 0.7834\n",
      "Epoch 852/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6122 - precision_8: 0.1127 - recall_5: 0.4219 - val_loss: 0.4252 - val_precision_8: 0.1234 - val_recall_5: 0.7903\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6144 - precision_8: 0.1148 - recall_5: 0.3950 - val_loss: 0.4153 - val_precision_8: 0.1242 - val_recall_5: 0.5668\n",
      "Epoch 854/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6278 - precision_8: 0.1107 - recall_5: 0.3316 - val_loss: 0.4180 - val_precision_8: 0.1274 - val_recall_5: 0.6959\n",
      "Epoch 855/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6256 - precision_8: 0.1092 - recall_5: 0.3856 - val_loss: 0.4295 - val_precision_8: 0.1206 - val_recall_5: 0.7949\n",
      "Epoch 856/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6224 - precision_8: 0.1107 - recall_5: 0.4302 - val_loss: 0.4336 - val_precision_8: 0.1198 - val_recall_5: 0.8041\n",
      "Epoch 857/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6226 - precision_8: 0.1058 - recall_5: 0.4161 - val_loss: 0.4331 - val_precision_8: 0.1201 - val_recall_5: 0.8041\n",
      "Epoch 858/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6190 - precision_8: 0.1065 - recall_5: 0.4126 - val_loss: 0.4268 - val_precision_8: 0.1239 - val_recall_5: 0.7903\n",
      "Epoch 859/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6257 - precision_8: 0.1066 - recall_5: 0.3832 - val_loss: 0.4236 - val_precision_8: 0.1262 - val_recall_5: 0.7512\n",
      "Epoch 860/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6346 - precision_8: 0.1020 - recall_5: 0.3509 - val_loss: 0.4226 - val_precision_8: 0.1284 - val_recall_5: 0.7304\n",
      "Epoch 861/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6192 - precision_8: 0.1097 - recall_5: 0.3685 - val_loss: 0.4258 - val_precision_8: 0.1258 - val_recall_5: 0.7627\n",
      "Epoch 862/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6194 - precision_8: 0.1114 - recall_5: 0.3950 - val_loss: 0.4334 - val_precision_8: 0.1209 - val_recall_5: 0.8018\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6287 - precision_8: 0.1081 - recall_5: 0.4173 - val_loss: 0.4364 - val_precision_8: 0.1194 - val_recall_5: 0.8041\n",
      "Epoch 864/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6165 - precision_8: 0.1123 - recall_5: 0.4360 - val_loss: 0.4295 - val_precision_8: 0.1240 - val_recall_5: 0.7903\n",
      "Epoch 865/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6215 - precision_8: 0.1070 - recall_5: 0.3815 - val_loss: 0.4272 - val_precision_8: 0.1245 - val_recall_5: 0.7535\n",
      "Epoch 866/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6212 - precision_8: 0.1082 - recall_5: 0.3897 - val_loss: 0.4318 - val_precision_8: 0.1218 - val_recall_5: 0.7926\n",
      "Epoch 867/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6260 - precision_8: 0.1047 - recall_5: 0.3926 - val_loss: 0.4325 - val_precision_8: 0.1211 - val_recall_5: 0.7926\n",
      "Epoch 868/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6180 - precision_8: 0.1086 - recall_5: 0.4008 - val_loss: 0.4288 - val_precision_8: 0.1244 - val_recall_5: 0.7742\n",
      "Epoch 869/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6208 - precision_8: 0.1076 - recall_5: 0.3856 - val_loss: 0.4268 - val_precision_8: 0.1257 - val_recall_5: 0.7442\n",
      "Epoch 870/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6104 - precision_8: 0.1182 - recall_5: 0.4173 - val_loss: 0.4332 - val_precision_8: 0.1209 - val_recall_5: 0.7926\n",
      "Epoch 871/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6176 - precision_8: 0.1078 - recall_5: 0.4225 - val_loss: 0.4421 - val_precision_8: 0.1165 - val_recall_5: 0.8111\n",
      "Epoch 872/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6163 - precision_8: 0.1084 - recall_5: 0.4378 - val_loss: 0.4325 - val_precision_8: 0.1220 - val_recall_5: 0.7926\n",
      "Epoch 873/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6169 - precision_8: 0.1105 - recall_5: 0.3991 - val_loss: 0.4260 - val_precision_8: 0.1273 - val_recall_5: 0.6774\n",
      "Epoch 874/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6267 - precision_8: 0.1064 - recall_5: 0.3392 - val_loss: 0.4278 - val_precision_8: 0.1267 - val_recall_5: 0.7304\n",
      "Epoch 875/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6137 - precision_8: 0.1138 - recall_5: 0.4043 - val_loss: 0.4354 - val_precision_8: 0.1208 - val_recall_5: 0.7949\n",
      "Epoch 876/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6148 - precision_8: 0.1132 - recall_5: 0.4249 - val_loss: 0.4342 - val_precision_8: 0.1215 - val_recall_5: 0.7926\n",
      "Epoch 877/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6141 - precision_8: 0.1114 - recall_5: 0.4219 - val_loss: 0.4355 - val_precision_8: 0.1207 - val_recall_5: 0.7926\n",
      "Epoch 878/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6119 - precision_8: 0.1083 - recall_5: 0.4143 - val_loss: 0.4361 - val_precision_8: 0.1206 - val_recall_5: 0.7926\n",
      "Epoch 879/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6147 - precision_8: 0.1087 - recall_5: 0.4085 - val_loss: 0.4342 - val_precision_8: 0.1220 - val_recall_5: 0.7834\n",
      "Epoch 880/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6219 - precision_8: 0.1038 - recall_5: 0.3879 - val_loss: 0.4322 - val_precision_8: 0.1234 - val_recall_5: 0.7581\n",
      "Epoch 881/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6182 - precision_8: 0.1084 - recall_5: 0.3727 - val_loss: 0.4297 - val_precision_8: 0.1246 - val_recall_5: 0.6797\n",
      "Epoch 882/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6200 - precision_8: 0.1077 - recall_5: 0.3621 - val_loss: 0.4356 - val_precision_8: 0.1217 - val_recall_5: 0.7880\n",
      "Epoch 883/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6217 - precision_8: 0.1054 - recall_5: 0.4026 - val_loss: 0.4452 - val_precision_8: 0.1160 - val_recall_5: 0.8088\n",
      "Epoch 884/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6289 - precision_8: 0.1032 - recall_5: 0.4131 - val_loss: 0.4391 - val_precision_8: 0.1205 - val_recall_5: 0.7972\n",
      "Epoch 885/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6092 - precision_8: 0.1125 - recall_5: 0.4102 - val_loss: 0.4320 - val_precision_8: 0.1236 - val_recall_5: 0.6797\n",
      "Epoch 886/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6207 - precision_8: 0.1086 - recall_5: 0.3562 - val_loss: 0.4354 - val_precision_8: 0.1221 - val_recall_5: 0.7627\n",
      "Epoch 887/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6165 - precision_8: 0.1089 - recall_5: 0.4190 - val_loss: 0.4525 - val_precision_8: 0.1155 - val_recall_5: 0.8249\n",
      "Epoch 888/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6260 - precision_8: 0.1040 - recall_5: 0.4319 - val_loss: 0.4486 - val_precision_8: 0.1170 - val_recall_5: 0.8203\n",
      "Epoch 889/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6196 - precision_8: 0.1051 - recall_5: 0.4173 - val_loss: 0.4347 - val_precision_8: 0.1223 - val_recall_5: 0.7051\n",
      "Epoch 890/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6190 - precision_8: 0.1143 - recall_5: 0.3721 - val_loss: 0.4337 - val_precision_8: 0.1190 - val_recall_5: 0.6106\n",
      "Epoch 891/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6156 - precision_8: 0.1145 - recall_5: 0.3891 - val_loss: 0.4423 - val_precision_8: 0.1185 - val_recall_5: 0.7903\n",
      "Epoch 892/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6051 - precision_8: 0.1149 - recall_5: 0.4642 - val_loss: 0.4487 - val_precision_8: 0.1167 - val_recall_5: 0.8111\n",
      "Epoch 893/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6173 - precision_8: 0.1101 - recall_5: 0.4384 - val_loss: 0.4370 - val_precision_8: 0.1191 - val_recall_5: 0.7327\n",
      "Epoch 894/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6193 - precision_8: 0.1082 - recall_5: 0.3756 - val_loss: 0.4354 - val_precision_8: 0.1150 - val_recall_5: 0.5876\n",
      "Epoch 895/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6174 - precision_8: 0.1141 - recall_5: 0.3556 - val_loss: 0.4387 - val_precision_8: 0.1200 - val_recall_5: 0.6912\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6143 - precision_8: 0.1102 - recall_5: 0.3885 - val_loss: 0.4499 - val_precision_8: 0.1175 - val_recall_5: 0.8041\n",
      "Epoch 897/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6206 - precision_8: 0.1037 - recall_5: 0.4108 - val_loss: 0.4626 - val_precision_8: 0.1134 - val_recall_5: 0.8272\n",
      "Epoch 898/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6167 - precision_8: 0.1078 - recall_5: 0.4542 - val_loss: 0.4614 - val_precision_8: 0.1138 - val_recall_5: 0.8272\n",
      "Epoch 899/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6151 - precision_8: 0.1049 - recall_5: 0.4331 - val_loss: 0.4488 - val_precision_8: 0.1177 - val_recall_5: 0.7949\n",
      "Epoch 900/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6144 - precision_8: 0.1082 - recall_5: 0.4014 - val_loss: 0.4448 - val_precision_8: 0.1207 - val_recall_5: 0.7650\n",
      "Epoch 901/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6174 - precision_8: 0.1054 - recall_5: 0.3744 - val_loss: 0.4498 - val_precision_8: 0.1169 - val_recall_5: 0.7949\n",
      "Epoch 902/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6125 - precision_8: 0.1097 - recall_5: 0.4284 - val_loss: 0.4535 - val_precision_8: 0.1165 - val_recall_5: 0.8157\n",
      "Epoch 903/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6131 - precision_8: 0.1064 - recall_5: 0.4190 - val_loss: 0.4460 - val_precision_8: 0.1197 - val_recall_5: 0.7696\n",
      "Epoch 904/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6138 - precision_8: 0.1093 - recall_5: 0.3815 - val_loss: 0.4445 - val_precision_8: 0.1228 - val_recall_5: 0.7442\n",
      "Epoch 905/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6142 - precision_8: 0.1067 - recall_5: 0.3856 - val_loss: 0.4546 - val_precision_8: 0.1162 - val_recall_5: 0.8157\n",
      "Epoch 906/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6145 - precision_8: 0.1070 - recall_5: 0.4372 - val_loss: 0.4547 - val_precision_8: 0.1168 - val_recall_5: 0.8180\n",
      "Epoch 907/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6161 - precision_8: 0.1094 - recall_5: 0.4261 - val_loss: 0.4454 - val_precision_8: 0.1221 - val_recall_5: 0.7396\n",
      "Epoch 908/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6119 - precision_8: 0.1128 - recall_5: 0.3779 - val_loss: 0.4451 - val_precision_8: 0.1211 - val_recall_5: 0.6889\n",
      "Epoch 909/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6193 - precision_8: 0.1062 - recall_5: 0.3574 - val_loss: 0.4521 - val_precision_8: 0.1171 - val_recall_5: 0.7972\n",
      "Epoch 910/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6109 - precision_8: 0.1095 - recall_5: 0.4343 - val_loss: 0.4609 - val_precision_8: 0.1143 - val_recall_5: 0.8272\n",
      "Epoch 911/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6160 - precision_8: 0.1049 - recall_5: 0.4313 - val_loss: 0.4530 - val_precision_8: 0.1172 - val_recall_5: 0.7995\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6118 - precision_8: 0.1026 - recall_5: 0.3891 - val_loss: 0.4512 - val_precision_8: 0.1180 - val_recall_5: 0.7857\n",
      "Epoch 913/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6141 - precision_8: 0.1063 - recall_5: 0.4067 - val_loss: 0.4560 - val_precision_8: 0.1161 - val_recall_5: 0.8088\n",
      "Epoch 914/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6161 - precision_8: 0.1058 - recall_5: 0.4137 - val_loss: 0.4567 - val_precision_8: 0.1165 - val_recall_5: 0.8134\n",
      "Epoch 915/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6050 - precision_8: 0.1102 - recall_5: 0.4401 - val_loss: 0.4553 - val_precision_8: 0.1164 - val_recall_5: 0.8018\n",
      "Epoch 916/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6124 - precision_8: 0.1103 - recall_5: 0.4243 - val_loss: 0.4514 - val_precision_8: 0.1186 - val_recall_5: 0.7742\n",
      "Epoch 917/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6133 - precision_8: 0.1057 - recall_5: 0.3903 - val_loss: 0.4595 - val_precision_8: 0.1152 - val_recall_5: 0.8203\n",
      "Epoch 918/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6195 - precision_8: 0.1053 - recall_5: 0.4313 - val_loss: 0.4671 - val_precision_8: 0.1129 - val_recall_5: 0.8295\n",
      "Epoch 919/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6092 - precision_8: 0.1094 - recall_5: 0.4589 - val_loss: 0.4614 - val_precision_8: 0.1147 - val_recall_5: 0.8249\n",
      "Epoch 920/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6068 - precision_8: 0.1093 - recall_5: 0.4390 - val_loss: 0.4597 - val_precision_8: 0.1150 - val_recall_5: 0.8157\n",
      "Epoch 921/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6160 - precision_8: 0.1058 - recall_5: 0.4219 - val_loss: 0.4592 - val_precision_8: 0.1152 - val_recall_5: 0.8134\n",
      "Epoch 922/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6188 - precision_8: 0.1042 - recall_5: 0.4149 - val_loss: 0.4551 - val_precision_8: 0.1176 - val_recall_5: 0.7903\n",
      "Epoch 923/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6107 - precision_8: 0.1101 - recall_5: 0.4085 - val_loss: 0.4550 - val_precision_8: 0.1181 - val_recall_5: 0.7811\n",
      "Epoch 924/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6112 - precision_8: 0.1083 - recall_5: 0.4067 - val_loss: 0.4671 - val_precision_8: 0.1130 - val_recall_5: 0.8272\n",
      "Epoch 925/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6106 - precision_8: 0.1072 - recall_5: 0.4595 - val_loss: 0.4664 - val_precision_8: 0.1129 - val_recall_5: 0.8249\n",
      "Epoch 926/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6086 - precision_8: 0.1116 - recall_5: 0.4308 - val_loss: 0.4569 - val_precision_8: 0.1244 - val_recall_5: 0.7028\n",
      "Epoch 927/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6169 - precision_8: 0.1096 - recall_5: 0.3727 - val_loss: 0.4715 - val_precision_8: 0.1127 - val_recall_5: 0.8364\n",
      "Epoch 928/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6156 - precision_8: 0.1051 - recall_5: 0.4630 - val_loss: 0.4854 - val_precision_8: 0.1105 - val_recall_5: 0.8571\n",
      "Epoch 929/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6054 - precision_8: 0.1103 - recall_5: 0.4765 - val_loss: 0.4621 - val_precision_8: 0.1168 - val_recall_5: 0.8065\n",
      "Epoch 930/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6044 - precision_8: 0.1119 - recall_5: 0.4272 - val_loss: 0.4619 - val_precision_8: 0.1168 - val_recall_5: 0.8065\n",
      "Epoch 931/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6084 - precision_8: 0.1084 - recall_5: 0.4308 - val_loss: 0.4676 - val_precision_8: 0.1135 - val_recall_5: 0.8249\n",
      "Epoch 932/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6213 - precision_8: 0.1039 - recall_5: 0.4196 - val_loss: 0.4598 - val_precision_8: 0.1188 - val_recall_5: 0.7949\n",
      "Epoch 933/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6103 - precision_8: 0.1104 - recall_5: 0.4067 - val_loss: 0.4602 - val_precision_8: 0.1178 - val_recall_5: 0.7972\n",
      "Epoch 934/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6173 - precision_8: 0.1039 - recall_5: 0.4126 - val_loss: 0.4651 - val_precision_8: 0.1148 - val_recall_5: 0.8249\n",
      "Epoch 935/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6102 - precision_8: 0.1097 - recall_5: 0.4531 - val_loss: 0.4574 - val_precision_8: 0.1223 - val_recall_5: 0.7373\n",
      "Epoch 936/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6081 - precision_8: 0.1163 - recall_5: 0.3803 - val_loss: 0.4593 - val_precision_8: 0.1176 - val_recall_5: 0.7926\n",
      "Epoch 937/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6136 - precision_8: 0.1064 - recall_5: 0.4384 - val_loss: 0.4905 - val_precision_8: 0.1108 - val_recall_5: 0.8687\n",
      "Epoch 938/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6171 - precision_8: 0.1087 - recall_5: 0.4982 - val_loss: 0.4642 - val_precision_8: 0.1163 - val_recall_5: 0.8249\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6062 - precision_8: 0.1077 - recall_5: 0.4090 - val_loss: 0.4587 - val_precision_8: 0.1207 - val_recall_5: 0.7166\n",
      "Epoch 940/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6091 - precision_8: 0.1085 - recall_5: 0.3979 - val_loss: 0.4687 - val_precision_8: 0.1134 - val_recall_5: 0.8295\n",
      "Epoch 941/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6065 - precision_8: 0.1093 - recall_5: 0.4642 - val_loss: 0.4682 - val_precision_8: 0.1135 - val_recall_5: 0.8272\n",
      "Epoch 942/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6054 - precision_8: 0.1094 - recall_5: 0.4648 - val_loss: 0.4638 - val_precision_8: 0.1158 - val_recall_5: 0.8203\n",
      "Epoch 943/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6075 - precision_8: 0.1101 - recall_5: 0.4343 - val_loss: 0.4605 - val_precision_8: 0.1175 - val_recall_5: 0.7949\n",
      "Epoch 944/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6082 - precision_8: 0.1077 - recall_5: 0.4219 - val_loss: 0.4612 - val_precision_8: 0.1160 - val_recall_5: 0.7972\n",
      "Epoch 945/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6057 - precision_8: 0.1101 - recall_5: 0.4384 - val_loss: 0.4617 - val_precision_8: 0.1160 - val_recall_5: 0.8065\n",
      "Epoch 946/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6089 - precision_8: 0.1078 - recall_5: 0.4325 - val_loss: 0.4619 - val_precision_8: 0.1161 - val_recall_5: 0.8111\n",
      "Epoch 947/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6123 - precision_8: 0.1064 - recall_5: 0.4437 - val_loss: 0.4660 - val_precision_8: 0.1142 - val_recall_5: 0.8272\n",
      "Epoch 948/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6115 - precision_8: 0.1044 - recall_5: 0.4354 - val_loss: 0.4610 - val_precision_8: 0.1167 - val_recall_5: 0.8018\n",
      "Epoch 949/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6024 - precision_8: 0.1094 - recall_5: 0.4448 - val_loss: 0.4651 - val_precision_8: 0.1146 - val_recall_5: 0.8249\n",
      "Epoch 950/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6069 - precision_8: 0.1085 - recall_5: 0.4577 - val_loss: 0.4633 - val_precision_8: 0.1152 - val_recall_5: 0.8134\n",
      "Epoch 951/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6031 - precision_8: 0.1087 - recall_5: 0.4501 - val_loss: 0.4606 - val_precision_8: 0.1168 - val_recall_5: 0.7811\n",
      "Epoch 952/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6051 - precision_8: 0.1096 - recall_5: 0.4302 - val_loss: 0.4626 - val_precision_8: 0.1167 - val_recall_5: 0.8088\n",
      "Epoch 953/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6056 - precision_8: 0.1080 - recall_5: 0.4425 - val_loss: 0.4627 - val_precision_8: 0.1167 - val_recall_5: 0.8041\n",
      "Epoch 954/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6024 - precision_8: 0.1134 - recall_5: 0.4566 - val_loss: 0.4646 - val_precision_8: 0.1153 - val_recall_5: 0.8157\n",
      "Epoch 955/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6112 - precision_8: 0.1087 - recall_5: 0.4407 - val_loss: 0.4629 - val_precision_8: 0.1166 - val_recall_5: 0.8065\n",
      "Epoch 956/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5986 - precision_8: 0.1118 - recall_5: 0.4671 - val_loss: 0.4688 - val_precision_8: 0.1134 - val_recall_5: 0.8272\n",
      "Epoch 957/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6068 - precision_8: 0.1076 - recall_5: 0.4654 - val_loss: 0.4630 - val_precision_8: 0.1164 - val_recall_5: 0.8088\n",
      "Epoch 958/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6115 - precision_8: 0.1073 - recall_5: 0.4090 - val_loss: 0.4610 - val_precision_8: 0.1174 - val_recall_5: 0.7696\n",
      "Epoch 959/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6035 - precision_8: 0.1132 - recall_5: 0.4554 - val_loss: 0.4681 - val_precision_8: 0.1135 - val_recall_5: 0.8272\n",
      "Epoch 960/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6136 - precision_8: 0.1031 - recall_5: 0.4343 - val_loss: 0.4611 - val_precision_8: 0.1164 - val_recall_5: 0.7719\n",
      "Epoch 961/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6125 - precision_8: 0.1046 - recall_5: 0.3932 - val_loss: 0.4616 - val_precision_8: 0.1183 - val_recall_5: 0.7488\n",
      "Epoch 962/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6132 - precision_8: 0.1074 - recall_5: 0.3908 - val_loss: 0.4667 - val_precision_8: 0.1139 - val_recall_5: 0.8180\n",
      "Epoch 963/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6074 - precision_8: 0.1089 - recall_5: 0.4671 - val_loss: 0.4698 - val_precision_8: 0.1131 - val_recall_5: 0.8295\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5986 - precision_8: 0.1113 - recall_5: 0.4607 - val_loss: 0.4634 - val_precision_8: 0.1168 - val_recall_5: 0.7972\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6103 - precision_8: 0.1035 - recall_5: 0.4196 - val_loss: 0.4688 - val_precision_8: 0.1138 - val_recall_5: 0.8295\n",
      "Epoch 966/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6059 - precision_8: 0.1058 - recall_5: 0.4419 - val_loss: 0.4640 - val_precision_8: 0.1169 - val_recall_5: 0.8018\n",
      "Epoch 967/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6147 - precision_8: 0.1036 - recall_5: 0.3950 - val_loss: 0.4651 - val_precision_8: 0.1155 - val_recall_5: 0.8088\n",
      "Epoch 968/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6020 - precision_8: 0.1105 - recall_5: 0.4689 - val_loss: 0.4737 - val_precision_8: 0.1117 - val_recall_5: 0.8318\n",
      "Epoch 969/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6050 - precision_8: 0.1114 - recall_5: 0.4730 - val_loss: 0.4649 - val_precision_8: 0.1173 - val_recall_5: 0.7903\n",
      "Epoch 970/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6093 - precision_8: 0.1077 - recall_5: 0.4313 - val_loss: 0.4745 - val_precision_8: 0.1114 - val_recall_5: 0.8341\n",
      "Epoch 971/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6070 - precision_8: 0.1072 - recall_5: 0.4759 - val_loss: 0.4748 - val_precision_8: 0.1114 - val_recall_5: 0.8341\n",
      "Epoch 972/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6070 - precision_8: 0.1113 - recall_5: 0.4665 - val_loss: 0.4662 - val_precision_8: 0.1187 - val_recall_5: 0.7696\n",
      "Epoch 973/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6088 - precision_8: 0.1076 - recall_5: 0.3985 - val_loss: 0.4695 - val_precision_8: 0.1139 - val_recall_5: 0.8272\n",
      "Epoch 974/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6024 - precision_8: 0.1046 - recall_5: 0.4636 - val_loss: 0.4762 - val_precision_8: 0.1107 - val_recall_5: 0.8341\n",
      "Epoch 975/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6032 - precision_8: 0.1079 - recall_5: 0.4718 - val_loss: 0.4667 - val_precision_8: 0.1178 - val_recall_5: 0.7857\n",
      "Epoch 976/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6051 - precision_8: 0.1094 - recall_5: 0.4255 - val_loss: 0.4671 - val_precision_8: 0.1157 - val_recall_5: 0.8065\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6044 - precision_8: 0.1072 - recall_5: 0.4337 - val_loss: 0.4765 - val_precision_8: 0.1106 - val_recall_5: 0.8341\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6068 - precision_8: 0.1065 - recall_5: 0.4894 - val_loss: 0.4723 - val_precision_8: 0.1126 - val_recall_5: 0.8318\n",
      "Epoch 979/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6054 - precision_8: 0.1092 - recall_5: 0.4384 - val_loss: 0.4688 - val_precision_8: 0.1207 - val_recall_5: 0.7581\n",
      "Epoch 980/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6045 - precision_8: 0.1067 - recall_5: 0.4219 - val_loss: 0.4752 - val_precision_8: 0.1110 - val_recall_5: 0.8341\n",
      "Epoch 981/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6034 - precision_8: 0.1070 - recall_5: 0.4648 - val_loss: 0.4673 - val_precision_8: 0.1151 - val_recall_5: 0.8111\n",
      "Epoch 982/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6095 - precision_8: 0.1085 - recall_5: 0.4531 - val_loss: 0.4706 - val_precision_8: 0.1134 - val_recall_5: 0.8295\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5994 - precision_8: 0.1153 - recall_5: 0.5123 - val_loss: 0.4678 - val_precision_8: 0.1145 - val_recall_5: 0.8134\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6083 - precision_8: 0.1098 - recall_5: 0.4249 - val_loss: 0.4678 - val_precision_8: 0.1164 - val_recall_5: 0.7857\n",
      "Epoch 985/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6043 - precision_8: 0.1091 - recall_5: 0.4671 - val_loss: 0.4770 - val_precision_8: 0.1103 - val_recall_5: 0.8341\n",
      "Epoch 986/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5973 - precision_8: 0.1096 - recall_5: 0.4789 - val_loss: 0.4687 - val_precision_8: 0.1154 - val_recall_5: 0.8065\n",
      "Epoch 987/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6069 - precision_8: 0.1069 - recall_5: 0.4536 - val_loss: 0.4740 - val_precision_8: 0.1121 - val_recall_5: 0.8318\n",
      "Epoch 988/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6092 - precision_8: 0.1050 - recall_5: 0.4636 - val_loss: 0.4704 - val_precision_8: 0.1149 - val_recall_5: 0.8249\n",
      "Epoch 989/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6063 - precision_8: 0.1065 - recall_5: 0.4401 - val_loss: 0.4702 - val_precision_8: 0.1151 - val_recall_5: 0.8249\n",
      "Epoch 990/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5942 - precision_8: 0.1122 - recall_5: 0.4842 - val_loss: 0.4716 - val_precision_8: 0.1134 - val_recall_5: 0.8295\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5986 - precision_8: 0.1090 - recall_5: 0.4607 - val_loss: 0.4695 - val_precision_8: 0.1182 - val_recall_5: 0.7650\n",
      "Epoch 992/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6059 - precision_8: 0.1114 - recall_5: 0.4102 - val_loss: 0.4683 - val_precision_8: 0.1151 - val_recall_5: 0.8088\n",
      "Epoch 993/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6114 - precision_8: 0.1046 - recall_5: 0.4202 - val_loss: 0.4703 - val_precision_8: 0.1144 - val_recall_5: 0.8295\n",
      "Epoch 994/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6005 - precision_8: 0.1130 - recall_5: 0.4765 - val_loss: 0.4693 - val_precision_8: 0.1154 - val_recall_5: 0.8088\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6034 - precision_8: 0.1141 - recall_5: 0.4495 - val_loss: 0.4760 - val_precision_8: 0.1111 - val_recall_5: 0.8341\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6051 - precision_8: 0.1125 - recall_5: 0.4982 - val_loss: 0.4702 - val_precision_8: 0.1155 - val_recall_5: 0.8088\n",
      "Epoch 997/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6023 - precision_8: 0.1083 - recall_5: 0.4202 - val_loss: 0.4705 - val_precision_8: 0.1151 - val_recall_5: 0.8111\n",
      "Epoch 998/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6061 - precision_8: 0.1098 - recall_5: 0.4583 - val_loss: 0.4825 - val_precision_8: 0.1101 - val_recall_5: 0.8456\n",
      "Epoch 999/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6076 - precision_8: 0.1075 - recall_5: 0.4707 - val_loss: 0.4725 - val_precision_8: 0.1165 - val_recall_5: 0.7834\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6076 - precision_8: 0.1078 - recall_5: 0.4167 - val_loss: 0.4782 - val_precision_8: 0.1107 - val_recall_5: 0.8341\n"
     ]
    }
   ],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "EPOCHS = 1000\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:24:54.107607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 971ms/step - loss: 0.4769 - precision_8: 0.1107 - recall_5: 0.8411\n",
      "loss :  0.47686511278152466\n",
      "precision_8 :  0.11072834581136703\n",
      "recall_5 :  0.84112149477005\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  11476\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  3614\n",
      "Fraudulent Transactions Missed (False Negatives):  85\n",
      "Fraudulent Transactions Detected (True Positives):  450\n",
      "Total Fraudulent Transactions:  535\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
    "                                           batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_weighted,threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mac",
   "language": "python",
   "name": "tf_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
