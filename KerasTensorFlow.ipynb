{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.layers import Flatten\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CMI_C01</th>\n",
       "      <th>CMI_C02</th>\n",
       "      <th>CMI_C03</th>\n",
       "      <th>CMI_C04</th>\n",
       "      <th>CMI_C05</th>\n",
       "      <th>CMI_C06</th>\n",
       "      <th>CMI_C07</th>\n",
       "      <th>CMI_C08</th>\n",
       "      <th>CMI_C09</th>\n",
       "      <th>...</th>\n",
       "      <th>CMI_C14</th>\n",
       "      <th>CMI_C15</th>\n",
       "      <th>CMI_C16</th>\n",
       "      <th>ACM</th>\n",
       "      <th>BCM</th>\n",
       "      <th>Cloud_Probabilities</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.481706</td>\n",
       "      <td>0.431289</td>\n",
       "      <td>0.579424</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.478710</td>\n",
       "      <td>0.376825</td>\n",
       "      <td>302.55830</td>\n",
       "      <td>239.46284</td>\n",
       "      <td>247.80550</td>\n",
       "      <td>...</td>\n",
       "      <td>275.37940</td>\n",
       "      <td>274.17140</td>\n",
       "      <td>263.11536</td>\n",
       "      <td>2.156176</td>\n",
       "      <td>0.937424</td>\n",
       "      <td>0.762866</td>\n",
       "      <td>40.131033</td>\n",
       "      <td>-93.381551</td>\n",
       "      <td>(40.13103323474366, -93.38155072424266)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.365158</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.495337</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.376627</td>\n",
       "      <td>0.285793</td>\n",
       "      <td>300.49400</td>\n",
       "      <td>239.29651</td>\n",
       "      <td>247.77374</td>\n",
       "      <td>...</td>\n",
       "      <td>276.07140</td>\n",
       "      <td>274.72607</td>\n",
       "      <td>263.44934</td>\n",
       "      <td>1.843675</td>\n",
       "      <td>0.843675</td>\n",
       "      <td>0.530524</td>\n",
       "      <td>40.126986</td>\n",
       "      <td>-93.274144</td>\n",
       "      <td>(40.12698592712501, -93.2741436595977)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.318968</td>\n",
       "      <td>0.255297</td>\n",
       "      <td>0.471785</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.333135</td>\n",
       "      <td>0.245873</td>\n",
       "      <td>299.16797</td>\n",
       "      <td>238.83704</td>\n",
       "      <td>247.44296</td>\n",
       "      <td>...</td>\n",
       "      <td>276.19113</td>\n",
       "      <td>274.57343</td>\n",
       "      <td>263.16013</td>\n",
       "      <td>1.874843</td>\n",
       "      <td>0.812655</td>\n",
       "      <td>0.615035</td>\n",
       "      <td>40.122966</td>\n",
       "      <td>-93.166853</td>\n",
       "      <td>(40.122965705716815, -93.16685328500078)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.310932</td>\n",
       "      <td>0.245516</td>\n",
       "      <td>0.473551</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.323313</td>\n",
       "      <td>0.240774</td>\n",
       "      <td>298.23325</td>\n",
       "      <td>237.81775</td>\n",
       "      <td>246.41095</td>\n",
       "      <td>...</td>\n",
       "      <td>274.68738</td>\n",
       "      <td>272.76428</td>\n",
       "      <td>261.35620</td>\n",
       "      <td>2.905629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980994</td>\n",
       "      <td>40.118972</td>\n",
       "      <td>-93.059679</td>\n",
       "      <td>(40.11897247748837, -93.05967862352706)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.373254</td>\n",
       "      <td>0.310456</td>\n",
       "      <td>0.511190</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>0.365952</td>\n",
       "      <td>0.287559</td>\n",
       "      <td>295.21048</td>\n",
       "      <td>235.05566</td>\n",
       "      <td>243.14026</td>\n",
       "      <td>...</td>\n",
       "      <td>267.70728</td>\n",
       "      <td>265.78076</td>\n",
       "      <td>255.51756</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999029</td>\n",
       "      <td>40.115006</td>\n",
       "      <td>-92.952619</td>\n",
       "      <td>(40.115006150366405, -92.95261870531907)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   CMI_C01   CMI_C02   CMI_C03   CMI_C04   CMI_C05   CMI_C06  \\\n",
       "0           0  0.481706  0.431289  0.579424  0.002143  0.478710  0.376825   \n",
       "1           1  0.365158  0.305932  0.495337  0.002024  0.376627  0.285793   \n",
       "2           2  0.318968  0.255297  0.471785  0.003135  0.333135  0.245873   \n",
       "3           3  0.310932  0.245516  0.473551  0.006746  0.323313  0.240774   \n",
       "4           4  0.373254  0.310456  0.511190  0.020992  0.365952  0.287559   \n",
       "\n",
       "     CMI_C07    CMI_C08    CMI_C09  ...    CMI_C14    CMI_C15    CMI_C16  \\\n",
       "0  302.55830  239.46284  247.80550  ...  275.37940  274.17140  263.11536   \n",
       "1  300.49400  239.29651  247.77374  ...  276.07140  274.72607  263.44934   \n",
       "2  299.16797  238.83704  247.44296  ...  276.19113  274.57343  263.16013   \n",
       "3  298.23325  237.81775  246.41095  ...  274.68738  272.76428  261.35620   \n",
       "4  295.21048  235.05566  243.14026  ...  267.70728  265.78076  255.51756   \n",
       "\n",
       "        ACM       BCM  Cloud_Probabilities        lat        lon  \\\n",
       "0  2.156176  0.937424             0.762866  40.131033 -93.381551   \n",
       "1  1.843675  0.843675             0.530524  40.126986 -93.274144   \n",
       "2  1.874843  0.812655             0.615035  40.122966 -93.166853   \n",
       "3  2.905629  1.000000             0.980994  40.118972 -93.059679   \n",
       "4  3.000000  1.000000             0.999029  40.115006 -92.952619   \n",
       "\n",
       "                                Coordinates  Lightning  \n",
       "0   (40.13103323474366, -93.38155072424266)          1  \n",
       "1    (40.12698592712501, -93.2741436595977)          0  \n",
       "2  (40.122965705716815, -93.16685328500078)          0  \n",
       "3   (40.11897247748837, -93.05967862352706)          0  \n",
       "4  (40.115006150366405, -92.95261870531907)          0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/robbiefeldstein/Documents/Programming/Research/Datasets/May_22.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 312500\n",
      "    Positive: 64000 (20.48% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Look at class imbalance\n",
    "\n",
    "neg, pos = np.bincount(df['Lightning'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"CMI_C01\", \"CMI_C02\", \"CMI_C03\",\"CMI_C04\", \"CMI_C05\",\"CMI_C06\", \"CMI_C07\",\"CMI_C15\",\"Cloud_Probabilities\",\"Lightning\"]\n",
    "#let's just do less features\n",
    "#Predictors\n",
    "\n",
    "copy_df = df.copy()\n",
    "copy_df = copy_df[features]\n",
    "\n",
    "X = copy_df[features]\n",
    "\n",
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(copy_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Lightning'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Lightning'))\n",
    "test_labels = np.array(test_df.pop('Lightning'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class probability in training set:   0.2043\n",
      "Average class probability in validation set: 0.2041\n",
      "Average class probability in test set:       0.2071\n"
     ]
    }
   ],
   "source": [
    "#Averages are roughly similar\n",
    "\n",
    "print(f'Average class probability in training set:   {train_labels.mean():.4f}')\n",
    "print(f'Average class probability in validation set: {val_labels.mean():.4f}')\n",
    "print(f'Average class probability in test set:       {test_labels.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (200000,)\n",
      "Validation labels shape: (50000,)\n",
      "Test labels shape: (62500,)\n",
      "Training features shape: (200000, 9)\n",
      "Validation features shape: (50000, 9)\n",
      "Test features shape: (62500, 9)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 15:21:25.821409: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-10-28 15:21:25.821433: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-10-28 15:21:25.821439: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-10-28 15:21:25.821504: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-28 15:21:25.821537: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#Recommended parameters for imbalanced model\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "      keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Dense(len(features), activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    #Output layer\n",
    "    keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.FalsePositives(), tf.keras.metrics.Precision()])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 128\n",
    "BATCH_SIZE = 16384\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.58572139]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                100       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 10)                40        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                176       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501 (1.96 KB)\n",
      "Trainable params: 481 (1.88 KB)\n",
      "Non-trainable params: 20 (80.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initial_bias = np.log([pos/len(df)])\n",
    "print(initial_bias)\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 15:21:27.075345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 15:21:29.999355: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 496ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05333985],\n",
       "       [0.09517443],\n",
       "       [0.31102636],\n",
       "       [0.0891537 ],\n",
       "       [0.28324202],\n",
       "       [0.10903572],\n",
       "       [0.30821165],\n",
       "       [0.22181803],\n",
       "       [0.06279704],\n",
       "       [0.20257062]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n",
    "\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model()\n",
    "# model.load_weights(initial_weights)\n",
    "# model.layers[-1].bias.assign([0.0])\n",
    "# zero_bias_history = model.fit(\n",
    "#     train_features,\n",
    "#     train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=16,\n",
    "#     validation_data=(val_features, val_labels), \n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model()\n",
    "# model.load_weights(initial_weights)\n",
    "# careful_bias_history = model.fit(\n",
    "#     train_features,\n",
    "#     train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=16,\n",
    "#     validation_data=(val_features, val_labels), \n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
    "# plot_loss(careful_bias_history, \"Careful Bias\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'precision',]\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > threshold)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(threshold))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.63\n",
      "Weight for class 1: 2.44\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 15:22:13.935629: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - ETA: 0s - loss: 2.3399 - false_positives_3: 35156.0000 - precision_3: 0.1972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 15:22:21.658589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 10s 433ms/step - loss: 2.3399 - false_positives_3: 35156.0000 - precision_3: 0.1972 - val_loss: 0.5860 - val_false_positives_3: 1477.0000 - val_precision_3: 0.0160\n",
      "Epoch 2/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.9814 - false_positives_3: 33927.0000 - precision_3: 0.2009 - val_loss: 0.5166 - val_false_positives_3: 1101.0000 - val_precision_3: 0.0134\n",
      "Epoch 3/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.7375 - false_positives_3: 32513.0000 - precision_3: 0.2165 - val_loss: 0.4818 - val_false_positives_3: 509.0000 - val_precision_3: 0.0078\n",
      "Epoch 4/150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.6030 - false_positives_3: 32604.0000 - precision_3: 0.2220 - val_loss: 0.4640 - val_false_positives_3: 86.0000 - val_precision_3: 0.4819\n",
      "Epoch 5/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.5037 - false_positives_3: 31713.0000 - precision_3: 0.2321 - val_loss: 0.4596 - val_false_positives_3: 1598.0000 - val_precision_3: 0.4189\n",
      "Epoch 6/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.4453 - false_positives_3: 32273.0000 - precision_3: 0.2375 - val_loss: 0.4641 - val_false_positives_3: 4277.0000 - val_precision_3: 0.4654\n",
      "Epoch 7/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.3948 - false_positives_3: 31970.0000 - precision_3: 0.2483 - val_loss: 0.4725 - val_false_positives_3: 6312.0000 - val_precision_3: 0.4638\n",
      "Epoch 8/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.3582 - false_positives_3: 32411.0000 - precision_3: 0.2513 - val_loss: 0.4826 - val_false_positives_3: 7546.0000 - val_precision_3: 0.4504\n",
      "Epoch 9/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.3406 - false_positives_3: 32543.0000 - precision_3: 0.2533 - val_loss: 0.4940 - val_false_positives_3: 8757.0000 - val_precision_3: 0.4272\n",
      "Epoch 10/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.3156 - false_positives_3: 32933.0000 - precision_3: 0.2583 - val_loss: 0.5053 - val_false_positives_3: 9538.0000 - val_precision_3: 0.4160\n",
      "Epoch 11/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.3059 - false_positives_3: 33831.0000 - precision_3: 0.2583 - val_loss: 0.5169 - val_false_positives_3: 10179.0000 - val_precision_3: 0.4073\n",
      "Epoch 12/150\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 1.2962 - false_positives_3: 34317.0000 - precision_3: 0.2581 - val_loss: 0.5291 - val_false_positives_3: 10826.0000 - val_precision_3: 0.3992\n",
      "Epoch 13/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.2722 - false_positives_3: 34752.0000 - precision_3: 0.2594 - val_loss: 0.5416 - val_false_positives_3: 11329.0000 - val_precision_3: 0.3928\n",
      "Epoch 14/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2561 - false_positives_3: 35526.0000 - precision_3: 0.2590 - val_loss: 0.5546 - val_false_positives_3: 11772.0000 - val_precision_3: 0.3885\n",
      "Epoch 15/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2448 - false_positives_3: 35942.0000 - precision_3: 0.2604 - val_loss: 0.5654 - val_false_positives_3: 12117.0000 - val_precision_3: 0.3848\n",
      "Epoch 16/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2403 - false_positives_3: 36428.0000 - precision_3: 0.2573 - val_loss: 0.5776 - val_false_positives_3: 12480.0000 - val_precision_3: 0.3805\n",
      "Epoch 17/150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.2313 - false_positives_3: 37329.0000 - precision_3: 0.2574 - val_loss: 0.5895 - val_false_positives_3: 12805.0000 - val_precision_3: 0.3772\n",
      "Epoch 18/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2258 - false_positives_3: 37962.0000 - precision_3: 0.2572 - val_loss: 0.6001 - val_false_positives_3: 13093.0000 - val_precision_3: 0.3742\n",
      "Epoch 19/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2255 - false_positives_3: 38677.0000 - precision_3: 0.2546 - val_loss: 0.6112 - val_false_positives_3: 13367.0000 - val_precision_3: 0.3713\n",
      "Epoch 20/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2149 - false_positives_3: 39473.0000 - precision_3: 0.2507 - val_loss: 0.6201 - val_false_positives_3: 13601.0000 - val_precision_3: 0.3690\n",
      "Epoch 21/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2122 - false_positives_3: 39859.0000 - precision_3: 0.2490 - val_loss: 0.6281 - val_false_positives_3: 13836.0000 - val_precision_3: 0.3667\n",
      "Epoch 22/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2039 - false_positives_3: 40430.0000 - precision_3: 0.2509 - val_loss: 0.6351 - val_false_positives_3: 14033.0000 - val_precision_3: 0.3651\n",
      "Epoch 23/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.2030 - false_positives_3: 40953.0000 - precision_3: 0.2485 - val_loss: 0.6421 - val_false_positives_3: 14206.0000 - val_precision_3: 0.3635\n",
      "Epoch 24/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1960 - false_positives_3: 41450.0000 - precision_3: 0.2488 - val_loss: 0.6464 - val_false_positives_3: 14326.0000 - val_precision_3: 0.3622\n",
      "Epoch 25/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1862 - false_positives_3: 42177.0000 - precision_3: 0.2480 - val_loss: 0.6494 - val_false_positives_3: 14417.0000 - val_precision_3: 0.3616\n",
      "Epoch 26/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1708 - false_positives_3: 42643.0000 - precision_3: 0.2472 - val_loss: 0.6520 - val_false_positives_3: 14513.0000 - val_precision_3: 0.3608\n",
      "Epoch 27/150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.1649 - false_positives_3: 43381.0000 - precision_3: 0.2464 - val_loss: 0.6547 - val_false_positives_3: 14607.0000 - val_precision_3: 0.3599\n",
      "Epoch 28/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1634 - false_positives_3: 43961.0000 - precision_3: 0.2431 - val_loss: 0.6576 - val_false_positives_3: 14721.0000 - val_precision_3: 0.3587\n",
      "Epoch 29/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1541 - false_positives_3: 44235.0000 - precision_3: 0.2472 - val_loss: 0.6597 - val_false_positives_3: 14780.0000 - val_precision_3: 0.3585\n",
      "Epoch 30/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1534 - false_positives_3: 44865.0000 - precision_3: 0.2457 - val_loss: 0.6621 - val_false_positives_3: 14840.0000 - val_precision_3: 0.3579\n",
      "Epoch 31/150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.1514 - false_positives_3: 45023.0000 - precision_3: 0.2434 - val_loss: 0.6647 - val_false_positives_3: 14898.0000 - val_precision_3: 0.3571\n",
      "Epoch 32/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.1348 - false_positives_3: 44921.0000 - precision_3: 0.2470 - val_loss: 0.6679 - val_false_positives_3: 14990.0000 - val_precision_3: 0.3560\n",
      "Epoch 33/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1380 - false_positives_3: 45204.0000 - precision_3: 0.2444 - val_loss: 0.6695 - val_false_positives_3: 15055.0000 - val_precision_3: 0.3557\n",
      "Epoch 34/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1317 - false_positives_3: 45687.0000 - precision_3: 0.2444 - val_loss: 0.6719 - val_false_positives_3: 15115.0000 - val_precision_3: 0.3553\n",
      "Epoch 35/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1287 - false_positives_3: 45542.0000 - precision_3: 0.2461 - val_loss: 0.6738 - val_false_positives_3: 15140.0000 - val_precision_3: 0.3551\n",
      "Epoch 36/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1213 - false_positives_3: 45566.0000 - precision_3: 0.2456 - val_loss: 0.6741 - val_false_positives_3: 15141.0000 - val_precision_3: 0.3552\n",
      "Epoch 37/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1133 - false_positives_3: 45700.0000 - precision_3: 0.2474 - val_loss: 0.6741 - val_false_positives_3: 15140.0000 - val_precision_3: 0.3554\n",
      "Epoch 38/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1058 - false_positives_3: 45957.0000 - precision_3: 0.2464 - val_loss: 0.6744 - val_false_positives_3: 15177.0000 - val_precision_3: 0.3551\n",
      "Epoch 39/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1127 - false_positives_3: 46213.0000 - precision_3: 0.2442 - val_loss: 0.6753 - val_false_positives_3: 15207.0000 - val_precision_3: 0.3551\n",
      "Epoch 40/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0990 - false_positives_3: 46218.0000 - precision_3: 0.2454 - val_loss: 0.6751 - val_false_positives_3: 15191.0000 - val_precision_3: 0.3558\n",
      "Epoch 41/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0937 - false_positives_3: 46302.0000 - precision_3: 0.2464 - val_loss: 0.6754 - val_false_positives_3: 15103.0000 - val_precision_3: 0.3571\n",
      "Epoch 42/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.0958 - false_positives_3: 46678.0000 - precision_3: 0.2438 - val_loss: 0.6763 - val_false_positives_3: 15072.0000 - val_precision_3: 0.3576\n",
      "Epoch 43/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0860 - false_positives_3: 46462.0000 - precision_3: 0.2448 - val_loss: 0.6766 - val_false_positives_3: 15039.0000 - val_precision_3: 0.3578\n",
      "Epoch 44/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.0783 - false_positives_3: 46136.0000 - precision_3: 0.2493 - val_loss: 0.6754 - val_false_positives_3: 14967.0000 - val_precision_3: 0.3585\n",
      "Epoch 45/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0733 - false_positives_3: 46243.0000 - precision_3: 0.2475 - val_loss: 0.6734 - val_false_positives_3: 14883.0000 - val_precision_3: 0.3594\n",
      "Epoch 46/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0594 - false_positives_3: 46114.0000 - precision_3: 0.2482 - val_loss: 0.6701 - val_false_positives_3: 14731.0000 - val_precision_3: 0.3614\n",
      "Epoch 47/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0589 - false_positives_3: 46206.0000 - precision_3: 0.2460 - val_loss: 0.6675 - val_false_positives_3: 14440.0000 - val_precision_3: 0.3654\n",
      "Epoch 48/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0475 - false_positives_3: 46078.0000 - precision_3: 0.2474 - val_loss: 0.6654 - val_false_positives_3: 14127.0000 - val_precision_3: 0.3698\n",
      "Epoch 49/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0384 - false_positives_3: 46058.0000 - precision_3: 0.2481 - val_loss: 0.6632 - val_false_positives_3: 13489.0000 - val_precision_3: 0.3802\n",
      "Epoch 50/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0305 - false_positives_3: 45904.0000 - precision_3: 0.2484 - val_loss: 0.6613 - val_false_positives_3: 13160.0000 - val_precision_3: 0.3856\n",
      "Epoch 51/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.0276 - false_positives_3: 45885.0000 - precision_3: 0.2480 - val_loss: 0.6587 - val_false_positives_3: 12960.0000 - val_precision_3: 0.3881\n",
      "Epoch 52/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0153 - false_positives_3: 45601.0000 - precision_3: 0.2500 - val_loss: 0.6559 - val_false_positives_3: 12776.0000 - val_precision_3: 0.3908\n",
      "Epoch 53/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0031 - false_positives_3: 45504.0000 - precision_3: 0.2524 - val_loss: 0.6518 - val_false_positives_3: 12622.0000 - val_precision_3: 0.3928\n",
      "Epoch 54/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9965 - false_positives_3: 45528.0000 - precision_3: 0.2500 - val_loss: 0.6482 - val_false_positives_3: 12445.0000 - val_precision_3: 0.3952\n",
      "Epoch 55/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9860 - false_positives_3: 45351.0000 - precision_3: 0.2536 - val_loss: 0.6452 - val_false_positives_3: 12214.0000 - val_precision_3: 0.3989\n",
      "Epoch 56/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9800 - false_positives_3: 45457.0000 - precision_3: 0.2516 - val_loss: 0.6415 - val_false_positives_3: 12013.0000 - val_precision_3: 0.4017\n",
      "Epoch 57/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9770 - false_positives_3: 45291.0000 - precision_3: 0.2490 - val_loss: 0.6376 - val_false_positives_3: 11805.0000 - val_precision_3: 0.4048\n",
      "Epoch 58/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9663 - false_positives_3: 45020.0000 - precision_3: 0.2506 - val_loss: 0.6346 - val_false_positives_3: 11669.0000 - val_precision_3: 0.4067\n",
      "Epoch 59/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9555 - false_positives_3: 44648.0000 - precision_3: 0.2540 - val_loss: 0.6315 - val_false_positives_3: 11506.0000 - val_precision_3: 0.4093\n",
      "Epoch 60/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.9491 - false_positives_3: 44331.0000 - precision_3: 0.2553 - val_loss: 0.6281 - val_false_positives_3: 11347.0000 - val_precision_3: 0.4117\n",
      "Epoch 61/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9389 - false_positives_3: 43987.0000 - precision_3: 0.2551 - val_loss: 0.6235 - val_false_positives_3: 11125.0000 - val_precision_3: 0.4153\n",
      "Epoch 62/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9305 - false_positives_3: 43725.0000 - precision_3: 0.2571 - val_loss: 0.6194 - val_false_positives_3: 10948.0000 - val_precision_3: 0.4182\n",
      "Epoch 63/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9236 - false_positives_3: 43543.0000 - precision_3: 0.2560 - val_loss: 0.6151 - val_false_positives_3: 10748.0000 - val_precision_3: 0.4209\n",
      "Epoch 64/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9172 - false_positives_3: 43154.0000 - precision_3: 0.2543 - val_loss: 0.6111 - val_false_positives_3: 10558.0000 - val_precision_3: 0.4238\n",
      "Epoch 65/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.9014 - false_positives_3: 42521.0000 - precision_3: 0.2626 - val_loss: 0.6067 - val_false_positives_3: 10417.0000 - val_precision_3: 0.4261\n",
      "Epoch 66/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8957 - false_positives_3: 42351.0000 - precision_3: 0.2594 - val_loss: 0.6036 - val_false_positives_3: 10252.0000 - val_precision_3: 0.4284\n",
      "Epoch 67/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8895 - false_positives_3: 42071.0000 - precision_3: 0.2605 - val_loss: 0.6005 - val_false_positives_3: 10084.0000 - val_precision_3: 0.4314\n",
      "Epoch 68/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8830 - false_positives_3: 41888.0000 - precision_3: 0.2633 - val_loss: 0.5971 - val_false_positives_3: 9906.0000 - val_precision_3: 0.4335\n",
      "Epoch 69/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.8764 - false_positives_3: 41799.0000 - precision_3: 0.2610 - val_loss: 0.5944 - val_false_positives_3: 9775.0000 - val_precision_3: 0.4352\n",
      "Epoch 70/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8637 - false_positives_3: 41359.0000 - precision_3: 0.2655 - val_loss: 0.5907 - val_false_positives_3: 9583.0000 - val_precision_3: 0.4380\n",
      "Epoch 71/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8589 - false_positives_3: 40793.0000 - precision_3: 0.2642 - val_loss: 0.5876 - val_false_positives_3: 9290.0000 - val_precision_3: 0.4439\n",
      "Epoch 72/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8519 - false_positives_3: 40117.0000 - precision_3: 0.2699 - val_loss: 0.5849 - val_false_positives_3: 9222.0000 - val_precision_3: 0.4451\n",
      "Epoch 73/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8493 - false_positives_3: 39685.0000 - precision_3: 0.2669 - val_loss: 0.5824 - val_false_positives_3: 9145.0000 - val_precision_3: 0.4462\n",
      "Epoch 74/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8410 - false_positives_3: 39217.0000 - precision_3: 0.2684 - val_loss: 0.5804 - val_false_positives_3: 8967.0000 - val_precision_3: 0.4493\n",
      "Epoch 75/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8298 - false_positives_3: 38877.0000 - precision_3: 0.2715 - val_loss: 0.5772 - val_false_positives_3: 8854.0000 - val_precision_3: 0.4507\n",
      "Epoch 76/150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8278 - false_positives_3: 38524.0000 - precision_3: 0.2726 - val_loss: 0.5752 - val_false_positives_3: 8805.0000 - val_precision_3: 0.4509\n",
      "Epoch 77/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.8196 - false_positives_3: 37925.0000 - precision_3: 0.2740 - val_loss: 0.5733 - val_false_positives_3: 8677.0000 - val_precision_3: 0.4533\n",
      "Epoch 78/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8124 - false_positives_3: 37484.0000 - precision_3: 0.2739 - val_loss: 0.5718 - val_false_positives_3: 8464.0000 - val_precision_3: 0.4572\n",
      "Epoch 79/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8036 - false_positives_3: 36702.0000 - precision_3: 0.2802 - val_loss: 0.5698 - val_false_positives_3: 8371.0000 - val_precision_3: 0.4587\n",
      "Epoch 80/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7959 - false_positives_3: 36548.0000 - precision_3: 0.2814 - val_loss: 0.5676 - val_false_positives_3: 8237.0000 - val_precision_3: 0.4609\n",
      "Epoch 81/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7899 - false_positives_3: 35615.0000 - precision_3: 0.2870 - val_loss: 0.5656 - val_false_positives_3: 8076.0000 - val_precision_3: 0.4644\n",
      "Epoch 82/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7852 - false_positives_3: 35054.0000 - precision_3: 0.2877 - val_loss: 0.5632 - val_false_positives_3: 7991.0000 - val_precision_3: 0.4657\n",
      "Epoch 83/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7785 - false_positives_3: 34305.0000 - precision_3: 0.2927 - val_loss: 0.5621 - val_false_positives_3: 7859.0000 - val_precision_3: 0.4688\n",
      "Epoch 84/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7763 - false_positives_3: 33915.0000 - precision_3: 0.2916 - val_loss: 0.5607 - val_false_positives_3: 7689.0000 - val_precision_3: 0.4723\n",
      "Epoch 85/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.7682 - false_positives_3: 33605.0000 - precision_3: 0.2944 - val_loss: 0.5596 - val_false_positives_3: 7473.0000 - val_precision_3: 0.4764\n",
      "Epoch 86/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7636 - false_positives_3: 32852.0000 - precision_3: 0.2996 - val_loss: 0.5579 - val_false_positives_3: 7415.0000 - val_precision_3: 0.4776\n",
      "Epoch 87/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7590 - false_positives_3: 32163.0000 - precision_3: 0.3001 - val_loss: 0.5557 - val_false_positives_3: 7382.0000 - val_precision_3: 0.4784\n",
      "Epoch 88/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7560 - false_positives_3: 31516.0000 - precision_3: 0.3030 - val_loss: 0.5552 - val_false_positives_3: 7129.0000 - val_precision_3: 0.4844\n",
      "Epoch 89/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7499 - false_positives_3: 30735.0000 - precision_3: 0.3075 - val_loss: 0.5535 - val_false_positives_3: 7089.0000 - val_precision_3: 0.4853\n",
      "Epoch 90/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7438 - false_positives_3: 30057.0000 - precision_3: 0.3140 - val_loss: 0.5534 - val_false_positives_3: 6917.0000 - val_precision_3: 0.4890\n",
      "Epoch 91/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7420 - false_positives_3: 29300.0000 - precision_3: 0.3162 - val_loss: 0.5520 - val_false_positives_3: 6833.0000 - val_precision_3: 0.4909\n",
      "Epoch 92/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7352 - false_positives_3: 28503.0000 - precision_3: 0.3239 - val_loss: 0.5509 - val_false_positives_3: 6743.0000 - val_precision_3: 0.4934\n",
      "Epoch 93/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.7311 - false_positives_3: 27625.0000 - precision_3: 0.3278 - val_loss: 0.5501 - val_false_positives_3: 6665.0000 - val_precision_3: 0.4954\n",
      "Epoch 94/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7273 - false_positives_3: 26882.0000 - precision_3: 0.3325 - val_loss: 0.5487 - val_false_positives_3: 6687.0000 - val_precision_3: 0.4949\n",
      "Epoch 95/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7247 - false_positives_3: 26150.0000 - precision_3: 0.3386 - val_loss: 0.5479 - val_false_positives_3: 6609.0000 - val_precision_3: 0.4965\n",
      "Epoch 96/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7202 - false_positives_3: 24985.0000 - precision_3: 0.3484 - val_loss: 0.5459 - val_false_positives_3: 6714.0000 - val_precision_3: 0.4944\n",
      "Epoch 97/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7182 - false_positives_3: 24299.0000 - precision_3: 0.3514 - val_loss: 0.5444 - val_false_positives_3: 6807.0000 - val_precision_3: 0.4922\n",
      "Epoch 98/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7151 - false_positives_3: 23646.0000 - precision_3: 0.3569 - val_loss: 0.5429 - val_false_positives_3: 6784.0000 - val_precision_3: 0.4927\n",
      "Epoch 99/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7123 - false_positives_3: 22687.0000 - precision_3: 0.3639 - val_loss: 0.5401 - val_false_positives_3: 6992.0000 - val_precision_3: 0.4879\n",
      "Epoch 100/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7079 - false_positives_3: 22096.0000 - precision_3: 0.3739 - val_loss: 0.5380 - val_false_positives_3: 7195.0000 - val_precision_3: 0.4829\n",
      "Epoch 101/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.7064 - false_positives_3: 21382.0000 - precision_3: 0.3794 - val_loss: 0.5364 - val_false_positives_3: 7256.0000 - val_precision_3: 0.4816\n",
      "Epoch 102/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7041 - false_positives_3: 20927.0000 - precision_3: 0.3847 - val_loss: 0.5344 - val_false_positives_3: 7290.0000 - val_precision_3: 0.4808\n",
      "Epoch 103/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7007 - false_positives_3: 20414.0000 - precision_3: 0.3877 - val_loss: 0.5332 - val_false_positives_3: 7213.0000 - val_precision_3: 0.4820\n",
      "Epoch 104/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6971 - false_positives_3: 19911.0000 - precision_3: 0.3977 - val_loss: 0.5322 - val_false_positives_3: 7112.0000 - val_precision_3: 0.4835\n",
      "Epoch 105/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6954 - false_positives_3: 19320.0000 - precision_3: 0.3999 - val_loss: 0.5317 - val_false_positives_3: 6949.0000 - val_precision_3: 0.4867\n",
      "Epoch 106/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6906 - false_positives_3: 18645.0000 - precision_3: 0.4068 - val_loss: 0.5302 - val_false_positives_3: 6859.0000 - val_precision_3: 0.4884\n",
      "Epoch 107/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6899 - false_positives_3: 18129.0000 - precision_3: 0.4104 - val_loss: 0.5281 - val_false_positives_3: 6830.0000 - val_precision_3: 0.4890\n",
      "Epoch 108/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6858 - false_positives_3: 17742.0000 - precision_3: 0.4169 - val_loss: 0.5272 - val_false_positives_3: 6701.0000 - val_precision_3: 0.4918\n",
      "Epoch 109/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6855 - false_positives_3: 17252.0000 - precision_3: 0.4186 - val_loss: 0.5274 - val_false_positives_3: 6606.0000 - val_precision_3: 0.4937\n",
      "Epoch 110/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6815 - false_positives_3: 16646.0000 - precision_3: 0.4255 - val_loss: 0.5280 - val_false_positives_3: 6400.0000 - val_precision_3: 0.4982\n",
      "Epoch 111/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6759 - false_positives_3: 16263.0000 - precision_3: 0.4314 - val_loss: 0.5273 - val_false_positives_3: 6386.0000 - val_precision_3: 0.4988\n",
      "Epoch 112/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6756 - false_positives_3: 16029.0000 - precision_3: 0.4344 - val_loss: 0.5280 - val_false_positives_3: 6230.0000 - val_precision_3: 0.5027\n",
      "Epoch 113/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6730 - false_positives_3: 15673.0000 - precision_3: 0.4389 - val_loss: 0.5294 - val_false_positives_3: 6060.0000 - val_precision_3: 0.5060\n",
      "Epoch 114/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6682 - false_positives_3: 15262.0000 - precision_3: 0.4451 - val_loss: 0.5297 - val_false_positives_3: 5986.0000 - val_precision_3: 0.5079\n",
      "Epoch 115/150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6694 - false_positives_3: 14957.0000 - precision_3: 0.4457 - val_loss: 0.5281 - val_false_positives_3: 6132.0000 - val_precision_3: 0.5049\n",
      "Epoch 116/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6649 - false_positives_3: 14647.0000 - precision_3: 0.4542 - val_loss: 0.5280 - val_false_positives_3: 6135.0000 - val_precision_3: 0.5053\n",
      "Epoch 117/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6670 - false_positives_3: 14583.0000 - precision_3: 0.4516 - val_loss: 0.5295 - val_false_positives_3: 5996.0000 - val_precision_3: 0.5086\n",
      "Epoch 118/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6620 - false_positives_3: 14230.0000 - precision_3: 0.4585 - val_loss: 0.5313 - val_false_positives_3: 5850.0000 - val_precision_3: 0.5130\n",
      "Epoch 119/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6600 - false_positives_3: 13972.0000 - precision_3: 0.4628 - val_loss: 0.5319 - val_false_positives_3: 5866.0000 - val_precision_3: 0.5128\n",
      "Epoch 120/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6592 - false_positives_3: 14187.0000 - precision_3: 0.4593 - val_loss: 0.5336 - val_false_positives_3: 5805.0000 - val_precision_3: 0.5144\n",
      "Epoch 121/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6589 - false_positives_3: 14041.0000 - precision_3: 0.4595 - val_loss: 0.5351 - val_false_positives_3: 5790.0000 - val_precision_3: 0.5147\n",
      "Epoch 122/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6588 - false_positives_3: 13943.0000 - precision_3: 0.4580 - val_loss: 0.5366 - val_false_positives_3: 5737.0000 - val_precision_3: 0.5162\n",
      "Epoch 123/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6563 - false_positives_3: 13812.0000 - precision_3: 0.4635 - val_loss: 0.5378 - val_false_positives_3: 5779.0000 - val_precision_3: 0.5151\n",
      "Epoch 124/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6556 - false_positives_3: 13889.0000 - precision_3: 0.4635 - val_loss: 0.5394 - val_false_positives_3: 5785.0000 - val_precision_3: 0.5152\n",
      "Epoch 125/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6543 - false_positives_3: 13725.0000 - precision_3: 0.4644 - val_loss: 0.5412 - val_false_positives_3: 5750.0000 - val_precision_3: 0.5163\n",
      "Epoch 126/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6541 - false_positives_3: 13751.0000 - precision_3: 0.4638 - val_loss: 0.5410 - val_false_positives_3: 5938.0000 - val_precision_3: 0.5120\n",
      "Epoch 127/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6530 - false_positives_3: 13821.0000 - precision_3: 0.4683 - val_loss: 0.5422 - val_false_positives_3: 5966.0000 - val_precision_3: 0.5110\n",
      "Epoch 128/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6509 - false_positives_3: 13890.0000 - precision_3: 0.4669 - val_loss: 0.5427 - val_false_positives_3: 6132.0000 - val_precision_3: 0.5071\n",
      "Epoch 129/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6499 - false_positives_3: 13977.0000 - precision_3: 0.4685 - val_loss: 0.5444 - val_false_positives_3: 6215.0000 - val_precision_3: 0.5052\n",
      "Epoch 130/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6495 - false_positives_3: 14080.0000 - precision_3: 0.4652 - val_loss: 0.5467 - val_false_positives_3: 6180.0000 - val_precision_3: 0.5060\n",
      "Epoch 131/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6469 - false_positives_3: 13990.0000 - precision_3: 0.4718 - val_loss: 0.5469 - val_false_positives_3: 6351.0000 - val_precision_3: 0.5025\n",
      "Epoch 132/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6497 - false_positives_3: 14222.0000 - precision_3: 0.4640 - val_loss: 0.5476 - val_false_positives_3: 6427.0000 - val_precision_3: 0.5009\n",
      "Epoch 133/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6471 - false_positives_3: 14463.0000 - precision_3: 0.4661 - val_loss: 0.5510 - val_false_positives_3: 6216.0000 - val_precision_3: 0.5053\n",
      "Epoch 134/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6467 - false_positives_3: 14291.0000 - precision_3: 0.4682 - val_loss: 0.5515 - val_false_positives_3: 6300.0000 - val_precision_3: 0.5042\n",
      "Epoch 135/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6465 - false_positives_3: 14366.0000 - precision_3: 0.4665 - val_loss: 0.5513 - val_false_positives_3: 6466.0000 - val_precision_3: 0.5007\n",
      "Epoch 136/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6451 - false_positives_3: 14587.0000 - precision_3: 0.4667 - val_loss: 0.5524 - val_false_positives_3: 6449.0000 - val_precision_3: 0.5011\n",
      "Epoch 137/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6453 - false_positives_3: 14549.0000 - precision_3: 0.4656 - val_loss: 0.5507 - val_false_positives_3: 6716.0000 - val_precision_3: 0.4955\n",
      "Epoch 138/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6448 - false_positives_3: 14764.0000 - precision_3: 0.4668 - val_loss: 0.5543 - val_false_positives_3: 6520.0000 - val_precision_3: 0.4994\n",
      "Epoch 139/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6455 - false_positives_3: 14615.0000 - precision_3: 0.4657 - val_loss: 0.5557 - val_false_positives_3: 6609.0000 - val_precision_3: 0.4973\n",
      "Epoch 140/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6441 - false_positives_3: 15004.0000 - precision_3: 0.4649 - val_loss: 0.5554 - val_false_positives_3: 6850.0000 - val_precision_3: 0.4924\n",
      "Epoch 141/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6449 - false_positives_3: 15128.0000 - precision_3: 0.4609 - val_loss: 0.5578 - val_false_positives_3: 6796.0000 - val_precision_3: 0.4936\n",
      "Epoch 142/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6442 - false_positives_3: 15249.0000 - precision_3: 0.4626 - val_loss: 0.5599 - val_false_positives_3: 6762.0000 - val_precision_3: 0.4945\n",
      "Epoch 143/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6436 - false_positives_3: 15357.0000 - precision_3: 0.4614 - val_loss: 0.5614 - val_false_positives_3: 6771.0000 - val_precision_3: 0.4947\n",
      "Epoch 144/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6413 - false_positives_3: 15249.0000 - precision_3: 0.4692 - val_loss: 0.5600 - val_false_positives_3: 6990.0000 - val_precision_3: 0.4898\n",
      "Epoch 145/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6425 - false_positives_3: 15654.0000 - precision_3: 0.4631 - val_loss: 0.5600 - val_false_positives_3: 7105.0000 - val_precision_3: 0.4872\n",
      "Epoch 146/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6420 - false_positives_3: 15419.0000 - precision_3: 0.4664 - val_loss: 0.5614 - val_false_positives_3: 7097.0000 - val_precision_3: 0.4875\n",
      "Epoch 147/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6403 - false_positives_3: 15802.0000 - precision_3: 0.4646 - val_loss: 0.5624 - val_false_positives_3: 7114.0000 - val_precision_3: 0.4874\n",
      "Epoch 148/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6407 - false_positives_3: 15863.0000 - precision_3: 0.4621 - val_loss: 0.5623 - val_false_positives_3: 7219.0000 - val_precision_3: 0.4852\n",
      "Epoch 149/150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6404 - false_positives_3: 15990.0000 - precision_3: 0.4654 - val_loss: 0.5644 - val_false_positives_3: 7147.0000 - val_precision_3: 0.4870\n",
      "Epoch 150/150\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6406 - false_positives_3: 16155.0000 - precision_3: 0.4627 - val_loss: 0.5653 - val_false_positives_3: 7206.0000 - val_precision_3: 0.4856\n"
     ]
    }
   ],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "EPOCHS = 150\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 15:23:05.392475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 14ms/step\n",
      "4/4 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 278ms/step - loss: 0.5665 - false_positives_3: 9183.0000 - precision_3: 0.4852\n",
      "loss :  0.5664575099945068\n",
      "false_positives_3 :  9183.0\n",
      "precision_3 :  0.48517125844955444\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  40375\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  9183\n",
      "Fraudulent Transactions Missed (False Negatives):  4288\n",
      "Fraudulent Transactions Detected (True Positives):  8654\n",
      "Total Fraudulent Transactions:  12942\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
    "                                           batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_weighted,threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mac",
   "language": "python",
   "name": "tf_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
