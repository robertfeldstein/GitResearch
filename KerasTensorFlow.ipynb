{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.layers import Flatten\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>nearest_time</th>\n",
       "      <th>lightning</th>\n",
       "      <th>CMI_C01</th>\n",
       "      <th>CMI_C02</th>\n",
       "      <th>CMI_C03</th>\n",
       "      <th>CMI_C04</th>\n",
       "      <th>CMI_C05</th>\n",
       "      <th>CMI_C06</th>\n",
       "      <th>...</th>\n",
       "      <th>CMI_C15</th>\n",
       "      <th>CMI_C16</th>\n",
       "      <th>ACM</th>\n",
       "      <th>BCM</th>\n",
       "      <th>Cloud_Probabilities</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th>time_int</th>\n",
       "      <th>Lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(40.13103323474366, -93.38155072424266)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481706</td>\n",
       "      <td>0.431289</td>\n",
       "      <td>0.579424</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.478710</td>\n",
       "      <td>0.376825</td>\n",
       "      <td>...</td>\n",
       "      <td>274.17140</td>\n",
       "      <td>263.11536</td>\n",
       "      <td>2.156176</td>\n",
       "      <td>0.937424</td>\n",
       "      <td>0.762866</td>\n",
       "      <td>40.131033</td>\n",
       "      <td>-93.381551</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(40.12698592712501, -93.2741436595977)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365158</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>0.495337</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.376627</td>\n",
       "      <td>0.285793</td>\n",
       "      <td>...</td>\n",
       "      <td>274.72607</td>\n",
       "      <td>263.44934</td>\n",
       "      <td>1.843675</td>\n",
       "      <td>0.843675</td>\n",
       "      <td>0.530524</td>\n",
       "      <td>40.126986</td>\n",
       "      <td>-93.274144</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(40.122965705716815, -93.16685328500078)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318968</td>\n",
       "      <td>0.255297</td>\n",
       "      <td>0.471785</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.333135</td>\n",
       "      <td>0.245873</td>\n",
       "      <td>...</td>\n",
       "      <td>274.57343</td>\n",
       "      <td>263.16013</td>\n",
       "      <td>1.874843</td>\n",
       "      <td>0.812655</td>\n",
       "      <td>0.615035</td>\n",
       "      <td>40.122966</td>\n",
       "      <td>-93.166853</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(40.11897247748837, -93.05967862352706)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310932</td>\n",
       "      <td>0.245516</td>\n",
       "      <td>0.473551</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.323313</td>\n",
       "      <td>0.240774</td>\n",
       "      <td>...</td>\n",
       "      <td>272.76428</td>\n",
       "      <td>261.35620</td>\n",
       "      <td>2.905629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980994</td>\n",
       "      <td>40.118972</td>\n",
       "      <td>-93.059679</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(40.115006150366405, -92.95261870531907)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.373254</td>\n",
       "      <td>0.310456</td>\n",
       "      <td>0.511190</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>0.365952</td>\n",
       "      <td>0.287559</td>\n",
       "      <td>...</td>\n",
       "      <td>265.78076</td>\n",
       "      <td>255.51756</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999029</td>\n",
       "      <td>40.115006</td>\n",
       "      <td>-92.952619</td>\n",
       "      <td>2022-05-21 18:00:31.272519936</td>\n",
       "      <td>1653156031272519936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               Coordinates nearest_time  \\\n",
       "0           0   (40.13103323474366, -93.38155072424266)            0   \n",
       "1           1    (40.12698592712501, -93.2741436595977)            0   \n",
       "2           2  (40.122965705716815, -93.16685328500078)            0   \n",
       "3           3   (40.11897247748837, -93.05967862352706)            0   \n",
       "4           4  (40.115006150366405, -92.95261870531907)            0   \n",
       "\n",
       "   lightning   CMI_C01   CMI_C02   CMI_C03   CMI_C04   CMI_C05   CMI_C06  ...  \\\n",
       "0        0.0  0.481706  0.431289  0.579424  0.002143  0.478710  0.376825  ...   \n",
       "1        0.0  0.365158  0.305932  0.495337  0.002024  0.376627  0.285793  ...   \n",
       "2        0.0  0.318968  0.255297  0.471785  0.003135  0.333135  0.245873  ...   \n",
       "3        0.0  0.310932  0.245516  0.473551  0.006746  0.323313  0.240774  ...   \n",
       "4        0.0  0.373254  0.310456  0.511190  0.020992  0.365952  0.287559  ...   \n",
       "\n",
       "     CMI_C15    CMI_C16       ACM       BCM  Cloud_Probabilities        lat  \\\n",
       "0  274.17140  263.11536  2.156176  0.937424             0.762866  40.131033   \n",
       "1  274.72607  263.44934  1.843675  0.843675             0.530524  40.126986   \n",
       "2  274.57343  263.16013  1.874843  0.812655             0.615035  40.122966   \n",
       "3  272.76428  261.35620  2.905629  1.000000             0.980994  40.118972   \n",
       "4  265.78076  255.51756  3.000000  1.000000             0.999029  40.115006   \n",
       "\n",
       "         lon                           time             time_int  Lightning  \n",
       "0 -93.381551  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "1 -93.274144  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "2 -93.166853  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "3 -93.059679  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "4 -92.952619  2022-05-21 18:00:31.272519936  1653156031272519936          0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/robbiefeldstein/Documents/Programming/Research/Datasets/May_22.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 468750\n",
      "    Positive: 30597 (6.53% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Look at class imbalance\n",
    "\n",
    "neg, pos = np.bincount(df['Lightning'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"CMI_C01\", \"CMI_C02\", \"CMI_C03\",\"CMI_C04\", \"CMI_C05\",\"CMI_C06\", \"CMI_C07\",\"CMI_C15\",\"Cloud_Probabilities\",\"Lightning\"]\n",
    "#let's just do less features\n",
    "#Predictors\n",
    "\n",
    "copy_df = df.copy()\n",
    "copy_df = copy_df[features]\n",
    "\n",
    "X = copy_df[features]\n",
    "\n",
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(copy_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Lightning'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Lightning'))\n",
    "test_labels = np.array(test_df.pop('Lightning'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class probability in training set:   0.0656\n",
      "Average class probability in validation set: 0.0647\n",
      "Average class probability in test set:       0.0648\n"
     ]
    }
   ],
   "source": [
    "#Averages are roughly similar\n",
    "\n",
    "print(f'Average class probability in training set:   {train_labels.mean():.4f}')\n",
    "print(f'Average class probability in validation set: {val_labels.mean():.4f}')\n",
    "print(f'Average class probability in test set:       {test_labels.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (300000,)\n",
      "Validation labels shape: (75000,)\n",
      "Test labels shape: (93750,)\n",
      "Training features shape: (300000, 9)\n",
      "Validation features shape: (75000, 9)\n",
      "Test features shape: (93750, 9)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 22:48:34.409795: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-11-05 22:48:34.409830: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-11-05 22:48:34.409838: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-11-05 22:48:34.409945: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-05 22:48:34.410203: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#Recommended parameters for imbalanced model\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "      keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Dense(len(features), activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    #Output layer\n",
    "    keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.FalsePositives(), tf.keras.metrics.Precision()])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 128\n",
    "BATCH_SIZE = 16384\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.72916761]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                100       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 10)                40        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                176       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501 (1.96 KB)\n",
      "Trainable params: 481 (1.88 KB)\n",
      "Non-trainable params: 20 (80.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initial_bias = np.log([pos/len(df)])\n",
    "print(initial_bias)\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 22:48:36.337009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 22:48:40.513003: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 720ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00500328],\n",
       "       [0.00755938],\n",
       "       [0.11994843],\n",
       "       [0.00771898],\n",
       "       [0.25490707],\n",
       "       [0.06887375],\n",
       "       [0.17940962],\n",
       "       [0.02982352],\n",
       "       [0.00159838],\n",
       "       [0.15171504]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n",
    "\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model()\n",
    "# model.load_weights(initial_weights)\n",
    "# model.layers[-1].bias.assign([0.0])\n",
    "# zero_bias_history = model.fit(\n",
    "#     train_features,\n",
    "#     train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=16,\n",
    "#     validation_data=(val_features, val_labels), \n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model()\n",
    "# model.load_weights(initial_weights)\n",
    "# careful_bias_history = model.fit(\n",
    "#     train_features,\n",
    "#     train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     epochs=16,\n",
    "#     validation_data=(val_features, val_labels), \n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
    "# plot_loss(careful_bias_history, \"Careful Bias\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'precision',]\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 12ms/step\n",
      "6/6 [==============================] - 0s 87ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > threshold)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(threshold))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.53\n",
      "Weight for class 1: 7.66\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 22:48:43.139789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 2.5639 - false_positives_2: 38158.0000 - precision_2: 0.0392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 22:48:55.734984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 17s 490ms/step - loss: 2.5639 - false_positives_2: 38158.0000 - precision_2: 0.0392 - val_loss: 0.3435 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 2.0790 - false_positives_2: 37135.0000 - precision_2: 0.0522 - val_loss: 0.2845 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.8047 - false_positives_2: 37172.0000 - precision_2: 0.0666 - val_loss: 0.2600 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.6922 - false_positives_2: 38354.0000 - precision_2: 0.0736 - val_loss: 0.2482 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1.5966 - false_positives_2: 38527.0000 - precision_2: 0.0805 - val_loss: 0.2437 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.5339 - false_positives_2: 38903.0000 - precision_2: 0.0852 - val_loss: 0.2440 - val_false_positives_2: 7.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.4868 - false_positives_2: 39257.0000 - precision_2: 0.0871 - val_loss: 0.2467 - val_false_positives_2: 22.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1.4415 - false_positives_2: 39694.0000 - precision_2: 0.0914 - val_loss: 0.2507 - val_false_positives_2: 38.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.3930 - false_positives_2: 39985.0000 - precision_2: 0.0951 - val_loss: 0.2548 - val_false_positives_2: 39.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.3715 - false_positives_2: 40447.0000 - precision_2: 0.0945 - val_loss: 0.2590 - val_false_positives_2: 42.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.3460 - false_positives_2: 40597.0000 - precision_2: 0.0952 - val_loss: 0.2624 - val_false_positives_2: 19.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.3209 - false_positives_2: 41273.0000 - precision_2: 0.0952 - val_loss: 0.2673 - val_false_positives_2: 33.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.2896 - false_positives_2: 41410.0000 - precision_2: 0.0987 - val_loss: 0.2714 - val_false_positives_2: 37.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1.2707 - false_positives_2: 41803.0000 - precision_2: 0.0989 - val_loss: 0.2751 - val_false_positives_2: 39.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.2422 - false_positives_2: 41956.0000 - precision_2: 0.0994 - val_loss: 0.2782 - val_false_positives_2: 30.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.2358 - false_positives_2: 42316.0000 - precision_2: 0.0959 - val_loss: 0.2806 - val_false_positives_2: 15.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.2098 - false_positives_2: 42741.0000 - precision_2: 0.0973 - val_loss: 0.2836 - val_false_positives_2: 11.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.2002 - false_positives_2: 42921.0000 - precision_2: 0.0953 - val_loss: 0.2864 - val_false_positives_2: 6.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.1851 - false_positives_2: 43233.0000 - precision_2: 0.0957 - val_loss: 0.2894 - val_false_positives_2: 4.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.1673 - false_positives_2: 43362.0000 - precision_2: 0.0949 - val_loss: 0.2928 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.1524 - false_positives_2: 43889.0000 - precision_2: 0.0941 - val_loss: 0.2962 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 1.1458 - false_positives_2: 43958.0000 - precision_2: 0.0930 - val_loss: 0.3002 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.1297 - false_positives_2: 44464.0000 - precision_2: 0.0921 - val_loss: 0.3045 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.1114 - false_positives_2: 44950.0000 - precision_2: 0.0921 - val_loss: 0.3087 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.1006 - false_positives_2: 45473.0000 - precision_2: 0.0916 - val_loss: 0.3134 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.0932 - false_positives_2: 46179.0000 - precision_2: 0.0899 - val_loss: 0.3181 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.0819 - false_positives_2: 46561.0000 - precision_2: 0.0885 - val_loss: 0.3234 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.0698 - false_positives_2: 47034.0000 - precision_2: 0.0891 - val_loss: 0.3284 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1.0611 - false_positives_2: 47684.0000 - precision_2: 0.0867 - val_loss: 0.3333 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.0445 - false_positives_2: 47860.0000 - precision_2: 0.0885 - val_loss: 0.3385 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.0338 - false_positives_2: 48265.0000 - precision_2: 0.0879 - val_loss: 0.3435 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.0183 - false_positives_2: 48304.0000 - precision_2: 0.0901 - val_loss: 0.3486 - val_false_positives_2: 3.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.0067 - false_positives_2: 48937.0000 - precision_2: 0.0895 - val_loss: 0.3530 - val_false_positives_2: 4.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1.0007 - false_positives_2: 49115.0000 - precision_2: 0.0882 - val_loss: 0.3573 - val_false_positives_2: 5.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.9947 - false_positives_2: 49450.0000 - precision_2: 0.0871 - val_loss: 0.3615 - val_false_positives_2: 7.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.9841 - false_positives_2: 49370.0000 - precision_2: 0.0882 - val_loss: 0.3657 - val_false_positives_2: 8.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.9725 - false_positives_2: 49744.0000 - precision_2: 0.0880 - val_loss: 0.3697 - val_false_positives_2: 11.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.9642 - false_positives_2: 50187.0000 - precision_2: 0.0881 - val_loss: 0.3735 - val_false_positives_2: 8.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.9553 - false_positives_2: 50183.0000 - precision_2: 0.0879 - val_loss: 0.3763 - val_false_positives_2: 10.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.9451 - false_positives_2: 50253.0000 - precision_2: 0.0892 - val_loss: 0.3790 - val_false_positives_2: 6.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.9427 - false_positives_2: 50334.0000 - precision_2: 0.0881 - val_loss: 0.3818 - val_false_positives_2: 6.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.9298 - false_positives_2: 50436.0000 - precision_2: 0.0902 - val_loss: 0.3843 - val_false_positives_2: 3.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.9233 - false_positives_2: 50430.0000 - precision_2: 0.0898 - val_loss: 0.3869 - val_false_positives_2: 3.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.9219 - false_positives_2: 50563.0000 - precision_2: 0.0893 - val_loss: 0.3887 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.9112 - false_positives_2: 50159.0000 - precision_2: 0.0901 - val_loss: 0.3906 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.9074 - false_positives_2: 49982.0000 - precision_2: 0.0900 - val_loss: 0.3925 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.9030 - false_positives_2: 50214.0000 - precision_2: 0.0890 - val_loss: 0.3941 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.8942 - false_positives_2: 49948.0000 - precision_2: 0.0910 - val_loss: 0.3957 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8884 - false_positives_2: 50214.0000 - precision_2: 0.0915 - val_loss: 0.3975 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8822 - false_positives_2: 50012.0000 - precision_2: 0.0924 - val_loss: 0.3986 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8746 - false_positives_2: 50014.0000 - precision_2: 0.0948 - val_loss: 0.3998 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8728 - false_positives_2: 49699.0000 - precision_2: 0.0935 - val_loss: 0.4010 - val_false_positives_2: 1.0000 - val_precision_2: 0.0000e+00\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8731 - false_positives_2: 49676.0000 - precision_2: 0.0931 - val_loss: 0.4018 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8673 - false_positives_2: 49483.0000 - precision_2: 0.0925 - val_loss: 0.4028 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8584 - false_positives_2: 49146.0000 - precision_2: 0.0944 - val_loss: 0.4042 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8576 - false_positives_2: 49060.0000 - precision_2: 0.0940 - val_loss: 0.4053 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8512 - false_positives_2: 48687.0000 - precision_2: 0.0954 - val_loss: 0.4064 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8478 - false_positives_2: 48899.0000 - precision_2: 0.0943 - val_loss: 0.4078 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8468 - false_positives_2: 48684.0000 - precision_2: 0.0946 - val_loss: 0.4087 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8431 - false_positives_2: 48404.0000 - precision_2: 0.0940 - val_loss: 0.4101 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.8369 - false_positives_2: 48125.0000 - precision_2: 0.0971 - val_loss: 0.4113 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8401 - false_positives_2: 48352.0000 - precision_2: 0.0948 - val_loss: 0.4125 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8315 - false_positives_2: 48147.0000 - precision_2: 0.0971 - val_loss: 0.4133 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.8262 - false_positives_2: 47827.0000 - precision_2: 0.0987 - val_loss: 0.4145 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8192 - false_positives_2: 47971.0000 - precision_2: 0.0998 - val_loss: 0.4161 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.8208 - false_positives_2: 48264.0000 - precision_2: 0.0994 - val_loss: 0.4172 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.8200 - false_positives_2: 48163.0000 - precision_2: 0.0990 - val_loss: 0.4184 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8124 - false_positives_2: 48016.0000 - precision_2: 0.1014 - val_loss: 0.4192 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.8115 - false_positives_2: 47673.0000 - precision_2: 0.1030 - val_loss: 0.4199 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.8079 - false_positives_2: 47723.0000 - precision_2: 0.1038 - val_loss: 0.4208 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.8013 - false_positives_2: 47347.0000 - precision_2: 0.1060 - val_loss: 0.4209 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7981 - false_positives_2: 47153.0000 - precision_2: 0.1076 - val_loss: 0.4218 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.7950 - false_positives_2: 47260.0000 - precision_2: 0.1082 - val_loss: 0.4221 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7952 - false_positives_2: 47111.0000 - precision_2: 0.1087 - val_loss: 0.4220 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7886 - false_positives_2: 46643.0000 - precision_2: 0.1101 - val_loss: 0.4224 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7868 - false_positives_2: 45587.0000 - precision_2: 0.1109 - val_loss: 0.4215 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.7851 - false_positives_2: 45070.0000 - precision_2: 0.1118 - val_loss: 0.4216 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7823 - false_positives_2: 44755.0000 - precision_2: 0.1127 - val_loss: 0.4228 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7799 - false_positives_2: 45030.0000 - precision_2: 0.1128 - val_loss: 0.4248 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.7754 - false_positives_2: 45156.0000 - precision_2: 0.1147 - val_loss: 0.4261 - val_false_positives_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7732 - false_positives_2: 44888.0000 - precision_2: 0.1154 - val_loss: 0.4265 - val_false_positives_2: 3.0000 - val_precision_2: 0.2500\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.7703 - false_positives_2: 44599.0000 - precision_2: 0.1174 - val_loss: 0.4269 - val_false_positives_2: 3.0000 - val_precision_2: 0.2500\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.7680 - false_positives_2: 44253.0000 - precision_2: 0.1174 - val_loss: 0.4270 - val_false_positives_2: 5.0000 - val_precision_2: 0.7368\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7690 - false_positives_2: 44103.0000 - precision_2: 0.1153 - val_loss: 0.4273 - val_false_positives_2: 16.0000 - val_precision_2: 0.6522\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7634 - false_positives_2: 43854.0000 - precision_2: 0.1195 - val_loss: 0.4286 - val_false_positives_2: 130.0000 - val_precision_2: 0.3868\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7648 - false_positives_2: 43874.0000 - precision_2: 0.1195 - val_loss: 0.4282 - val_false_positives_2: 112.0000 - val_precision_2: 0.3913\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7611 - false_positives_2: 43037.0000 - precision_2: 0.1189 - val_loss: 0.4278 - val_false_positives_2: 27.0000 - val_precision_2: 0.5714\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.7570 - false_positives_2: 42507.0000 - precision_2: 0.1192 - val_loss: 0.4286 - val_false_positives_2: 124.0000 - val_precision_2: 0.3981\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7533 - false_positives_2: 41779.0000 - precision_2: 0.1236 - val_loss: 0.4284 - val_false_positives_2: 134.0000 - val_precision_2: 0.3937\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7522 - false_positives_2: 41733.0000 - precision_2: 0.1238 - val_loss: 0.4300 - val_false_positives_2: 286.0000 - val_precision_2: 0.3687\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7476 - false_positives_2: 41761.0000 - precision_2: 0.1246 - val_loss: 0.4315 - val_false_positives_2: 1122.0000 - val_precision_2: 0.2952\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7459 - false_positives_2: 41986.0000 - precision_2: 0.1272 - val_loss: 0.4321 - val_false_positives_2: 2331.0000 - val_precision_2: 0.2658\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7412 - false_positives_2: 41383.0000 - precision_2: 0.1299 - val_loss: 0.4319 - val_false_positives_2: 2177.0000 - val_precision_2: 0.2630\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7432 - false_positives_2: 41446.0000 - precision_2: 0.1266 - val_loss: 0.4320 - val_false_positives_2: 2467.0000 - val_precision_2: 0.2556\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7387 - false_positives_2: 40790.0000 - precision_2: 0.1302 - val_loss: 0.4320 - val_false_positives_2: 2881.0000 - val_precision_2: 0.2499\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7362 - false_positives_2: 40254.0000 - precision_2: 0.1325 - val_loss: 0.4332 - val_false_positives_2: 3667.0000 - val_precision_2: 0.2461\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7341 - false_positives_2: 40657.0000 - precision_2: 0.1318 - val_loss: 0.4345 - val_false_positives_2: 4919.0000 - val_precision_2: 0.2513\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7286 - false_positives_2: 40460.0000 - precision_2: 0.1356 - val_loss: 0.4348 - val_false_positives_2: 5979.0000 - val_precision_2: 0.2564\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7311 - false_positives_2: 40272.0000 - precision_2: 0.1342 - val_loss: 0.4340 - val_false_positives_2: 6039.0000 - val_precision_2: 0.2560\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7252 - false_positives_2: 39504.0000 - precision_2: 0.1383 - val_loss: 0.4338 - val_false_positives_2: 6594.0000 - val_precision_2: 0.2540\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7238 - false_positives_2: 38742.0000 - precision_2: 0.1399 - val_loss: 0.4323 - val_false_positives_2: 6528.0000 - val_precision_2: 0.2541\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7204 - false_positives_2: 37959.0000 - precision_2: 0.1426 - val_loss: 0.4310 - val_false_positives_2: 6610.0000 - val_precision_2: 0.2535\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7198 - false_positives_2: 37277.0000 - precision_2: 0.1434 - val_loss: 0.4299 - val_false_positives_2: 6347.0000 - val_precision_2: 0.2550\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7176 - false_positives_2: 36829.0000 - precision_2: 0.1447 - val_loss: 0.4311 - val_false_positives_2: 7725.0000 - val_precision_2: 0.2454\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7141 - false_positives_2: 36698.0000 - precision_2: 0.1494 - val_loss: 0.4306 - val_false_positives_2: 8565.0000 - val_precision_2: 0.2381\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7106 - false_positives_2: 35816.0000 - precision_2: 0.1519 - val_loss: 0.4297 - val_false_positives_2: 8817.0000 - val_precision_2: 0.2373\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7094 - false_positives_2: 35585.0000 - precision_2: 0.1513 - val_loss: 0.4297 - val_false_positives_2: 9299.0000 - val_precision_2: 0.2341\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7066 - false_positives_2: 34753.0000 - precision_2: 0.1550 - val_loss: 0.4291 - val_false_positives_2: 9488.0000 - val_precision_2: 0.2331\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7046 - false_positives_2: 34360.0000 - precision_2: 0.1570 - val_loss: 0.4276 - val_false_positives_2: 9281.0000 - val_precision_2: 0.2349\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.7038 - false_positives_2: 33699.0000 - precision_2: 0.1574 - val_loss: 0.4287 - val_false_positives_2: 9980.0000 - val_precision_2: 0.2295\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.7006 - false_positives_2: 33606.0000 - precision_2: 0.1590 - val_loss: 0.4287 - val_false_positives_2: 10377.0000 - val_precision_2: 0.2249\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6973 - false_positives_2: 33162.0000 - precision_2: 0.1633 - val_loss: 0.4291 - val_false_positives_2: 10581.0000 - val_precision_2: 0.2228\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6965 - false_positives_2: 33277.0000 - precision_2: 0.1610 - val_loss: 0.4305 - val_false_positives_2: 11287.0000 - val_precision_2: 0.2160\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6932 - false_positives_2: 32938.0000 - precision_2: 0.1650 - val_loss: 0.4298 - val_false_positives_2: 11369.0000 - val_precision_2: 0.2153\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6896 - false_positives_2: 32171.0000 - precision_2: 0.1663 - val_loss: 0.4279 - val_false_positives_2: 10895.0000 - val_precision_2: 0.2204\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6886 - false_positives_2: 32040.0000 - precision_2: 0.1675 - val_loss: 0.4284 - val_false_positives_2: 11285.0000 - val_precision_2: 0.2163\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6844 - false_positives_2: 31884.0000 - precision_2: 0.1701 - val_loss: 0.4295 - val_false_positives_2: 11580.0000 - val_precision_2: 0.2137\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6826 - false_positives_2: 31754.0000 - precision_2: 0.1712 - val_loss: 0.4287 - val_false_positives_2: 11338.0000 - val_precision_2: 0.2161\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6820 - false_positives_2: 30931.0000 - precision_2: 0.1723 - val_loss: 0.4284 - val_false_positives_2: 11143.0000 - val_precision_2: 0.2181\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6822 - false_positives_2: 31093.0000 - precision_2: 0.1712 - val_loss: 0.4299 - val_false_positives_2: 11637.0000 - val_precision_2: 0.2137\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6817 - false_positives_2: 30961.0000 - precision_2: 0.1719 - val_loss: 0.4284 - val_false_positives_2: 11490.0000 - val_precision_2: 0.2152\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6765 - false_positives_2: 30356.0000 - precision_2: 0.1751 - val_loss: 0.4274 - val_false_positives_2: 11294.0000 - val_precision_2: 0.2171\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.6762 - false_positives_2: 29823.0000 - precision_2: 0.1762 - val_loss: 0.4294 - val_false_positives_2: 11352.0000 - val_precision_2: 0.2172\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6720 - false_positives_2: 30380.0000 - precision_2: 0.1756 - val_loss: 0.4324 - val_false_positives_2: 11780.0000 - val_precision_2: 0.2127\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6699 - false_positives_2: 30732.0000 - precision_2: 0.1782 - val_loss: 0.4331 - val_false_positives_2: 11948.0000 - val_precision_2: 0.2110\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6705 - false_positives_2: 29869.0000 - precision_2: 0.1759 - val_loss: 0.4311 - val_false_positives_2: 11396.0000 - val_precision_2: 0.2167\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6671 - false_positives_2: 29764.0000 - precision_2: 0.1792 - val_loss: 0.4342 - val_false_positives_2: 11942.0000 - val_precision_2: 0.2114\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6654 - false_positives_2: 30299.0000 - precision_2: 0.1768 - val_loss: 0.4354 - val_false_positives_2: 12150.0000 - val_precision_2: 0.2096\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6653 - false_positives_2: 30185.0000 - precision_2: 0.1766 - val_loss: 0.4341 - val_false_positives_2: 11852.0000 - val_precision_2: 0.2120\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6627 - false_positives_2: 29644.0000 - precision_2: 0.1809 - val_loss: 0.4354 - val_false_positives_2: 12105.0000 - val_precision_2: 0.2099\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6608 - false_positives_2: 29637.0000 - precision_2: 0.1815 - val_loss: 0.4358 - val_false_positives_2: 11837.0000 - val_precision_2: 0.2123\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6601 - false_positives_2: 30151.0000 - precision_2: 0.1812 - val_loss: 0.4385 - val_false_positives_2: 12288.0000 - val_precision_2: 0.2089\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6571 - false_positives_2: 29163.0000 - precision_2: 0.1845 - val_loss: 0.4418 - val_false_positives_2: 12675.0000 - val_precision_2: 0.2057\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6558 - false_positives_2: 30536.0000 - precision_2: 0.1809 - val_loss: 0.4401 - val_false_positives_2: 12110.0000 - val_precision_2: 0.2101\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.6536 - false_positives_2: 29635.0000 - precision_2: 0.1853 - val_loss: 0.4443 - val_false_positives_2: 12754.0000 - val_precision_2: 0.2053\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6532 - false_positives_2: 30382.0000 - precision_2: 0.1830 - val_loss: 0.4439 - val_false_positives_2: 12487.0000 - val_precision_2: 0.2079\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6516 - false_positives_2: 29943.0000 - precision_2: 0.1851 - val_loss: 0.4454 - val_false_positives_2: 12635.0000 - val_precision_2: 0.2064\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6498 - false_positives_2: 30128.0000 - precision_2: 0.1842 - val_loss: 0.4493 - val_false_positives_2: 13194.0000 - val_precision_2: 0.2019\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6526 - false_positives_2: 29799.0000 - precision_2: 0.1842 - val_loss: 0.4503 - val_false_positives_2: 12978.0000 - val_precision_2: 0.2035\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6459 - false_positives_2: 30894.0000 - precision_2: 0.1860 - val_loss: 0.4529 - val_false_positives_2: 13062.0000 - val_precision_2: 0.2034\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6455 - false_positives_2: 30774.0000 - precision_2: 0.1864 - val_loss: 0.4543 - val_false_positives_2: 13050.0000 - val_precision_2: 0.2036\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6461 - false_positives_2: 30733.0000 - precision_2: 0.1867 - val_loss: 0.4556 - val_false_positives_2: 12958.0000 - val_precision_2: 0.2042\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6461 - false_positives_2: 30745.0000 - precision_2: 0.1841 - val_loss: 0.4586 - val_false_positives_2: 13455.0000 - val_precision_2: 0.2003\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6435 - false_positives_2: 31307.0000 - precision_2: 0.1838 - val_loss: 0.4595 - val_false_positives_2: 13394.0000 - val_precision_2: 0.2008\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6423 - false_positives_2: 30953.0000 - precision_2: 0.1853 - val_loss: 0.4635 - val_false_positives_2: 13911.0000 - val_precision_2: 0.1973\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.6412 - false_positives_2: 31459.0000 - precision_2: 0.1843 - val_loss: 0.4633 - val_false_positives_2: 13664.0000 - val_precision_2: 0.1988\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6387 - false_positives_2: 31747.0000 - precision_2: 0.1866 - val_loss: 0.4661 - val_false_positives_2: 13844.0000 - val_precision_2: 0.1980\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6370 - false_positives_2: 31777.0000 - precision_2: 0.1871 - val_loss: 0.4715 - val_false_positives_2: 14578.0000 - val_precision_2: 0.1936\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6392 - false_positives_2: 31854.0000 - precision_2: 0.1857 - val_loss: 0.4679 - val_false_positives_2: 13123.0000 - val_precision_2: 0.2032\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6375 - false_positives_2: 31940.0000 - precision_2: 0.1857 - val_loss: 0.4755 - val_false_positives_2: 14798.0000 - val_precision_2: 0.1925\n"
     ]
    }
   ],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "EPOCHS = 150\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 22:49:55.353559: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 12ms/step\n",
      "6/6 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 242ms/step - loss: 0.4737 - false_positives_2: 18236.0000 - precision_2: 0.1911\n",
      "loss :  0.4736853837966919\n",
      "false_positives_2 :  18236.0\n",
      "precision_2 :  0.19112884998321533\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  69442\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  18236\n",
      "Fraudulent Transactions Missed (False Negatives):  1763\n",
      "Fraudulent Transactions Detected (True Positives):  4309\n",
      "Total Fraudulent Transactions:  6072\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
    "                                           batch_size=BATCH_SIZE, verbose=1)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_weighted,threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mac",
   "language": "python",
   "name": "tf_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
